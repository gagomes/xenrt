#!/usr/bin/python
# XenRT: Test harness for Xen and the XenServer product family
#
# Script to control tests at a deployment site.
#
# Copyright (c) 2006 XenSource, Inc. All use and distribution of this
# copyrighted material is governed by and subject to terms and
# conditions as licensed by XenSource, Inc. All other rights reserved.
#

import sys, string, getopt, urllib, os, pwd, traceback, signal, time
import tempfile, re, pickle, threading, ConfigParser
sys.path.append(os.path.dirname(sys.argv[0]))
import xenrtapi

_sharedir = "@sharedir@"
_rootdir = "@rootdir@"
_vardir = "@vardir@"
_stablebranch = "@stablebranch@"
if not _stablebranch:
    _stablebranch = "master"

optparse = []
optparse.append(("OPTIONS", "--arch", True))
optparse.append(("REPO", "--repo", True))
optparse.append(("REVISION", "--revision", True))
optparse.append(("OPTION_PATCHQUEUE", "--pq", True))
optparse.append(("OPTION_PQ_PATCH", "--pqpatch", True))
optparse.append(("OPTION_PATCHQUEUE_REV", "--pqrev", True))
optparse.append(("HVARCH", "--hvarch", True))
optparse.append(("HARNESS_TRACE", "--trace", False))
optparse.append(("NOFINALLY", "--no-finally", False))
optparsevars = []
for opt in optparse:
    var, flag, hasarg = opt
    optparsevars.append(var)

debug = False
traceon = 0
def trace(str):
    global traceon
    if traceon:
        sys.stderr.write(str)

def incrementfailcount():
    try:
        f = file("%s/site-controller-fail-count" % _vardir)
        count = int(f.readline().strip())
        f.close()
    except:
        count = 0
    f = file("%s/site-controller-fail-count" % _vardir, "w")
    f.write("%d\n" % (count + 1))
    f.close()

def execCmd(cmd, errorException=True):
    rc = os.system(cmd)
    if rc > 0 and errorException:
        raise Exception("Error running %s" % cmd)

# Kill self if still running after 5 minutes
class WatchdogThread(threading.Thread):
    def run(self):
        time.sleep(600)
        print "Site controller taken too long, killing"
        os.kill(os.getpid(), signal.SIGKILL)

watchdog = WatchdogThread()
watchdog.daemon=True
watchdog.start() 


site = None
domain = None
args = None
lockfile = None

## Rate limit for starting jobs.
# The window, in minutes, the the rolling rate limit is applied over
ratewindow = 10
# The maximum number of jobs that can be started in each ratewindow
ratejobs = 5
# The maximum number of jobs that can be started in any one site-controller run
burstjobs = 3
ratehistoryfile = "/tmp/xenrt-site-controller-history.dat"

logserver=None

# Dirty hack to use the JOBSERVER_PROXY and rate limit variables
if os.path.exists("/etc/xenrt/site.xml"):
    f = file("/etc/xenrt/site.xml", "r")
    data = f.read()
    f.close()
    r = re.search("<JOB_RATE_LIMIT_WINDOW>(\d+)<\/JOB_RATE_LIMIT_WINDOW>", data)
    if r:
        ratewindow = int(r.group(1))
    r = re.search("<JOB_RATE_LIMIT_JOBS>(\d+)<\/JOB_RATE_LIMIT_JOBS>", data)
    if r:
        ratejobs = int(r.group(1))
    r = re.search("<JOB_RATE_LIMIT_BURST>(\d+)<\/JOB_RATE_LIMIT_BURST>", data)
    if r:
        burstjobs = int(r.group(1))
    r = re.search("<LOG_SERVER>(.+)<\/LOG_SERVER>", data)
    if r:
        logserver = r.group(1)
try:
    config = ConfigParser.ConfigParser()
    config.read("%s/.xenrtrc" % os.path.expanduser("~"))
    apikey = config.get("xenrt", "apikey").strip()
except:
    raise Exception("No API key found in ~/.xenrtrc") 
try:
    server = config.get("xenrt", "server").strip()
except:
    server = None

xenrt = xenrtapi.XenRT(apikey=apikey, server=server)

try:
    print "Logged into XenRT as %s" % xenrt.get_loggedinuser()
except:
    print "Could not login to XenRT"
    raise

if not logserver:
    logserver = xenrt.get_logserver()
    

def fqdn(host):
    global domain
    if domain:
        return "%s.%s" % (host, domain)
    return host

def killJob(jobid):
    global _sharedir
    resdir = os.popen("realpath %s/results/jobs/%s" % (_sharedir, jobid)).read().strip()
    f = os.popen("sudo ls -l /proc/*/cwd |  grep  ' %s$' | cut -d '/' -f 3" % resdir)
    for l in f.readlines():
        if "main.py" in open("/proc/%s/cmdline" % l.strip()).read():
            pid = l.strip()
            cmd = "kill -2 %s" % pid
            trace("Killing job %s using %s\n" % (jobid, cmd))
            os.system(cmd)
            time.sleep(5)
    f.close()
    f = os.popen("sudo ls -l /proc/*/cwd |  grep  ' %s$' | cut -d '/' -f 3" % resdir)
    pids = []
    for l in f.readlines():
        pids.append(l.strip())
    if len(pids) > 0:
        cmd = "kill -9 %s" % (" ".join(pids))
        trace("Killing job %s using %s\n" % (jobid, cmd))
        os.system(cmd)

def checkJobRunning(jobid):
    pid = None
    global _sharedir
    resdir = os.popen("realpath %s/results/jobs/%s" % (_sharedir, jobid)).read().strip()
    f = os.popen("sudo ls -l /proc/*/cwd |  grep  ' %s$' | cut -d '/' -f 3" % resdir)
    for l in f.readlines():
        if "main.py" in open("/proc/%s/cmdline" % l.strip()).read():
            pid = m.group(1)
    f.close()
    return pid

def start_job(job):
    """Start a job using the machines previously scheduled"""
    global com, _sharedir, _rootdir, args, debug
    # Create a working directory
    resdir = "%s/results/jobs/%d" % (_sharedir, job['id'])
    os.makedirs(resdir)
    data = job['params']
    data['USERID'] = job['user']
    data['JOBID'] = str(job['id'])
    cmd = ["%s/exec/main.py" % (_sharedir)]
    cmd.append("-V")
    cmd.append("-C")
    cmd.append(resdir)
    cmd.append("--redir")
    cmd.append("--remote")
    if args:
        for a in string.split(args):
            cmd.append(a)
    if data.has_key("CLI_ARGS_PASSTHROUGH"):
        for i in string.split(data["CLI_ARGS_PASSTHROUGH"]):
            cmd.append(i)
    if data.has_key("SCHEDULEDON") and not "--pool" in cmd and not "--existing" in cmd:
        hosts = string.split(data["SCHEDULEDON"], ",")
        if data.has_key("SCHEDULEDON2"):
            hosts.extend(string.split(data["SCHEDULEDON2"], ","))
        if data.has_key("SCHEDULEDON3"):
            hosts.extend(string.split(data["SCHEDULEDON3"], ","))
        hostslong = map(fqdn, hosts)
        cmd.append("--host")
        cmd.append("%s" % (string.join(hostslong, ",")))
    if data.has_key("DEPS"):
        cmd.append("--sequence")
        cmd.append("%s" % (data["DEPS"]))
    else:
        xenrt.update_job(job['id'], params={"FAILED": "No sequence file specified"}, complete=True)
        return
    if data.has_key("TESTCASEFILES"):
        cmd.append("--testcasefiles")
        cmd.append("%s" % (data["TESTCASEFILES"]))
    for optpair in optparse:
        var, flag, hasarg = optpair
        if data.has_key(var):
            cmd.append(flag)
            if hasarg:
                cmd.append(data[var])
    for k in data.keys():
        if not k in ("DEPS", "SCHEDULEDON", "SCHEDULEDON2", "SCHEDULEDON3", "TESTCASEFILES", "CLI_ARGS_PASSTHROUGH") \
                and not k in optparsevars:
            cmd.append("-D")
            cmd.append("%s=%s" % (k, data[k]))

    if job.get("preemptable"):
        cmd.append("-D")
        cmd.append("PREEMPTABLE=yes")

    cmdl = string.join(cmd)

    if data.has_key("XRTBRANCH") and len(data["XRTBRANCH"]) > 0:
        branch = data['XRTBRANCH']
        otherBranch = True
    else:
        branch = _stablebranch
        otherBranch = False
    trace("Using branch '%s'\n" % (branch))

    try:
        execCmd("cd %s && git reset --hard" % (_rootdir), errorException=False)
        execCmd("cd %s && git checkout -f %s && git reset --hard" % (_rootdir, _stablebranch))
        execCmd("cd %s && git pull --ff-only" % (_rootdir), errorException=otherBranch)

        if otherBranch:
            # Try to delete the branch if it exists. Ignore the error
            execCmd("cd %s && git branch -D %s" % (_rootdir, branch), errorException=False)
            # Pull down the branch from upstream
            execCmd("cd %s && git fetch origin && git checkout -f %s" % (_rootdir, branch))

            execCmd("cd %s && git checkout -f %s && git reset --hard" % (_rootdir, branch))
            execCmd("cd %s && git pull --ff-only" % (_rootdir), errorException=otherBranch)
            try:
                execCmd("cd %s && git merge %s --no-edit" % (_rootdir, _stablebranch))
            except:
                execCmd("cd %s && git merge %s -m Merge" % (_rootdir, _stablebranch))
        
        execCmd("cd %s/../xenrt-internal.git && git checkout -f %s && git reset --hard && git pull --ff-only" % (_rootdir, _stablebranch), errorException=False)

    except Exception, e:
        # Failed set-up, so bail out.
        errmsg = "Failed to checkout from git - %s" % str(e) 
        execCmd("cd %s && git reset --hard" % (_rootdir), errorException=False)
        execCmd("cd %s && git checkout -f %s && git reset --hard" % (_rootdir, _stablebranch), errorException=False)
        if otherBranch:
            execCmd("cd %s && git branch -D %s" % (_rootdir, branch), errorException=False)
        trace("%s\n" % (errmsg))
        if not debug:
            xenrt.update_job(job['id'], params={"FAILED": errmsg[:200]}, complete=True)
        return
    
    custompatchtmp = ""
    if data.has_key("CUSTOM_PATCH") and len(data["CUSTOM_PATCH"]) > 0:
        errmsg = ""
        
        # download custom-patch from scheduler
        custompatchtmp = "/tmp/" + str(job['id']) + data["CUSTOM_PATCH"]
        patchurl = xenrt.get_job_attachment_pre_run(job['id'], data["CUSTOM_PATCH"])
        try:
            urllib.urlretrieve(patchurl, custompatchtmp)
        except Exception, e:
            errmsg = "Could not download custom patch - %s" % str(e)
        else:
            if os.path.isfile(custompatchtmp):
                # apply patch
                rc = os.system("cd %s && patch -p1 < %s" % (_rootdir, custompatchtmp))
                if rc > 0:
                    errmsg = "Could not import custom patch %s" % (data["CUSTOM_PATCH"])
            else:
                errmsg = "Could not find custom patch %s" % (data["CUSTOM_PATCH"])
            
        if len(errmsg) > 0:
            trace("%s\n" % (errmsg))
            if not debug:
                xenrt.update_job(job['id'], params={"FAILED": errmsg}, complete=True)
            
            if len(custompatchtmp) > 0 and os.path.isfile(custompatchtmp):
                os.system("cd %s && git reset --hard" % (_rootdir))
                # delete all files in the custom patch as some of these might be left as untracked
                # by the revert-all. They need to be deleted so as to allow patches on these files in future.
                os.system("cd %s && cat %s | lsdiff --strip 1 | xargs -I '{}' rm -f '{}'" % (_rootdir, custompatchtmp))
                os.system("cd %s && git reset --hard" % (_rootdir))
                os.system("rm -f %s" % custompatchtmp)
            return


    os.system("cd %s && BUILDDIR=%s/venvs/%d/exec make minimal-install" % (_rootdir, _sharedir, job['id']))
    cmd.insert(0, str(job['id']))
    cmd.insert(0, resdir)
    cmd.insert(0, "%s/venvs/%d" % (_sharedir, job['id']))
    cmd.insert(0, "%s/control/venvwrapper2.sh" % _sharedir)
    cmdl = string.join(cmd)
    trace("exec: %s\n" % (cmdl))
    if not debug:
        pid = os.spawnv(os.P_NOWAIT, cmd[0], cmd)
        xenrt.update_job(job['id'], params={"HARNESS_PID": "%u" % (pid), "LOG_SERVER": logserver})

    time.sleep(30)
    if len(custompatchtmp) > 0 and os.path.isfile(custompatchtmp):
        os.system("cd %s && git reset --hard" % (_rootdir))
        # delete all files in the custom patch as some of these might be left as untracked
        # when reverting. They need to be deleted so as to allow patches on these files in future.
        os.system("cd %s && cat %s | lsdiff --strip 1 | xargs -I '{}' rm -f '{}'" % (_rootdir, custompatchtmp))
        os.system("cd %s && git reset --hard" % (_rootdir))
        os.system("rm -f %s" % custompatchtmp)
    
    os.system("cd %s && git checkout -f %s" % (_rootdir, _stablebranch))
    if otherBranch:
        os.system("cd %s && git branch -D %s" % (_rootdir, branch))
    os.system("cd %s && make minimal-install" % (_rootdir))

# Main prog
if __name__ == '__main__':
    if os.path.exists("%s/halted" % _vardir):
        print "Site is halted"
        sys.exit(1)
    optlist, arglist = getopt.getopt(sys.argv[1:], 's:dD:x:A:Sl:')
    for argpair in optlist:
        (flag, value) = argpair
        if flag == "-d":
            traceon = 1
        if flag == "-s":
            site = value
        if flag == "-D":
            domain = value
        if flag == "-x":
            _sharedir = value
        if flag == "-A":
            args = value
        if flag == "-S":
            debug = True
        if flag == "-l":
            lockfile = value

    if not site:
        sys.stderr.write("Must specify the site ID.\n")
        sys.exit(1)

    if not lockfile:
        lockfile = "/tmp/xenrt-site-controller.pid"

    # Determine if we need to run or not
    if os.path.exists(lockfile):
        try:
            f = file(lockfile, 'r')
            data = f.read().strip()
            pid = None
            try:
                pid = int(data)
            except:
                # The lockfile doesn't contain a valid PID
                trace("Invalid lockfile found, continuing.\n")
            else:
                # Check if this pid is still running
                if os.path.exists("/proc/%d" % (pid)):
                    trace("Valid lockfile found, aborting.\n")
                    incrementfailcount()
                    sys.exit(0)
                else:
                    trace("Old lockfile found, continuing.\n")
        except Exception, e:
            if isinstance(e, SystemExit):
                raise e
            sys.stderr.write("Exception checking lockfile, aborting.\n")
            incrementfailcount()
            sys.exit(1)

    # Write out the lockfile
    f = file(lockfile, 'w')
    f.write(str(os.getpid()))
    f.close()

    f = file("%s/site-controller-fail-count" % _vardir, "w")
    f.write("0\n")
    f.close()

    # Read in our recent job starting history to use for rate limiting
    now = int(time.mktime(time.localtime()))
    windowopens = now - ratewindow * 60
    starttimes = []
    if os.path.exists(ratehistoryfile):
        f = file(ratehistoryfile, "r")
        data = f.read()
        f.close()
        for starttime in map(int, data.split()):
            # Only interested in starts within the rate limit window
            if starttime >= windowopens:
                starttimes.append(starttime)
        trace("Read in recent job start times: %s\n" % (starttimes))
    # Calculate how many jobs we are allowed to start this iteration
    remainingwindow = ratejobs - len(starttimes)
    if remainingwindow < 0:
        maystart = 0
    elif remainingwindow < burstjobs:
        maystart = remainingwindow
    else:
        maystart = burstjobs

    # Obtain the list of machines at our site
    trace("Fetching list of machines.\n")
    mlist = xenrt.get_machines(site=[site], pseudohosts=True)

    # For each machine, check whether we have a job running
    newjobs = {}
    ready = {}
    deadjobs = []
    for machine in sorted(mlist.keys()):
        m = mlist[machine]
        trace("Checking machine %s..." % (m['name']))
        if m['rawstatus'] == "idle":
            trace(" idle\n")
        elif m['rawstatus'] == "slaved":
            # Check whether the job has been marked as completed
            data = xenrt.get_job(m['jobid'])
            if data["rawstatus"] == "done":
                trace(" completed jobid %d\n" % (m['jobid']))
                xenrt.update_machine(m['name'], status="idle")
                xenrt.new_event("JobEnd", m['name'], str(m['jobid']))
            else:
                trace(" running jobid %d (slave)\n" % (m['jobid']))
        elif m['rawstatus'] == "scheduled":
            trace(" scheduled to run %d\n" % (m['jobid']))
            data = xenrt.get_job(m['jobid'])
            if data['removed']:
                trace(" removed, so not starting job\n")
                xenrt.update_job(m['jobid'], complete=True)
                xenrt.update_machine(m['name'], status="idle")
            else:
                if not newjobs.has_key(str(m['jobid'])):
                    newjobs[str(m['jobid'])] = []
                newjobs[str(m['jobid'])].append(m['name'])
                ready[m['name']] = True
        elif m['rawstatus'] == "running":
            # Check whether the job has been marked as completed
            data = xenrt.get_job(m['jobid'])
            if data['rawstatus'] == "done":
                trace(" completed jobid %d\n" % (m['jobid']))
                xenrt.update_machine(m['name'], status="idle")
                xenrt.new_event("JobEnd", m['name'], str(m['jobid']))
                os.spawnl(os.P_NOWAIT, "%s/exec/main.py" % _sharedir, "%s/exec/main.py" % _sharedir, "--cleanup-temp-dirs", str(m['jobid']))
            else:
                hpid = None
                if data['params'].has_key("HARNESS_PID") and os.path.exists("/proc/%s/stat" % data['params']['HARNESS_PID']):
                    hpid = data['params']['HARNESS_PID']
                if hpid:
                    trace(" running jobid %d, process %s\n" % (m['jobid'], hpid))
                else:
                    trace(" running jobid %d. ERROR - no process for job\n" % (m['jobid']))
                    xenrt.update_job(m['jobid'], params={"DEAD_JOB": "yes"})
                    deadjobs.append(str(m['jobid']))
                if data['removed']:
                    trace("Job %d set as removed, killing job\n" % m['jobid'])
                    killJob(str(m['jobid']))
                    xenrt.update_job(m['jobid'], complete=True)
                    xenrt.update_machine(m['name'], status="idle")
                    os.spawnl(os.P_NOWAIT, "%s/exec/main.py" % _sharedir, "%s/exec/main.py" % _sharedir, "--cleanup-temp-dirs", str(m['jobid']))
                    if not (data.has_key("OPTION_KEEP_NFS") and data["OPTION_KEEP_NFS"] == "yes"):
                        os.spawnl(os.P_NOWAIT, "%s/exec/main.py" % _sharedir, "%s/exec/main.py" % _sharedir, "--cleanup-nfs-dirs", str(m['jobid']))
        else:
            trace(" unknown status %s\n" % (m['rawstatus']))

    f = open("%s/deadjobs" % _vardir, "w")
    f.write("%s\n" % (", ".join(deadjobs)))
    f.close()

    # Sort the new job list by priority so that higher jobs get started
    # first and lower priority jobs are more likely to be rate limited.
    newjobprios = {}
    for j in newjobs.keys():
        job = xenrt.get_job(int(j))
        data = job['params']
        prio = 3
        if data.has_key("JOBPRIO"):
            try:
                prio = int(data["JOBPRIO"])
            except:
                pass
        sortkey = "P%03uJ%08u" % (prio, int(j))
        newjobprios[sortkey] = j
    newjobpriokeys = newjobprios.keys()
    newjobpriokeys.sort()
    newjoblist = [newjobprios[x] for x in newjobpriokeys]
        
    # If we have new jobs make sure we have all the machines ready then
    # start the job

    for j in newjoblist:
        trace("New job %s..." % (j))
        notready = []
        for m in newjobs[j]:
            if not ready.has_key(m):
                notready.append(m)
        if len(notready) == 0:
            if maystart > 0:
                # Run the job and note that these machines are now busy
                hosts = []
                trace(" starting\n")
                machines = []
                for m in newjobs[j]:
                    machines.append(m)
                    del ready[m]
                    xenrt.update_machine(m, status="running")

                # Set the user of the job to the DB events table for quick access later
                job = xenrt.get_job(int(j))
                for machine in job['machines']:
                    xenrt.new_event("JobStart", machine, str(j))
                start_job(job)
                starttimes.append(now)
                maystart = maystart - 1
            else:
                trace(" not starting due to job rate limiting\n")
        else:
            trace(" %s not ready\n" % (string.join(notready,",")))

    # Write out the recent scheduling history (including any within the
    # rate window read in earlier) for use in rate limit calculations
    # next time.
    f = file(ratehistoryfile, "w")
    f.write(string.join(map(str, starttimes), "\n"))
    f.close()

    # Erase the lock
    os.unlink(lockfile)

