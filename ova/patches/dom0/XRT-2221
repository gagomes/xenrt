diff -r 9ce9101b3e6b binary-overlay.xenrt/etc/httpd/conf.d/apt-cacher.conf
--- a/binary-overlay.xenrt/etc/httpd/conf.d/apt-cacher.conf	Wed Feb 27 12:23:56 2008 +0000
+++ b/binary-overlay.xenrt/etc/httpd/conf.d/apt-cacher.conf	Fri Mar 14 12:05:55 2008 +0000
@@ -1,6 +1,6 @@ Alias /apt-cacher /usr/local/share/apt-c
-Alias /apt-cacher /usr/local/share/apt-cacher/lib/apt-cacher.pl
+Alias /apt-cacher /usr/share/apt-cacher/apt-cacher.pl
 
-<DirectoryMatch /usr/local/share/apt-cacher/lib/>
+<DirectoryMatch /usr/share/apt-cacher/>
 	Options ExecCGI
 	AddHandler cgi-script .pl
 	AllowOverride None
diff -r 9ce9101b3e6b overlay.xenrt/etc/rc.local
--- a/overlay.xenrt/etc/rc.local	Wed Feb 27 12:23:56 2008 +0000
+++ b/overlay.xenrt/etc/rc.local	Thu Feb 28 15:49:14 2008 +0000
@@ -27,6 +27,8 @@ if [ ! -e /.configdone ]; then
     mkdir -p /local/inputs/linux/distros
     mkdir -p /local/inputs/linux/iso
     mv /home/xenrtd/tests /local/inputs/tests
+    # Populate the apt-cache
+    cp -fR /local/inputs/tests/apt-cache/* /local/apt-cache/
     chown xenrtd -R /local
     mkdir -p /var/log/httpd/apt-cache
     chown xenrtd /var/log/httpd/apt-cache
diff -r 9ce9101b3e6b packages.xenrt
--- a/packages.xenrt	Wed Feb 27 12:23:56 2008 +0000
+++ b/packages.xenrt	Fri Mar 14 12:03:41 2008 +0000
@@ -37,3 +37,4 @@ perl-IO-Socket-SSL
 perl-IO-Socket-SSL
 perl-Net-SSLeay
 vconfig
+perl-libwww-perl
diff -r 9ce9101b3e6b Makefile
--- a/Makefile	Wed Feb 27 12:23:56 2008 +0000
+++ b/Makefile	Fri Mar 14 13:44:21 2008 +0000
@@ -334,7 +334,7 @@ post: $(POST_COOKIE)
 	#$(CHROOT) find /home/xenrtd/xenrt.hg/keys ! -type d -exec rm -f "{}" \;
 	# Set up swap file
 	bash mkfs.swap $(XENRT_SWAP_IMAGE) $(XENRT_SWAP_G)
-	$(CHROOT) chmod -R a+x /usr/local/share/apt-cacher/lib
+	$(CHROOT) chmod -R a+x /usr/share/apt-cacher
 	$(CHROOT) chmod a+x /sbin/update-issue
 	# Bring in cleanroot images etc
 	cp -R $(XENRT_DISTMASTER)/clean $(STAGING)/tftpboot/
diff -r 9ce9101b3e6b binary-overlay.xenrt/etc/apt-cacher/apache.conf
--- /dev/null	Thu Jan 01 00:00:00 1970 +0000
+++ b/binary-overlay.xenrt/etc/apt-cacher/apache.conf	Fri Mar 14 11:50:26 2008 +0000
@@ -0,0 +1,10 @@
+Alias /apt-cacher /usr/share/apt-cacher/apt-cacher.pl
+
+<DirectoryMatch /usr/share/apt-cacher/>
+	Options ExecCGI
+	AddHandler cgi-script .pl
+	AllowOverride None
+	order allow,deny
+	allow from all
+</DirectoryMatch>
+
diff -r 9ce9101b3e6b binary-overlay.xenrt/etc/apt-cacher/apt-cacher.conf
--- /dev/null	Thu Jan 01 00:00:00 1970 +0000
+++ b/binary-overlay.xenrt/etc/apt-cacher/apt-cacher.conf	Fri Mar 14 12:03:22 2008 +0000
@@ -0,0 +1,140 @@
+#################################################################
+# This is the config file for apt-cacher. On most Debian systems
+# you can safely leave the defaults alone.
+#################################################################
+
+# cache_dir is used to set the location of the local cache. This can
+# become quite large, so make sure it is somewhere with plenty of space.
+cache_dir=/local/apt-cache
+
+# The email address of the administrator is displayed in the info page
+# and traffic reports.
+admin_email=root@localhost
+
+# For the daemon startup settings please edit the file /etc/default/apt-cacher.
+
+# Daemon port setting, only useful in stand-alone mode. You need to run the
+# daemon as root to use privileged ports (<1024).
+daemon_port=3142
+
+# optional settings, user and group to run the daemon as. Make sure they have
+# sufficient permissions on the cache and log directories. Comment the settings
+# to run apt-cacher as the native user.
+group=xenrtd
+user=xenrtd
+
+# optional setting, binds the listening daemon to one specified IP. Use IP
+# ranges for more advanced configuration, see below.
+# daemon_addr=localhost
+
+# If your apt-cacher machine is directly exposed to the Internet and you are
+# worried about unauthorised machines fetching packages through it, you can
+# specify a list of IPv4 addresses which are allowed to use it and another
+# list of IPv4 addresses which aren't.
+# Localhost (127.0.0.1) is always allowed. Other addresses must be matched
+# by allowed_hosts and not by denied_hosts to be permitted to use the cache.
+# Setting allowed_hosts to "*" means "allow all".
+# Otherwise the format is a comma-separated list containing addresses,
+# optionally with masks (like 10.0.0.0/22), or ranges of addresses (two
+# addresses separated by a hyphen, no masks, like '192.168.0.3-192.168.0.56').
+allowed_hosts=*
+denied_hosts=
+
+# And similiarly for IPv6 with allowed_hosts_6 and denied_hosts_6.
+# Note that IPv4-mapped IPv6 addresses (::ffff:w.x.y.z) are truncated to
+# w.x.y.z and are handled as IPv4.
+allowed_hosts_6=fec0::/16
+denied_hosts_6=
+
+# This thing can be done by Apache but is much simplier here - limit access to
+# Debian mirrors based on server names in the URLs
+#allowed_locations=ftp.uni-kl.de,ftp.nerim.net,debian.tu-bs.de
+
+# Apt-cacher can generate usage reports every 24 hours if you set this
+# directive to 1. You can view the reports in a web browser by pointing
+# to your cache machine with '/apt-cacher/report' on the end, like this:
+#      http://yourcache.example.com/apt-cacher/report
+# Generating reports is very fast even with many thousands of logfile
+# lines, so you can safely turn this on without creating much 
+# additional system load.
+generate_reports=0
+
+# Apt-cacher can clean up its cache directory every 24 hours if you set
+# this directive to 1. Cleaning the cache can take some time to run
+# (generally in the order of a few minutes) and removes all package
+# files that are not mentioned in any existing 'Packages' lists. This
+# has the effect of deleting packages that have been superseded by an
+# updated 'Packages' list.
+clean_cache=0
+
+# The directory to use for apt-cacher access and error logs.
+# The access log records every request in the format:
+# date-time|client ip address|HIT/MISS/EXPIRED|object size|object name
+# The error log is slightly more free-form, and is also used for debug
+# messages if debug mode is turned on.
+# Note that the old 'logfile' and 'errorfile' directives are
+# deprecated: if you set them explicitly they will be honoured, but it's
+# better to just get rid of them from old config files.
+logdir=/var/log/httpd/apt-cache
+
+# apt-cacher can use different methods to decide whether package lists need to
+# be updated,
+# A) looking at the age of the cached files
+# B) getting HTTP header from server and comparing that with cached data. This
+# method is more reliable and avoids desynchronisation of data and index files
+# but needs to transfer few bytes from the server every time somebody requests
+# the files ("apt-get update")
+# Set the following value to the maximum age (in hours) for method A or to 0
+# for method B
+expire_hours=0
+
+# Apt-cacher can pass all its requests to an external http proxy like
+# Squid, which could be very useful if you are using an ISP that blocks
+# port 80 and requires all web traffic to go through its proxy. The
+# format is 'hostname:port', eg: 'proxy.example.com:8080'.
+http_proxy=proxy.example.com:8080
+
+# Use of an external proxy can be turned on or off with this flag.
+# Value should be either 0 (off) or 1 (on).
+use_proxy=0
+
+# External http proxy sometimes need authentication to get full access. The
+# format is 'username:password'.
+http_proxy_auth=proxyuser:proxypass
+
+# Use of external proxy authentication can be turned on or off with this flag.
+# Value should be either 0 (off) or 1 (on).
+use_proxy_auth=0
+
+# Rate limiting sets the maximum bandwidth in bytes per second to use
+# for fetching packages. Syntax is fully defined in 'man wget'.
+# Use 'k' or 'm' to use kilobits or megabits / second: eg, 'limit=25k'.
+# Use 0 or a negative value for no rate limiting.
+limit=0
+
+# Debug mode makes apt-cacher spew a lot of extra debug junk to the
+# error log (whose location is defined with the 'logdir' directive).
+# Leave this off unless you need it, or your error log will get very
+# big. Acceptable values are 0 or 1.
+debug=0
+
+# Adapt the line in the usage info web page to match your server configuration
+# example_sources_line=deb&nbsp;http://<b>my.cacher.server:3142/</b>ftp.au.debian.org/debian&nbsp;unstable&nbsp;main&nbsp;contrib&nbsp;non-free
+
+# Print a 410 (Gone) HTTP message with the specified text when accessed via
+# CGI. Useful to tell users to adapt their sources.list files when the
+# apt-cacher server is beeing relocated (via apt-get's error messages while
+# running "update")
+#cgi_advise_to_use = Please use http://cacheserver:3142/ as apt-cacher access URL
+#cgi_advise_to_use = Server relocated. To change sources.list, run perl -pe "s,/apt-cacher\??,:3142," -i /etc/apt/sources.list
+
+# Server mapping - this allows to hide real server names behind virtual paths
+# that appear in the access URL. This method is known from apt-proxy. This is
+# also the only method to use FTP access to the target hosts. The syntax is simple, the part of the beginning to replace, followed by a list of mirror urls, all space separated. Multiple profile are separated by semicolons
+# path_map = debian ftp.uni-kl.de/pub/linux/debian ftp2.de.debian.org/debian ; ubuntu archive.ubuntu.com/ubuntu ; security security.debian.org/debian-security ftp2.de.debian.org/debian-security
+# Note that you need to specify all target servers in the allowed_locations
+# options if you make use of it. Also note that the paths should not overlap
+# each other. FTP access method not supported yet, maybe in the future.
+
+# Use offline mode by default
+offline_mode=1
diff -r 9ce9101b3e6b binary-overlay.xenrt/etc/apt-cacher/checksumming.conf
--- /dev/null	Thu Jan 01 00:00:00 1970 +0000
+++ b/binary-overlay.xenrt/etc/apt-cacher/checksumming.conf	Fri Mar 14 11:50:26 2008 +0000
@@ -0,0 +1,8 @@
+# To enable data checksumming, install libdbd-sqlite3-perl and uncomment the
+# line below. Then wait untill the Packages/Sources files have been refreshed
+# once (and so the database has been built up). You can also nuke them in the
+# cache to trigger the update.
+# require '/usr/share/apt-cacher/apt-cacher-lib-cs.pl';
+
+# don't touch the following line
+1;
diff -r 9ce9101b3e6b binary-overlay.xenrt/usr/sbin/apt-cacher
--- /dev/null	Thu Jan 01 00:00:00 1970 +0000
+++ b/binary-overlay.xenrt/usr/sbin/apt-cacher	Fri Mar 14 11:52:04 2008 +0000
@@ -0,0 +1,1648 @@
+#!/usr/bin/perl
+
+=head1 NAME
+
+ apt-cacher2 - WWW proxy optimized for use with APT
+
+ Copyright (C) 2005 Eduard Bloch <blade@debian.org>
+ Distributed under the terms of the GNU Public Licence (GPL).
+
+=head1 SYNOPSIS
+
+ ./setup.pl /home/me/cache
+ edit /etc/apt/sources.list (use sources like deb http://proxy:3142/archiveserver/debian ...)
+ apt-get update
+ apt-get -u upgrade
+
+=head1 DESCRIPTION
+
+If you have two or more Debian GNU/Linux machines on a fast local
+network and you wish to upgrade packages from the Internet, you
+don't want to download every package several times.
+
+apt-cacher2 is a tiny HTTP proxy that keeps a cache on disk of Debian
+binary/source packages and meta files which have been received from Debian
+distribution servers on the Internet. When an apt-get client issues
+a request for a file to apt-cacher2, if the file is already on disk
+it is served to the client immediately, otherwise it is fetched from the
+Internet and served to the client while a copy is beeing stored on the disk.
+This means that several Debian machines can be upgraded but each package needs
+to be downloaded only once.
+
+apt-cacher2 is a rewrite of the original apt-cacher.pl CGI script, keeping
+compatibility in mind. The cached data can be shared by the both
+implementations, while apt-cacher2 providers better performance and less server
+load.
+
+=head1 INSTALLATION
+
+Assuming your cache server is called B<www.myserver.com>
+and your cache directory is called B</home/me/cache>, then:
+
+1. Edit apt-cacher.conf to customize your settings
+
+2. Run apt-cacher2
+
+=cut
+# ----------------------------------------------------------------------------
+
+use strict;
+#use warnings;
+
+use Fcntl ':flock';
+use POSIX;
+
+use LWP::UserAgent;
+use IO::Socket::INET;
+use HTTP::Response;
+
+use Time::HiRes qw( sleep gettimeofday tv_interval );
+
+
+my @index_files = (
+    'Index',
+	'Packages.gz',
+	'Packages.bz2',
+	'Release',
+	'Release.gpg',
+	'Sources.gz',
+	'Sources.bz2',
+	'Contents-.+\.gz',
+    'pkglist.*\.bz2',
+    'release$',
+    'release\..*',
+    'srclist.*\.bz2'
+);
+my $index_files_regexp = '(' . join('|', @index_files) . ')$';
+
+
+# Include the library for the config file parser
+require '/usr/share/apt-cacher/apt-cacher-lib.pl';
+require '/etc/apt-cacher/checksumming.conf';
+
+
+# Set some defaults
+my $version='0.1'; # this will be auto-replaced when the Debian package is beeing built
+my $configfile_default = '/etc/apt-cacher/apt-cacher.conf';
+my $daemon_port_default=3142;
+my $client="local";
+
+# Read in the config file and set the necessary variables
+my $configfile = $configfile_default;
+
+my $direct_mode; # defines using STDIN/STDOUT
+my $inetd_mode; # no security checks
+my $cgi_mode;
+my $cgi_path;
+
+my $cfg;
+
+my $pidfile;
+my @extraconfig;
+
+my $chroot;
+my $retnum;
+my $do_fork_away;
+
+# this script needs to be executed trough a CGI wrapper setting a flag variable
+if($ENV{CGI_MODE})
+{
+    # yahoo, back to the roots, assume beeing in CGI mode
+    $cgi_mode=1;
+    $direct_mode=1;
+    # pick up the URL
+    $cgi_path=$ENV{PATH_INFO} if ! $cgi_path;
+    $cgi_path=$ENV{QUERY_STRING} if ! $cgi_path;
+    $cgi_path="/" if ! $cgi_path; # set an invalid path to display infos below
+}
+else {
+    while(scalar @ARGV) {
+
+        my $arg=shift(@ARGV);
+
+        if($arg eq "-c") {
+            $configfile=shift(@ARGV);
+            die "$configfile unreadable" if ! -r $configfile;
+        }
+        elsif($arg eq "-r") {
+            $chroot=shift(@ARGV);
+            die "No such directory: $chroot\n" if ! -d $chroot;
+        }
+        elsif($arg eq "-R") {
+            $retnum=shift(@ARGV);
+        }
+        elsif($arg eq "-i") {
+            $inetd_mode=1;
+            $direct_mode=1;
+        }
+        elsif($arg eq "-d") {
+            $do_fork_away=1;
+        }
+        elsif($arg eq "-p") {
+            $pidfile=shift(@ARGV);
+        }
+        elsif($arg=~/(\S+)=(\S+)/) {
+            push(@extraconfig, $1, $2);
+        }
+        elsif($arg eq "-h" || $arg eq "--help") {
+            print <<EOM;
+USAGE: $0 <options> <override(s)>
+Options:
+
+-c configfile   Custom config file (default: $configfile_default)
+-i              Inetd mode, STDIN and STDOUT are used for service
+(default: standalone server mode)
+-d              become a background daemon
+
+Advanced options (root only):
+-r directory    (experimental option) 
+                path to chroot to after reading the config and opening the log
+                files. cache directory setting must be relative to the new root.
+                WARNING: log files should be created before and be owned by tne
+                effective user/group if -g or -u are used
+-p pidfile      write the server process ID into this file
+
+Overrides:     override config variables (see config file), eg. daemon_port=9999
+
+EOM
+            exit(0);
+        }
+        else {
+            die "Unknown parameter $arg\n";
+        }
+    }
+}
+
+eval {
+        $cfg = read_config($configfile);
+};
+
+# not sure what to do if we can't read the config file...
+die "Could not read config file: $@" if $@;
+
+# Now set some things from the config file
+# $logfile used to be set in the config file: now we derive it from $logdir
+$$cfg{logfile} = "$$cfg{logdir}/access.log";
+
+# $errorfile used to be set in the config file: now we derive it from $logdir
+$$cfg{errorfile} = "$$cfg{logdir}/error.log";
+
+$$cfg{fetch_timeout}=300; # five minutes from now
+
+my $private_dir = "$$cfg{cache_dir}/private";
+define_global_lockfile("$private_dir/exlock");
+
+# override config values with the user-specified parameters
+while(@extraconfig) { 
+    my $k=shift(@extraconfig);
+    my $v=shift(@extraconfig); 
+    $$cfg{$k}=$v;
+}
+
+
+my ($aclog_fh, $erlog_fh);
+#FIXME: genauer die Scopes betrachten
+my ($path, $filename, $new_filename, $con, $source);
+
+my %pathmap;
+
+if($$cfg{path_map}) {
+    for(split(/\s*;\s*/, $$cfg{path_map})) {
+        my @tmp = split(/\s+/, $_);
+        # must have at least one path and target
+        next if ($#tmp < 1);
+        my $key=shift(@tmp);
+        $pathmap{$key}=[@tmp];
+    }
+}
+
+
+# Output data as soon as we print it
+$| = 1;
+
+# Function prototypes
+sub ipv4_addr_in_list ($$);
+sub ipv6_addr_in_list ($$);
+sub get_abort_time ();
+
+# ----------------------------------------------------------------------------
+# Die if we have not been configured correctly
+die "$0: No cache_dir directory!\n" if (!-d $$cfg{cache_dir});
+die "$0: No cache_dir/private directory!\n" if (!-d $private_dir);
+
+# ----------------------------------------------------------------------------
+# Data shared between functions
+
+my $cached_file;
+my $cached_head;
+my $complete_file;
+my $notify_file;
+
+my $do_import=0;
+my $concloseflag;
+my $is_index_file;
+
+my $ua;
+my $daemon;
+my $server_pid;
+my $fetcher_pid;
+my %childPids;
+my $terminating;
+
+sub term_handler {
+    $terminating=1;
+
+    # close all connections or shutdown the server if parent and kill 
+    debug_message("received SIGTERM, terminating");
+    $con->close if defined($con);
+
+    
+    if($server_pid && $server_pid == $$) {
+        $daemon->shutdown(2);
+    }
+
+    # stop all children
+    #{ doesn't work, signal comes delayed. Why?!
+    #    local $SIG{"TERM"} = 'IGNORE';          
+    #    kill("TERM", -$$);
+    #}
+    for(keys %childPids) { 
+        &debug_message("killing subprocess: $_"); 
+        kill 15, $_;
+    };
+    exit 0;
+};
+
+sub reload_config {
+    debug_message("Got SIGHUP, reloading config");
+    $cfg = read_config($configfile);
+};
+
+# broken, kills unrelated processes. Not using for now.
+# perlipc(1)
+# also remove them from the to-be-killed list
+#sub reap_children {
+#    my $child;
+#    while (($child = waitpid(-1,WNOHANG)) > 0) {
+#        delete $childPids{$child};
+#    }
+#    $SIG{CHLD} = \&reap_children;  # still loathe sysV
+#
+#}
+#$SIG{CHLD} = \&reap_children;
+$SIG{CHLD} = 'IGNORE';
+$SIG{'TERM'} = \&term_handler;
+$SIG{'HUP'} = \&reload_config;
+
+my $getBufLen=10000;
+my $maxspeed;
+
+my ($chfd, $pkfd);
+
+# for rate limit support
+if($$cfg{limit}>0) {
+    $maxspeed = $$cfg{limit}*1024;
+    $getBufLen = $maxspeed/20; # 20 portions per second should be enough
+}
+
+sub setup_agent {
+
+   return if(defined($ua));
+
+   $ua=LWP::UserAgent->new('keep_alive' => 1);
+
+   # Check whether a proxy is to be used, and set the appropriate environment variable
+   my $proxystring;
+   if ( $$cfg{use_proxy} eq 1 && $$cfg{http_proxy}) {
+       $proxystring="http://";
+       if ( $$cfg{use_proxy_auth} eq 1) {
+           $proxystring.=$$cfg{http_proxy_auth}.'@';
+       }
+       $proxystring.=$$cfg{http_proxy};
+   }
+   $ua->proxy("http", $proxystring) if $proxystring;
+}
+
+
+
+
+
+# BEGINN MAIN PART
+
+if($cgi_mode && defined($$cfg{cgi_advise_to_use}) && $$cfg{cgi_advise_to_use}) {
+    print "Status: 410 $$cfg{cgi_advise_to_use}\r\n\r\n";
+    exit 0;
+}
+
+if($direct_mode) {
+    &setup_ownership;
+    &open_log_files;
+#optional checksumming support
+    db_init("$$cfg{cache_dir}/md5sums.sl3");
+    $client = "INETD" if $inetd_mode;
+
+    # get the string if available even in inetd / direct mode so local calles can
+    # identify themselves in the logs.
+    $client=$ENV{REMOTE_ADDR} if exists $ENV{REMOTE_ADDR};
+
+    &handle_connection;
+    exit 0;
+}
+
+my %daemonopts = (LocalPort => $$cfg{daemon_port}, Proto => 'tcp', Listen => 1, ReuseAddr => 1);
+$daemonopts{LocalAddr}=$$cfg{daemon_addr} if(defined($$cfg{daemon_addr}));
+
+while(1) {
+    $daemon = IO::Socket::INET->new(%daemonopts);
+    last if $daemon;
+    $retnum--;
+    last if($retnum<=0);
+    print STDERR "Unable to bind socket (port $$cfg{daemon_port}), trying again in 5 seconds.\n";
+    sleep 5;
+}
+die "Unable to bind socket (port $$cfg{daemon_port}), $0 not started.\n" if ! $daemon;
+
+$server_pid=$$;
+
+if($do_fork_away) {
+    my $pid = fork();
+    if ($pid < 0) {
+        barf("fork() failed");
+    }
+    if ($pid > 0) {
+        # parent
+        exit 0;
+    }
+}
+
+# STATE: Port open, still beeing root. Create pidfiles, logfiles, then su
+# 
+if($pidfile) {
+    open(my $fh, ">$pidfile");
+    print $fh $$;
+    close($fh);
+}
+
+
+&setup_ownership;
+&open_log_files;
+#optional checksumming support
+db_init("$$cfg{cache_dir}/md5sums.sl3");
+
+# State: READY
+# That is the working condition (daemon mode)
+
+debug_message("Apt-Cacher started with Debug output enabled, accepting connections...");
+
+while (1)
+{
+    my $newcon = $daemon->accept;
+    # we don't stop, only by term_handler since the accept method is unreliable
+    next if(!$newcon);
+    last if $terminating;
+
+    $client = $newcon->peerhost;
+    debug_message("Connection from $client");
+
+    my $pid = fork();
+    if ($pid < 0) {
+        barf("fork() failed");
+    }
+
+    if ($pid > 0) {
+        # parent
+        debug_message("registred child process: $pid");
+        $childPids{$pid}=1;
+        next;
+    }
+    # child
+    undef %childPids;
+
+    &handle_connection($newcon);
+    exit (0);
+
+}
+exit 0;
+# exit from the daemon loop
+
+
+
+sub handle_connection {
+    # now begin connection's personal stuff
+    debug_message("New HTTP connection open");
+    
+    if($direct_mode) {
+        # beeing in forced mode, ie. manual call
+        $source=*STDIN;
+        $con = *STDOUT;
+    }
+    else {
+
+        # serving a network client
+        
+        $con = shift;
+        $source = $con;
+    }
+    
+
+    if(!$inetd_mode) {
+        # ----------------------------------------------------------------------------
+        # Let's do some security checking. We only want to respond to clients within an
+        # authorised address range (127.0.0.1 and ::1 are always allowed).
+
+        my $ip_pass = 1;
+        my $ip_fail = 0;
+        my $clientaddr;
+
+        # allowed_hosts == '*' means allow all ('' means deny all)
+        # denied_hosts == '' means don't explicitly deny any
+        # localhost is always accepted
+        # otherwise host must be in allowed list and not in denied list to be accepted
+
+        if ($client =~ /:/) # IPv6?
+        {
+            defined ($clientaddr = ipv6_normalise ($client)) or goto badaddr;
+            if (substr ($clientaddr, 0, 12) eq "\0\0\0\0\0\0\0\0\0\0\xFF\xFF")
+            {
+                $clientaddr = substr ($clientaddr, 12);
+                goto is_ipv4;
+            }
+            elsif ($clientaddr eq "\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\1")
+            {
+                debug_message("client is localhost");
+            }
+            else
+            {
+                $ip_pass = ($$cfg{allowed_hosts_6} =~ /^\*?$/) ||
+                ipv6_addr_in_list ($clientaddr, 'allowed_hosts_6');
+                $ip_fail = ipv6_addr_in_list ($clientaddr, 'denied_hosts_6');
+            }
+        }
+        elsif (defined ($clientaddr = ipv4_normalise ($client))) # IPv4?
+        {
+            is_ipv4:
+            if ($clientaddr eq "\x7F\0\0\1")
+            {
+                debug_message("client is localhost");
+            }
+            else
+            {
+                $ip_pass = ($$cfg{allowed_hosts} =~ /^\*?$/) ||
+                ipv4_addr_in_list ($clientaddr, 'allowed_hosts');
+                $ip_fail = ipv4_addr_in_list ($clientaddr, 'denied_hosts');
+            }
+        }
+        else
+        {
+            goto badaddr;
+        }
+
+        # Now check if the client address falls within this range
+        if ($ip_pass && !$ip_fail)
+        {
+            # Everything's cool, client is in allowed range
+            debug_message("Client $client passed access control rules");
+        }
+#        elsif($client eq "local")
+#        {
+#            # Everything's cool, client is in allowed range
+#            debug_message("Client $client passed access control rules");
+#        }
+        else
+        {
+            # Bzzzt, client is outside allowed range. Send 'em a 403 and bail.
+            badaddr:
+            debug_message("Alert: client $client disallowed by access control");
+
+            &sendrsp(403, "Access to cache prohibited");
+            exit(4);
+        }
+
+    }
+
+    REQUEST:
+    while(!$concloseflag) {
+
+        my $testpath; # temporary, to be set by GET lines, undef on GO
+        my $ifmosince;# to be undef by new GET lines
+        my $send_head_only=0; # to be undef by new GET lines
+        my $tolerated_empty_lines=20;
+        my $rangereq;
+
+        # reading input line by line, trough the secure input method
+        CLIENTLINE: while(1) {
+
+            debug_message("Processing a new request line");
+
+            $_=&getRequestLine;
+            debug_message("got: $_");
+
+            exit if !defined($_);
+
+            if(/^$/) {
+                if(defined($testpath)) {
+                    # done reading request
+                    $path=$testpath;
+                    last CLIENTLINE;
+                }
+                elsif(!$tolerated_empty_lines)   {
+                    &sendrsp(403, "Go away");
+                    exit(4);
+                }
+                else {
+                    $tolerated_empty_lines--;
+                }
+            }
+            else {
+                if(/^(GET|HEAD)\s+(\S+)/) {
+                    if(defined($testpath)) {
+                        &sendrsp(403, "Confusing request");
+                        exit(4);
+                    }
+                    $testpath=$2;
+                    # also support pure HEAD calls
+                    if($1 eq 'HEAD') {
+                        $send_head_only=1;
+                    }
+                }
+                elsif(/^Connection: close/i) {
+                    $concloseflag=1;
+                }
+                elsif(/^Connection: .*TE/) {
+                    $concloseflag=1;
+                }
+                elsif(/^Range/i) {
+                    $rangereq=1;
+                }
+                elsif(/^If-Modified-Since:\s+(.*)/i) {
+                    $ifmosince=$1;
+                }
+                elsif(/^\S+: [^:]*/) {
+                    # whatever, but valid
+                }
+                else {
+                    &sendrsp(403, "Could not understand $_");
+                    exit(4);
+                }
+            }
+        }
+
+        # always resend the file if a part was requested since we don't support ranges
+        $ifmosince=0 if !$rangereq;
+
+        # tolerate CGI specific junk and two slashes in the beginning
+        $path =~ s!^/apt-cacher\??/!/!;
+        $path =~ s!^//!/!;
+        $path =~ s!^http://!!; # allow proxy style
+
+        # Now parse the path
+        if ($path =~ /^\/?report/) {
+            usage_report();
+            exit(0);
+        }
+
+        if ($path !~ m(^/?.+/.+)) {
+            usage_error();
+        }
+
+        REPARSE:
+        
+        my($host,$uri) = ($path =~ m#^/?([^/]+)(/.+)#);
+        
+        if ( !$host || !$uri ) {
+            usage_error();
+        }
+
+        ($filename) = ($uri =~ /\/?([^\/]+)$/);
+
+        if($$cfg{allowed_locations}) {
+            #         debug_message("Doing location check for ".$$cfg{allowed_locations} );
+            my $mess;
+            my $cleanuri=$uri;
+            $cleanuri=~s!/[^/]+/[\.]{2}/!/!g;
+            if ($host eq ".." ) {
+                $mess = "'..' contained in the hostname";
+            }
+            elsif ($cleanuri =~/\/\.\./) {
+                $mess = "File outside of the allowed path";
+            }
+            else {
+                for( split(/\s*,\s*/,$$cfg{allowed_locations}) ) {
+                    debug_message("Testing URI: $host$cleanuri on $_");
+                    goto location_allowed if ("$host$cleanuri" =~ /^$_/);
+                }
+                $mess = "Host '$host' is not configured in the allowed_locations directive";
+            }
+            badguy:
+            debug_message("$mess; access denied");
+            &sendrsp(403, "Access to cache prohibited, $mess");
+            exit(4);
+        }
+        location_allowed:
+
+        $do_import=0;
+        $is_index_file=0;
+
+        if ($filename =~ /(\.deb|\.rpm|\.dsc|\.tar\.gz|\.diff\.gz|\.udeb)$/) {
+            # We must be fetching a .deb or a .rpm, so let's cache it.
+            # Place the file in the cache with just its basename
+            $new_filename = $filename;
+            debug_message("new filename with just basename: $new_filename");
+        } 
+        elsif ($filename =~ /2\d\d\d-\d\d-\d\d.*\.gz$/) {
+            # a patch file. Needs a unique filename but no freshness checks
+            $new_filename = "$host$uri";
+            $new_filename =~ s/\//_/g;
+            debug_message("new long filename: $new_filename");
+        }
+        elsif ($filename =~ /$index_files_regexp/) {
+            $is_index_file=1;
+            # It's a Packages.gz or related file: make a long filename so we can cache these files without
+            # the names colliding
+            $new_filename = "$host$uri";
+            $new_filename =~ s/\//_/g;
+            debug_message("new long filename: $new_filename");
+            # optional checksumming support
+            if ($filename =~ /(Packages|Sources)/) {
+                # warning, an attacker could poison the checksum cache easily
+                $do_import=1;
+            }
+        } else {
+            # Maybe someone's trying to use us as a general purpose proxy / relay.
+            # Let's stomp on that now.
+            debug_message("Sorry, not allowed to fetch that type of file: $filename");
+            &sendrsp(403, "Sorry, not allowed to fetch that type of file: $filename");
+            exit(4);
+        }
+
+        $cached_file = "$$cfg{cache_dir}/packages/$new_filename";
+        $cached_head = "$$cfg{cache_dir}/headers/$new_filename";
+        $complete_file = "$private_dir/$new_filename.complete";
+        $notify_file = "$private_dir/$new_filename.notify";
+
+        my $force_download=0;
+
+        my $cache_status;
+
+        debug_message("looking for $cached_file");
+
+        if ($is_index_file) {
+            debug_message("known as index file: $filename");
+            # in offline mode, deliver it as-is, otherwise check freshness
+            if (-f $cached_file && -f $cached_head && !$$cfg{offline_mode}) {
+                if($$cfg{expire_hours} > 0) {
+                    my $now = time();
+                    my @stat = stat($cached_file);
+                    if (@stat && int(($now - $stat[9])/3600) > $$cfg{expire_hours}) {
+                        debug_message("unlinking $new_filename because it is too old");
+                        # Set the status to EXPIRED so the log file can show it was downloaded again
+                        $cache_status = "EXPIRED";
+                        debug_message("$cache_status");
+                        $force_download=1;
+                    }
+                }
+                else {
+                    # use HTTP timestamping
+                    my ($oldhead, $testfile, $newhead);
+                    my $response = &ua_act(1, $host, $uri);
+                    #my $response = $ua->head("http://$host$uri");
+                    $newhead = $response->header("Last-Modified");
+                    if($newhead && open($testfile, $cached_head)) {
+                        
+                        $newhead =~ s/\n|\r//g;
+
+                        for(<$testfile>){
+                            if(/^.*Last-Modified:\s(.*)(\r|\n)/) {
+                                $oldhead = $1;
+                                last
+                            }
+                        }
+                        close($testfile);
+                    }
+                    if($oldhead && ($oldhead eq $newhead) ) {
+                        # that's ok
+                        debug_message("remote file not changed, $oldhead vs. $newhead");
+                    }
+                    else {
+                        debug_message("unlinking $new_filename because it differs from server's version");
+                        $cache_status = "EXPIRED";
+                        debug_message("$cache_status");
+                        $force_download=1;
+                    }
+                }
+            }
+        }
+
+        # handle if-modified-since in a better way (check the equality of
+        # the time stamps). Do only if download not forced above.
+
+        if($ifmosince && !$force_download) {
+            $ifmosince=~s/\n|\r//g;
+
+            my $oldhead;
+            if(open(my $testfile, $cached_head)) {
+                LINE: for(<$testfile>){
+                    if(/^.*Last-Modified:\s(.*)(\r|\n)/) {
+                        $oldhead = $1;
+                        last LINE;
+                    }
+                }
+                close($testfile);
+            }
+
+            if($oldhead && $ifmosince eq $oldhead) {
+                &sendrsp(304, "Not Modified");
+                debug_message("File not changed: $ifmosince");
+                next REQUEST;
+            }
+        }
+
+        &set_global_lock(": file download decission"); # file state decissions, lock that area
+
+        my $fromfile; # handle for the reader
+
+        # download or not decission. Also releases the global lock
+        dl_check:
+        if( !$force_download && -e $cached_head && -e $cached_file) {
+            if (-f $complete_file) {
+                # not much to do if complete
+                $cache_status = "HIT";
+                debug_message("$cache_status");
+            }
+            else {
+                # a fetcher was either not successfull or is still running
+                # look for activity...
+                sysopen($fromfile, $cached_file, O_RDONLY) || undef $fromfile;
+                if (flock($fromfile, LOCK_EX|LOCK_NB)) {
+                    flock($fromfile, LOCK_UN);
+                    # bad, no fetcher working on this package. Redownload it.
+                    close($fromfile); undef $fromfile;
+                    debug_message("no fetcher running, forcing download");
+                    $force_download=1;
+                    goto dl_check;
+                }
+            }
+
+            &release_global_lock;
+        }
+        else {
+            # bypass for offline mode, no forking, just report the "problem"
+            if($$cfg{offline_mode})
+            {
+                &sendrsp(503, "Apt-Cacher in Offline Mode");
+                next REQUEST;
+            }
+
+            # (re) download them
+            unlink($cached_file, $cached_head, $complete_file, $notify_file);
+            debug_message("file does not exist or so, creating it");
+            # Set the status to MISS so the log file can show it had to be downloaded
+            if(!defined($cache_status)) { # except on special presets from index file checks above
+                $cache_status = "MISS"; 
+                debug_message("$cache_status");
+            }
+
+            # the writer releases the global lock after opening the target file
+            my $pid = fork();
+            if ($pid < 0) {
+                barf("fork() failed");
+            }
+            if ($pid == 0) {
+                # child, the fetcher thread
+                undef %childPids;
+                sysopen($pkfd, $cached_file, O_RDWR|O_CREAT|O_EXCL, 0644) || barf("Unable to store files");
+                open ( $chfd, ">$cached_head");
+
+                if (flock($pkfd, LOCK_EX)) {
+                    # jump from the global lock to a lock on the target file
+                    &release_global_lock;
+
+                    &fetch_store ($host, $uri); 
+
+                    exit 0;
+                }
+                else {
+                    barf("Problem locking the target file!");
+                }
+                # child exiting above, so or so
+            }
+            # parent continues
+            $childPids{$pid}=1;
+            debug_message("registred child process: $pid");
+            # &release_global_lock; to be release by downloader thread, not here
+        }
+
+        debug_message("checks done, can return now");
+        my $ret = &return_file (\$fromfile, $send_head_only);
+        goto dl_check if $ret==2; # retry code
+        debug_message("Package sent");
+
+        # Write all the stuff to the log file
+        writeaccesslog("$cache_status", "$new_filename");
+        if(!$is_index_file && !check_sum($new_filename)) {
+            writeerrorlog("   ALARM!    Faulty package in local cache detected! Removing, to be replaced with the next download.");
+            unlink $cached_file;
+            exit(5);
+        }
+        
+    }
+
+}
+
+
+sub return_file {
+    # At this point the file is open, and it's either complete or somebody
+    # is fetching its contents
+
+    our ($ffref, $send_head_only) =@_;
+    my $fromfile=$$ffref;
+
+    my $header_printed=0;
+
+    data_init();
+    
+    my $abort_time = get_abort_time();
+
+    my $buf;
+
+    my $geslen=0;
+    my $curlen=0;
+    my $explen;
+
+    my $complete_found;
+
+    # needs to print the header first
+    CHUNK: while (1) {
+
+        #debug_message("Send loop iteration:");
+
+        if (time() > $abort_time) {
+            debug_message("abort (timeout)");
+            exit(4);
+        }
+
+        if(! $header_printed) {
+
+            # add this reader to the notification list before printing anything useful to the client
+            if(! -f $complete_file) { # there is no point if the package is already downloaded
+                open(my $nf, ">>$notify_file");
+                flock($nf, LOCK_EX);
+                print $nf "$$\n";
+                flock($nf, LOCK_UN);
+                close($nf);
+            }
+
+            my $headstring;
+            if(-s $cached_head) {
+                # header file seen, protect the reading 
+                &set_global_lock(": reading the header file");
+                if(! -f $cached_head) {
+                    # file removed while waiting for lock - download failure?!
+                    # start over, maybe spawning an own fetcher
+                    &release_global_lock;
+                    return 2;
+                    #goto dl_check;
+                }
+
+                open(my $in, $cached_head);
+                my $code=200;
+                my $msg='';
+                my $headstring='';
+
+                $headstring=<$in>; # read exactly one status line
+
+                ($code, $msg) = ($headstring=~/^HTTP\S+\s+(\d+)\s(.*)/);
+                # alternative for critical errors
+                if(!defined($code)) {
+                    ($code, $msg) = ($headstring=~/^(5\d\d)\s(.*)/);
+                }
+
+                if(!defined($code)) {
+                    writeerrorlog("Faulty header file detected: $cached_head, first line was: $headstring");
+                    unlink $cached_head;
+                    exit 3;
+                }
+
+                # in CGI mode, use alternative status line. Don't print one
+                # for normal data output (apache does not like that) but on
+                # anormal codes, and then exit immediately
+                if($cgi_mode) {
+                    # don't print the head line but a Status on errors instead
+                    $headstring=~s/^HTTP\S+/Status:/;
+                    if($code == 200) {
+                        $headstring=''; # kick headline by default
+                    }
+                    else {
+                        print $con $headstring."\n\n";
+                        exit 1;
+                    }
+                }
+
+                # keep alive or not? Just follow the client
+                $headstring .= "Connection: ".($concloseflag?"Close":"Keep-Alive")."\r\n";
+
+                # keep only parts interesting for apt
+                if($code==200) {
+                    for(<$in>) {
+                        if(/^Last-Modified|Content|Accept/) {
+                            $headstring.=$_;
+                            if(/^Content-Length:\ *(\d+)/) {
+                                $explen=$1;
+                            }
+                        }
+                    }
+                }
+                close($in);
+                &release_global_lock;
+
+                print $con $headstring."\r\n";
+
+                $header_printed=1;
+                debug_message("Header sent: $headstring");
+
+                # Stop after sending the header with errors
+                return if($code != 200); 
+
+            }
+            else {
+                sleep(0.5);
+                next CHUNK;
+            }
+
+            # pure HEAD request, we are done
+            return if $send_head_only;
+            debug_message("ready to send contents of $cached_file");
+        }
+
+        if(! $fromfile) # is the data file open already? open in this iteration if needed
+        {
+            debug_message("opening file first: $cached_file");
+            if( ! -f $cached_file) {
+                sleep(1);
+                next CHUNK;
+            }
+
+            sysopen($fromfile, $cached_file, O_RDONLY); #FIXME, checken
+            next CHUNK;
+        }
+        else
+        {
+            my $n=0;
+            $n = sysread($fromfile, $buf, 65536);
+            debug_message("read $n bytes");
+
+            if(!defined($n)) {
+                debug_message("Error detected, closing connection");
+                exit(4);
+            }
+            
+            if($n==0) {
+                
+                if($complete_found) { # comlete file was found in the previous iteration
+                    # this is the loop exit condition
+                    # 
+                    # some extra error cases
+                    #if($explen && $curlen != $explen) {
+                    #    writeerrorlog("  ALARM!   $cached_file file is smaller than expected ($explen). Renaming to $cached_file.corrupted for further investigation, check your filesystem!");
+                    #    unlink "$cached_file.corrupted";
+                    #    rename($cached_file, "$cached_file.corrupted");
+                    #    exit(5);
+                    #}
+                    last CHUNK;
+                }
+
+                if (-f $complete_file) {
+                    # do another iteration, may need to read remaining data
+                    debug_message("complete file found");
+                    $complete_found=1;
+                    next CHUNK;
+                }
+
+                #debug_message("waiting for new data");
+                # wait for fresh data
+                sleep(0.5);
+                next CHUNK;
+
+            }
+            else {
+                $curlen+=$n;
+                if($explen && $curlen > $explen) {
+                    writeerrorlog("  ALARM!   $cached_file file is larger than expected ($explen). Renaming to $cached_file.corrupted for further investigation, check your filesystem!");
+                    unlink "$cached_file.corrupted";
+                    rename($cached_file, "$cached_file.corrupted");
+                    exit(5);
+                }
+                #debug_message("write $n / $curlen bytes");
+                # send data and update watchdog
+                print $con $buf;
+                debug_message("wrote $n (sum: $curlen) bytes");
+                $abort_time = get_abort_time();
+                data_feed(\$buf);
+            }
+        }
+    }
+}
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+sub barf {
+	my $errs = shift;
+
+	die "--- $0: Fatal: $errs\n";
+}
+
+sub usage_error {
+    &open_log_files;
+	writeerrorlog("--- $0: Usage error");
+
+    if(! defined($$cfg{example_sources_line})) {
+        $$cfg{example_sources_line}="deb&nbsp;http://<b>yourcache.example.com:$$cfg{daemon_port}/</b>ftp.au.debian.org/debian&nbsp;unstable&nbsp;main&nbsp;contrib&nbsp;non-free";
+    }
+
+    &sendrsp(200, "OK", "Content-Type", "text/html", "Expires", 0);
+	print $con <<EOF;
+
+<html>
+<title>Apt-cacher version $version
+</title><style type="text/css"><!--
+a { text-decoration: none; }
+a:hover { text-decoration: underline; }
+h1 { font-family: arial, helvetica, sans-serif; font-size: 18pt; font-weight: bold;}
+h2 { font-family: arial, helvetica, sans-serif; font-size: 14pt; font-weight: bold;}
+body, td { font-family: arial, helvetica, sans-serif; font-size: 10pt; }
+th { font-family: arial, helvetica, sans-serif; font-size: 11pt; font-weight: bold; }
+//--></style>
+</head>
+<body>
+<p>
+<table border=0 cellpadding=8 cellspacing=1 bgcolor="#000000" align="center" width="600">
+<tr bgcolor="#9999cc"><td> <h1>Apt-cacher version $version</h1> </td></tr>
+<tr bgcolor="#cccccc"><td>
+Usage: edit your /etc/apt/sources.list so all your HTTP sources are prepended 
+with the address of your apt-cacher machine and the port, like this:
+<blockquote>deb&nbsp;http://ftp.au.debian.org/debian&nbsp;unstable&nbsp;main&nbsp;contrib&nbsp;non-free</blockquote>
+becomes
+<blockquote>$$cfg{example_sources_line}</blockquote>
+</td></tr>
+</table>
+
+<h2 align="center">config values</h2>
+<table border=0 cellpadding=3 cellspacing=1 bgcolor="#000000" align="center">
+<tr bgcolor="#9999cc"><th> Directive </th><th> Value </th></tr>
+<tr bgcolor="#cccccc"><td bgcolor="#ccccff"> configfile </td><td> $configfile </td></tr>
+<tr bgcolor="#cccccc"><td bgcolor="#ccccff"> admin_email </td><td> <a href="mailto:$$cfg{admin_email}">$$cfg{admin_email}</a> </td></tr>
+<tr bgcolor="#cccccc"><td bgcolor="#ccccff"> generate_reports </td><td> $$cfg{generate_reports} </td></tr>
+<tr bgcolor="#cccccc"><td bgcolor="#ccccff"> cache_dir </td><td> $$cfg{cache_dir} </td></tr>
+<tr bgcolor="#cccccc"><td bgcolor="#ccccff"> logfile </td><td> $$cfg{logfile} </td></tr>
+<tr bgcolor="#cccccc"><td bgcolor="#ccccff"> errorfile </td><td> $$cfg{errorfile} </td></tr>
+<tr bgcolor="#cccccc"><td bgcolor="#ccccff"> expire_hours </td><td> $$cfg{expire_hours} </td></tr>
+<tr bgcolor="#cccccc"><td bgcolor="#ccccff"> http_proxy </td><td> $$cfg{http_proxy} </td></tr>
+<tr bgcolor="#cccccc"><td bgcolor="#ccccff"> use_proxy </td><td> $$cfg{use_proxy} </td></tr>
+<tr bgcolor="#cccccc"><td bgcolor="#ccccff"> use_proxy_auth </td><td> $$cfg{use_proxy_auth} </td></tr>
+<tr bgcolor="#cccccc"><td bgcolor="#ccccff"> debug </td><td> $$cfg{debug} </td></tr>
+</table>
+
+<p>
+<h2 align="center">license</h2>
+<table border=0 cellpadding=8 cellspacing=1 bgcolor="#000000" align="center" width="600">
+<tr bgcolor="#cccccc"><td>
+<p>Apt-cacher is free software; you can redistribute it and/or modify it under the terms of the GNU General 
+Public License as published by the Free Software Foundation; either version 2 of the License, or (at your 
+option) any later version.
+
+<p>Apt-cacher is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the 
+implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public 
+License for more details.
+
+<p>A copy of the GNU General Public License is available as /usr/share/common-licenses/GPL in the Debian 
+GNU/Linux distribution or on the World Wide Web at http://www.gnu.org/copyleft/gpl.html. You can also 
+obtain it by writing to the Free Software Foundation, Inc., 59 Temple Place - Suite 330, Boston, MA 
+02111-1307, USA.
+</td></tr>
+</table>
+</body>
+</html>
+EOF
+
+    exit 1;
+
+}
+
+
+# Jon's extra stuff to write the event to a log file.
+sub writeaccesslog {
+    my $cache_status = shift;
+    my $new_filename = shift;
+
+    # The format is 'time|cache status (HIT, MISS or EXPIRED)|client IP address|file size|name of requested file'
+    my $time = localtime;
+    my ($dev,$ino,$mode,$nlink,$uid,$gid,$rdev,$size,$atime,$mtime,$ctime,$blksize,$blocks) = stat($cached_file);
+    my $file_length = 0;
+    $file_length+=$size if defined($size);
+
+    flock($aclog_fh, LOCK_EX);
+    print $aclog_fh "$time|$client|$cache_status|$file_length|$new_filename\n";
+    flock($aclog_fh, LOCK_UN);
+}
+
+# Jon's extra stuff to write errors to a log file.
+sub writeerrorlog {
+	my $message = shift;
+	
+	my $time = localtime;
+
+    flock($erlog_fh, LOCK_EX);
+    # files may need to be reopened sometimes - reason unknown yet, EBADF
+    # results
+	syswrite($erlog_fh,"$time|$client|$message\n") || &open_log_files;
+    flock($erlog_fh, LOCK_UN);
+}
+
+# Stuff to append debug messages to the error log.
+sub debug_message {
+    if ($$cfg{debug} eq 1) {
+        my $message = shift;
+        &writeerrorlog("debug [$$]: $message");
+    }
+}
+
+sub open_log_files {
+	if(!$erlog_fh)
+    {
+        open($erlog_fh,">>$$cfg{errorfile}") or barf("Unable to open $$cfg{errorfile}");
+    }
+    if(!$aclog_fh) {
+        open($aclog_fh,">>$$cfg{logfile}") or barf("Unable to open $$cfg{logfile}");
+    }
+}
+ 
+sub get_abort_time () {
+  return time () + $$cfg{fetch_timeout}; # five minutes from now
+}
+
+my $header_stored=0;
+
+my $tstart;
+my $geslen;
+
+sub get_callback {
+    my $errors=0;
+
+    my ($data, $response, $proto) = @_;
+#    debug_message("Callback got data\n");
+    if(!$header_stored) {
+        $header_stored=1;
+        my $headstring = $response->as_string;
+
+        # print $con $headstring;
+        
+        &set_global_lock(": Callback, storing the header"); # set the lock before writting the first byte to that file, and release it after the file is closed
+        (scalar print $chfd $headstring ) || $errors++;
+        close($chfd);
+        &release_global_lock;
+
+        if($maxspeed) {
+            $geslen=-$getBufLen; # will be re-added below
+            $tstart = [gettimeofday];
+        }
+
+    }
+    (scalar print $pkfd $data ) || $errors++;
+    #print $con $data;
+
+    data_feed(\$data);
+
+    # delay for rate limiting
+    if($maxspeed) {
+        $geslen+=$getBufLen;
+        my $delta= $geslen/$maxspeed - ( scalar tv_interval ( $tstart ));
+        sleep($delta) if ($delta > 0);
+    }
+
+    if($errors) {
+        writeerrorlog("Write error. Disk full?");
+        # don't just exit here, fetcher needs to handle that
+        die();
+    }
+}
+
+sub fetch_store {
+
+    my ($host, $uri) = @_;
+
+    my $url = "http://$host$uri";
+    debug_message("fetcher: try to fetch $url");
+
+    # for checksumming
+    data_init();
+
+    my $response = &ua_act(0, $host, $uri);
+    #my $response = $ua->get($url, ':content_cb' => \&get_callback, ':read_size_hint' => $getBufLen);
+    #$geslen=0;
+
+    debug_message("Get is back");
+
+    if ($response->is_success && !defined($response->header("X-Died")) )
+    {
+
+        close($pkfd) if $pkfd;
+        undef $pkfd;
+
+        debug_message("stored $url as $cached_file");
+
+        # check missmatch or fetcher failure, could not connect the server
+        if( !$is_index_file && !check_sum($new_filename)) {
+            &set_global_lock(": file corruption report");
+            writeerrorlog("Do00h, checksum mismatch on $new_filename");
+            unlink $cached_file, $cached_head;
+            open(MF, ">$cached_head");
+            print MF "HTTP/1.1 502 Data corruption";
+            close(MF);
+            &kill_readers;
+            &release_global_lock;
+        }
+
+        # assuming here that the filesystem really closes the file and writes
+        # it out to disk before creating the complete flag file
+        
+        debug_message("setting complete flag for $new_filename");
+        # Now create the file to show the pickup is complete, also store the original URL there
+        open(MF, ">$private_dir/$new_filename.complete");
+        print MF $path;
+        close(MF); 
+
+        # index file seen? Get checksums
+        import_sums($cached_file) if $do_import;
+        
+        # store the sum, it may be not available yet but better this one than
+        # nothing. 
+        # disabled for now store_sum($new_filename);
+        # The sum may change on index files but that case is handled
+        # separately, the stored sum is allowed to differ from the data
+        # contents.
+
+    }
+    else
+    {
+        if(defined($response->header("X-Died"))) {
+            $response->code(502);
+            $response->message("Apt-Cacher: Transfer terminated");
+        }
+
+        debug_message("Reporting error: ".$response->code);
+        &set_global_lock(": HTTP error report");
+        open(my $ch, $cached_head);
+        my $headstring = $response->as_string;
+        if($headstring=~/^5\d\d/) { 
+            # work around LWP bug, incorrect status line with internal messages
+            $headstring = "HTTP/1.1 $headstring";
+        }
+        print $chfd $headstring;
+        close($chfd);
+        &release_global_lock;
+        if(defined($response->header("X-Died"))) { # was critical, most likely frozen now
+            &kill_readers;
+        }
+    }
+
+    debug_message("fetcher exiting");
+    unlink $notify_file;
+
+    # reset the shared vars
+    $header_stored=0; # FIXME, really needed? fetcher thread runs only once
+
+    _exit(0);
+}
+
+# FIXME: that sucks. Still needed?!
+sub kill_readers {
+    my $nf;
+    if(open($nf, $notify_file)) {
+        while(<$nf>) {
+            chomp;
+        debug_message("Stopping reader: $_");
+               kill 9, $_; # hard, bypassing the handler
+        }
+        close($nf);
+    }
+    # should be okay to unlink the file after all readers are "notified"
+    unlink $cached_file;
+}
+
+
+# Check if there has been a usage report generated and display it
+sub usage_report {
+	my $usage_file = "$$cfg{logdir}/report.html";
+    &sendrsp(200, "OK", "Content-Type", "text/html", "Expires", 0);
+	if (!-f $usage_file) {
+		print $con <<EOF;
+
+<html>
+<title>Apt-cacher traffic report</title><style type="text/css"><!--
+a { text-decoration: none; }
+a:hover { text-decoration: underline; }
+h1 { font-family: arial, helvetica, sans-serif; font-size: 18pt; font-weight: bold;}
+h2 { font-family: arial, helvetica, sans-serif; font-size: 14pt; font-weight: bold;}
+body, td { font-family: arial, helvetica, sans-serif; font-size: 10pt; }
+th { font-family: arial, helvetica, sans-serif; font-size: 11pt; font-weight: bold; }
+//--></style>
+</head>
+<body>
+<table border=0 cellpadding=8 cellspacing=1 bgcolor="#000000" align="center" width="600">
+<tr bgcolor="#9999cc"><td> <h1>Apt-cacher traffic report</h1> </td></tr>
+</td></tr>
+</table>
+		
+<p><table border=0 cellpadding=3 cellspacing=1 bgcolor="#000000" align="center" width="600">
+<tr bgcolor="#9999cc"><th bgcolor="#9999cc"> An Apt-cacher usage report has not yet been generated </th></tr>
+<tr bgcolor="#cccccc"><td bgcolor="#ccccff"> Reports are generated every 24 hours. If you want reports to be generated, make sure you set '<b>generate_reports=1</b>' in <b>$configfile</b>.</td></tr>
+</table>
+		</body>
+		</html>
+EOF
+
+	}
+	else
+	{
+        open(my $usefile, $usage_file);
+        my @usedata = <$usefile>;
+        close($usefile);
+        print $con @usedata;
+	}
+}
+
+# IP address filtering.
+sub ipv4_addr_in_list ($$)
+{
+	return 0 if $_[0] eq '';
+	debug_message ("testing $_[1]");
+	return 0 unless $$cfg{$_[1]};
+
+	my ($client, $cfitem) = @_;
+	my @allowed_hosts = split(/,\s*/, $$cfg{$cfitem});
+	for my $ahp (@allowed_hosts)
+	{
+		goto unknown if $ahp !~ /^[-\/,.[:digit:]]+$/;
+
+		# single host
+		if ($ahp =~ /^([^-\/]*)$/)
+		{
+			my $ip = $1;
+			debug_message("checking against $ip");
+			defined ($ip = ipv4_normalise($ip)) or goto unknown;
+			return 1 if $ip eq $client;
+		}
+		# range of hosts (netmask)
+		elsif ($ahp =~ /^([^-\/]*)\/([^-\/]*)$/)
+		{
+			my ($base, $mask) = ($1, $2);
+			debug_message("checking against $ahp");
+			defined ($base = ipv4_normalise($base)) or goto unknown;
+			$mask = ($mask =~ /^\d+$/) ? make_mask ($mask, 32)
+																 : ipv4_normalise ($mask);
+			goto unknown unless defined $mask;
+			return 1 if ($client & $mask) eq ($base & $mask);
+		}
+		# range of hosts (start & end)
+		elsif ($ahp =~ /^([^-\/]*)-([^-\/]*)$/)
+		{
+			my ($start, $end) = ($1, $2);
+			debug_message("checking against $start to $end");
+			defined ($start = ipv4_normalise($start)) or goto unknown;
+			defined ($end = ipv4_normalise($end)) or goto unknown;
+			return 1 if $client ge $start && $client le $end;
+		}
+		# unknown
+		else
+		{
+			unknown:
+			debug_message("Alert: $cfitem ($ahp) is bad");
+			&sendrsp(500, "Configuration error");
+			exit(4);
+		}
+	}
+	return 0; # failed
+}
+
+sub ipv6_addr_in_list ($$)
+{
+	return 0 if $_[0] eq '';
+	debug_message ("testing $_[1]");
+	return 0 unless $$cfg{$_[1]};
+
+	my ($client, $cfitem) = @_;
+	my @allowed_hosts = split(/,\s*/, $$cfg{$cfitem});
+	for my $ahp (@allowed_hosts)
+	{
+		goto unknown if $ahp !~ /^[-\/,:[:xdigit:]]+$/;
+
+		# single host
+		if ($ahp =~ /^([^-\/]*)$/)
+		{
+			my $ip = $1;
+			debug_message("checking against $ip");
+			$ip = ipv6_normalise($ip);
+			goto unknown if $ip eq '';
+			return 1 if $ip eq $client;
+		}
+		# range of hosts (netmask)
+		elsif ($ahp =~ /^([^-\/]*)\/([^-\/]*)$/)
+		{
+			my ($base, $mask) = ($1, $2);
+			debug_message("checking against $ahp");
+			$base = ipv6_normalise($base);
+			goto unknown if $base eq '';
+			goto unknown if $mask !~ /^\d+$/ || $mask < 0 || $mask > 128;
+			my $m = ("\xFF" x ($mask / 8));
+			$m .= chr ((-1 << (8 - $mask % 8)) & 255) if $mask % 8;
+			$mask = $m . ("\0" x (16 - length ($m)));
+			return 1 if ($client & $mask) eq ($base & $mask);
+		}
+		# range of hosts (start & end)
+		elsif ($ahp =~ /^([^-\/]*)-([^-\/]*)$/)
+		{
+			my ($start, $end) = ($1, $2);
+			debug_message("checking against $start to $end");
+			$start = ipv6_normalise($start);
+			$end = ipv6_normalise($end);
+			goto unknown if $start eq '' || $end eq '';
+			return 1 if $client ge $start && $client le $end;
+		}
+		# unknown
+		else
+		{
+			unknown:
+			debug_message("Alert: $cfitem ($ahp) is bad");
+            &sendrsp(500, "Configuration error");
+			exit(4);
+		}
+	}
+	return 0; # failed
+}
+
+sub sendrsp {
+    my $code=shift;
+    my $msg=shift;
+    $msg="" if !defined($msg);
+    
+    my $initmsg=
+    $cgi_mode ? 
+    "Status: $code $msg\r\n" :
+    "HTTP/1.1 $code $msg\r\n";
+    
+    $initmsg.="Connection: Keep-Alive\r\nAccept-Ranges: bytes\r\nKeep-Alive: timeout=15, max=100\r\n" if ($code ne 403);
+
+    #debug_message("Sending Response: $initmsg");
+    print $con $initmsg;
+
+    my $altbit=0;
+    for(@_) {
+        $altbit=!$altbit;
+        if($altbit) {
+            #debug_message("$_: ");
+            print $con $_.": ";
+        }
+        else {
+            #debug_message($_."\r\n);
+            print $con $_."\r\n";
+        }
+    }
+    print $con "\r\n";
+
+}
+
+# DOS attack safe input reader
+my @reqLineBuf;
+my $reqTail;
+sub getRequestLine {
+    if($cgi_path) { 
+        push(@reqLineBuf, "GET $cgi_path", "", undef); # undef stops operation
+        undef $cgi_path; # don't re-add it
+    }
+    if(! @reqLineBuf) {
+        my $buf="";
+
+        # after every read at least one line MUST have been found. Read length
+        # is large enough.
+
+        my $n=sysread($source, $buf, 1024);
+        $buf=$reqTail.$buf if(defined($reqTail));
+        undef $reqTail;
+
+        # pushes the lines found into the buffer. The last one may be incomplete,
+        # extra handling below
+        push(@reqLineBuf, split(/\r\n/, $buf, 1000) );
+
+        # buf did not end in a line terminator so the last line is an incomplete
+        # chunk. Does also work if \r and \n are separated
+        if(substr($buf, -2) ne "\r\n") {
+            $reqTail=pop(@reqLineBuf);
+        }
+    }
+    return shift(@reqLineBuf);
+}
+
+# runs the get or head operations on the user agent
+sub ua_act {
+    my ($only_head, $vhost, $uri) = @_;
+
+    my $url="http://$vhost$uri";
+    
+    &setup_agent;
+
+    my $do_hopping = (exists $pathmap{$vhost});
+
+    my $response;
+    my $hostcand;
+
+    RETRY_ACTION:
+
+    # make the virtual hosts real. The list is reduced which is not so smart,
+    # but since the fetcher process dies anyway it does not matter.
+    if($do_hopping) {
+        $hostcand = shift(@{$pathmap{$vhost}});
+        debug_message("Candidate: $hostcand");
+        $url=($hostcand =~ /^http:/?"" : "http://").$hostcand.$uri;
+        #$url="http://$hostcand$uri";
+        #$url="$hostcand$uri" if not $hostcand =~ /:\/\//;
+    }
+
+    debug_message("download agent: getting $url");
+    
+    if($only_head) {
+        $response = $ua->head($url);
+    }
+    else {
+        $response = $ua->get($url, ':content_cb' => \&get_callback, ':read_size_hint' => $getBufLen);
+    }
+
+    if($do_hopping) {
+        # if okay or the last candidate failes, put it back into the list
+        if($response->is_success || ! @{$pathmap{$vhost}} ) { 
+            unshift(@{$pathmap{$vhost}}, $hostcand);
+        }
+        else {
+            goto RETRY_ACTION;
+        }
+    }
+
+    return $response;
+}
+
+
+sub setup_ownership {
+    my $uid=$$cfg{user};
+    my $gid=$$cfg{group};
+
+    if($chroot) {
+        if($uid || $gid) {
+            # open them now, before it is too late
+            # FIXME: reopening won't work, but the lose of file handles needs to be
+            # made reproducible first
+            &open_log_files;
+        }
+        chroot $chroot || die "Unable to chroot, aborting.\n";
+        chdir $chroot;
+    }
+
+    if($gid) {
+        if($gid=~/^\d+$/) {
+            my $name=getgrgid($gid);
+            die "Unknown group ID: $gid (exiting)\n" if !$name;
+        }
+        else {
+            $gid=getgrnam($gid);
+            die "No such group (exiting)\n" if !defined($gid);
+        }
+        $) = $gid;
+        $( = $gid;
+        $) =~ /^$gid\b/ && $( =~ /^$gid\b/ || barf("Unable to change group id");
+    }
+
+    if($uid) {
+        if($uid=~/^\d+$/) {
+            my $name=getpwuid($uid);
+            die "Unknown user ID: $uid (exiting)\n" if !$name;
+        }
+        else {
+            $uid=getpwnam($uid);
+            die "No such user (exiting)\n" if !defined($uid);
+        }
+        $> = $uid;
+        $< = $uid;
+        $> == $uid && $< == $uid || barf("Unable to change user id");
+    }
+}
diff -r 9ce9101b3e6b binary-overlay.xenrt/usr/share/apt-cacher/apt-cacher
--- /dev/null	Thu Jan 01 00:00:00 1970 +0000
+++ b/binary-overlay.xenrt/usr/share/apt-cacher/apt-cacher	Fri Mar 14 11:52:03 2008 +0000
@@ -0,0 +1,1648 @@
+#!/usr/bin/perl
+
+=head1 NAME
+
+ apt-cacher2 - WWW proxy optimized for use with APT
+
+ Copyright (C) 2005 Eduard Bloch <blade@debian.org>
+ Distributed under the terms of the GNU Public Licence (GPL).
+
+=head1 SYNOPSIS
+
+ ./setup.pl /home/me/cache
+ edit /etc/apt/sources.list (use sources like deb http://proxy:3142/archiveserver/debian ...)
+ apt-get update
+ apt-get -u upgrade
+
+=head1 DESCRIPTION
+
+If you have two or more Debian GNU/Linux machines on a fast local
+network and you wish to upgrade packages from the Internet, you
+don't want to download every package several times.
+
+apt-cacher2 is a tiny HTTP proxy that keeps a cache on disk of Debian
+binary/source packages and meta files which have been received from Debian
+distribution servers on the Internet. When an apt-get client issues
+a request for a file to apt-cacher2, if the file is already on disk
+it is served to the client immediately, otherwise it is fetched from the
+Internet and served to the client while a copy is beeing stored on the disk.
+This means that several Debian machines can be upgraded but each package needs
+to be downloaded only once.
+
+apt-cacher2 is a rewrite of the original apt-cacher.pl CGI script, keeping
+compatibility in mind. The cached data can be shared by the both
+implementations, while apt-cacher2 providers better performance and less server
+load.
+
+=head1 INSTALLATION
+
+Assuming your cache server is called B<www.myserver.com>
+and your cache directory is called B</home/me/cache>, then:
+
+1. Edit apt-cacher.conf to customize your settings
+
+2. Run apt-cacher2
+
+=cut
+# ----------------------------------------------------------------------------
+
+use strict;
+#use warnings;
+
+use Fcntl ':flock';
+use POSIX;
+
+use LWP::UserAgent;
+use IO::Socket::INET;
+use HTTP::Response;
+
+use Time::HiRes qw( sleep gettimeofday tv_interval );
+
+
+my @index_files = (
+    'Index',
+	'Packages.gz',
+	'Packages.bz2',
+	'Release',
+	'Release.gpg',
+	'Sources.gz',
+	'Sources.bz2',
+	'Contents-.+\.gz',
+    'pkglist.*\.bz2',
+    'release$',
+    'release\..*',
+    'srclist.*\.bz2'
+);
+my $index_files_regexp = '(' . join('|', @index_files) . ')$';
+
+
+# Include the library for the config file parser
+require '/usr/share/apt-cacher/apt-cacher-lib.pl';
+require '/etc/apt-cacher/checksumming.conf';
+
+
+# Set some defaults
+my $version='0.1'; # this will be auto-replaced when the Debian package is beeing built
+my $configfile_default = '/etc/apt-cacher/apt-cacher.conf';
+my $daemon_port_default=3142;
+my $client="local";
+
+# Read in the config file and set the necessary variables
+my $configfile = $configfile_default;
+
+my $direct_mode; # defines using STDIN/STDOUT
+my $inetd_mode; # no security checks
+my $cgi_mode;
+my $cgi_path;
+
+my $cfg;
+
+my $pidfile;
+my @extraconfig;
+
+my $chroot;
+my $retnum;
+my $do_fork_away;
+
+# this script needs to be executed trough a CGI wrapper setting a flag variable
+if($ENV{CGI_MODE})
+{
+    # yahoo, back to the roots, assume beeing in CGI mode
+    $cgi_mode=1;
+    $direct_mode=1;
+    # pick up the URL
+    $cgi_path=$ENV{PATH_INFO} if ! $cgi_path;
+    $cgi_path=$ENV{QUERY_STRING} if ! $cgi_path;
+    $cgi_path="/" if ! $cgi_path; # set an invalid path to display infos below
+}
+else {
+    while(scalar @ARGV) {
+
+        my $arg=shift(@ARGV);
+
+        if($arg eq "-c") {
+            $configfile=shift(@ARGV);
+            die "$configfile unreadable" if ! -r $configfile;
+        }
+        elsif($arg eq "-r") {
+            $chroot=shift(@ARGV);
+            die "No such directory: $chroot\n" if ! -d $chroot;
+        }
+        elsif($arg eq "-R") {
+            $retnum=shift(@ARGV);
+        }
+        elsif($arg eq "-i") {
+            $inetd_mode=1;
+            $direct_mode=1;
+        }
+        elsif($arg eq "-d") {
+            $do_fork_away=1;
+        }
+        elsif($arg eq "-p") {
+            $pidfile=shift(@ARGV);
+        }
+        elsif($arg=~/(\S+)=(\S+)/) {
+            push(@extraconfig, $1, $2);
+        }
+        elsif($arg eq "-h" || $arg eq "--help") {
+            print <<EOM;
+USAGE: $0 <options> <override(s)>
+Options:
+
+-c configfile   Custom config file (default: $configfile_default)
+-i              Inetd mode, STDIN and STDOUT are used for service
+(default: standalone server mode)
+-d              become a background daemon
+
+Advanced options (root only):
+-r directory    (experimental option) 
+                path to chroot to after reading the config and opening the log
+                files. cache directory setting must be relative to the new root.
+                WARNING: log files should be created before and be owned by tne
+                effective user/group if -g or -u are used
+-p pidfile      write the server process ID into this file
+
+Overrides:     override config variables (see config file), eg. daemon_port=9999
+
+EOM
+            exit(0);
+        }
+        else {
+            die "Unknown parameter $arg\n";
+        }
+    }
+}
+
+eval {
+        $cfg = read_config($configfile);
+};
+
+# not sure what to do if we can't read the config file...
+die "Could not read config file: $@" if $@;
+
+# Now set some things from the config file
+# $logfile used to be set in the config file: now we derive it from $logdir
+$$cfg{logfile} = "$$cfg{logdir}/access.log";
+
+# $errorfile used to be set in the config file: now we derive it from $logdir
+$$cfg{errorfile} = "$$cfg{logdir}/error.log";
+
+$$cfg{fetch_timeout}=300; # five minutes from now
+
+my $private_dir = "$$cfg{cache_dir}/private";
+define_global_lockfile("$private_dir/exlock");
+
+# override config values with the user-specified parameters
+while(@extraconfig) { 
+    my $k=shift(@extraconfig);
+    my $v=shift(@extraconfig); 
+    $$cfg{$k}=$v;
+}
+
+
+my ($aclog_fh, $erlog_fh);
+#FIXME: genauer die Scopes betrachten
+my ($path, $filename, $new_filename, $con, $source);
+
+my %pathmap;
+
+if($$cfg{path_map}) {
+    for(split(/\s*;\s*/, $$cfg{path_map})) {
+        my @tmp = split(/\s+/, $_);
+        # must have at least one path and target
+        next if ($#tmp < 1);
+        my $key=shift(@tmp);
+        $pathmap{$key}=[@tmp];
+    }
+}
+
+
+# Output data as soon as we print it
+$| = 1;
+
+# Function prototypes
+sub ipv4_addr_in_list ($$);
+sub ipv6_addr_in_list ($$);
+sub get_abort_time ();
+
+# ----------------------------------------------------------------------------
+# Die if we have not been configured correctly
+die "$0: No cache_dir directory!\n" if (!-d $$cfg{cache_dir});
+die "$0: No cache_dir/private directory!\n" if (!-d $private_dir);
+
+# ----------------------------------------------------------------------------
+# Data shared between functions
+
+my $cached_file;
+my $cached_head;
+my $complete_file;
+my $notify_file;
+
+my $do_import=0;
+my $concloseflag;
+my $is_index_file;
+
+my $ua;
+my $daemon;
+my $server_pid;
+my $fetcher_pid;
+my %childPids;
+my $terminating;
+
+sub term_handler {
+    $terminating=1;
+
+    # close all connections or shutdown the server if parent and kill 
+    debug_message("received SIGTERM, terminating");
+    $con->close if defined($con);
+
+    
+    if($server_pid && $server_pid == $$) {
+        $daemon->shutdown(2);
+    }
+
+    # stop all children
+    #{ doesn't work, signal comes delayed. Why?!
+    #    local $SIG{"TERM"} = 'IGNORE';          
+    #    kill("TERM", -$$);
+    #}
+    for(keys %childPids) { 
+        &debug_message("killing subprocess: $_"); 
+        kill 15, $_;
+    };
+    exit 0;
+};
+
+sub reload_config {
+    debug_message("Got SIGHUP, reloading config");
+    $cfg = read_config($configfile);
+};
+
+# broken, kills unrelated processes. Not using for now.
+# perlipc(1)
+# also remove them from the to-be-killed list
+#sub reap_children {
+#    my $child;
+#    while (($child = waitpid(-1,WNOHANG)) > 0) {
+#        delete $childPids{$child};
+#    }
+#    $SIG{CHLD} = \&reap_children;  # still loathe sysV
+#
+#}
+#$SIG{CHLD} = \&reap_children;
+$SIG{CHLD} = 'IGNORE';
+$SIG{'TERM'} = \&term_handler;
+$SIG{'HUP'} = \&reload_config;
+
+my $getBufLen=10000;
+my $maxspeed;
+
+my ($chfd, $pkfd);
+
+# for rate limit support
+if($$cfg{limit}>0) {
+    $maxspeed = $$cfg{limit}*1024;
+    $getBufLen = $maxspeed/20; # 20 portions per second should be enough
+}
+
+sub setup_agent {
+
+   return if(defined($ua));
+
+   $ua=LWP::UserAgent->new('keep_alive' => 1);
+
+   # Check whether a proxy is to be used, and set the appropriate environment variable
+   my $proxystring;
+   if ( $$cfg{use_proxy} eq 1 && $$cfg{http_proxy}) {
+       $proxystring="http://";
+       if ( $$cfg{use_proxy_auth} eq 1) {
+           $proxystring.=$$cfg{http_proxy_auth}.'@';
+       }
+       $proxystring.=$$cfg{http_proxy};
+   }
+   $ua->proxy("http", $proxystring) if $proxystring;
+}
+
+
+
+
+
+# BEGINN MAIN PART
+
+if($cgi_mode && defined($$cfg{cgi_advise_to_use}) && $$cfg{cgi_advise_to_use}) {
+    print "Status: 410 $$cfg{cgi_advise_to_use}\r\n\r\n";
+    exit 0;
+}
+
+if($direct_mode) {
+    &setup_ownership;
+    &open_log_files;
+#optional checksumming support
+    db_init("$$cfg{cache_dir}/md5sums.sl3");
+    $client = "INETD" if $inetd_mode;
+
+    # get the string if available even in inetd / direct mode so local calles can
+    # identify themselves in the logs.
+    $client=$ENV{REMOTE_ADDR} if exists $ENV{REMOTE_ADDR};
+
+    &handle_connection;
+    exit 0;
+}
+
+my %daemonopts = (LocalPort => $$cfg{daemon_port}, Proto => 'tcp', Listen => 1, ReuseAddr => 1);
+$daemonopts{LocalAddr}=$$cfg{daemon_addr} if(defined($$cfg{daemon_addr}));
+
+while(1) {
+    $daemon = IO::Socket::INET->new(%daemonopts);
+    last if $daemon;
+    $retnum--;
+    last if($retnum<=0);
+    print STDERR "Unable to bind socket (port $$cfg{daemon_port}), trying again in 5 seconds.\n";
+    sleep 5;
+}
+die "Unable to bind socket (port $$cfg{daemon_port}), $0 not started.\n" if ! $daemon;
+
+$server_pid=$$;
+
+if($do_fork_away) {
+    my $pid = fork();
+    if ($pid < 0) {
+        barf("fork() failed");
+    }
+    if ($pid > 0) {
+        # parent
+        exit 0;
+    }
+}
+
+# STATE: Port open, still beeing root. Create pidfiles, logfiles, then su
+# 
+if($pidfile) {
+    open(my $fh, ">$pidfile");
+    print $fh $$;
+    close($fh);
+}
+
+
+&setup_ownership;
+&open_log_files;
+#optional checksumming support
+db_init("$$cfg{cache_dir}/md5sums.sl3");
+
+# State: READY
+# That is the working condition (daemon mode)
+
+debug_message("Apt-Cacher started with Debug output enabled, accepting connections...");
+
+while (1)
+{
+    my $newcon = $daemon->accept;
+    # we don't stop, only by term_handler since the accept method is unreliable
+    next if(!$newcon);
+    last if $terminating;
+
+    $client = $newcon->peerhost;
+    debug_message("Connection from $client");
+
+    my $pid = fork();
+    if ($pid < 0) {
+        barf("fork() failed");
+    }
+
+    if ($pid > 0) {
+        # parent
+        debug_message("registred child process: $pid");
+        $childPids{$pid}=1;
+        next;
+    }
+    # child
+    undef %childPids;
+
+    &handle_connection($newcon);
+    exit (0);
+
+}
+exit 0;
+# exit from the daemon loop
+
+
+
+sub handle_connection {
+    # now begin connection's personal stuff
+    debug_message("New HTTP connection open");
+    
+    if($direct_mode) {
+        # beeing in forced mode, ie. manual call
+        $source=*STDIN;
+        $con = *STDOUT;
+    }
+    else {
+
+        # serving a network client
+        
+        $con = shift;
+        $source = $con;
+    }
+    
+
+    if(!$inetd_mode) {
+        # ----------------------------------------------------------------------------
+        # Let's do some security checking. We only want to respond to clients within an
+        # authorised address range (127.0.0.1 and ::1 are always allowed).
+
+        my $ip_pass = 1;
+        my $ip_fail = 0;
+        my $clientaddr;
+
+        # allowed_hosts == '*' means allow all ('' means deny all)
+        # denied_hosts == '' means don't explicitly deny any
+        # localhost is always accepted
+        # otherwise host must be in allowed list and not in denied list to be accepted
+
+        if ($client =~ /:/) # IPv6?
+        {
+            defined ($clientaddr = ipv6_normalise ($client)) or goto badaddr;
+            if (substr ($clientaddr, 0, 12) eq "\0\0\0\0\0\0\0\0\0\0\xFF\xFF")
+            {
+                $clientaddr = substr ($clientaddr, 12);
+                goto is_ipv4;
+            }
+            elsif ($clientaddr eq "\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\1")
+            {
+                debug_message("client is localhost");
+            }
+            else
+            {
+                $ip_pass = ($$cfg{allowed_hosts_6} =~ /^\*?$/) ||
+                ipv6_addr_in_list ($clientaddr, 'allowed_hosts_6');
+                $ip_fail = ipv6_addr_in_list ($clientaddr, 'denied_hosts_6');
+            }
+        }
+        elsif (defined ($clientaddr = ipv4_normalise ($client))) # IPv4?
+        {
+            is_ipv4:
+            if ($clientaddr eq "\x7F\0\0\1")
+            {
+                debug_message("client is localhost");
+            }
+            else
+            {
+                $ip_pass = ($$cfg{allowed_hosts} =~ /^\*?$/) ||
+                ipv4_addr_in_list ($clientaddr, 'allowed_hosts');
+                $ip_fail = ipv4_addr_in_list ($clientaddr, 'denied_hosts');
+            }
+        }
+        else
+        {
+            goto badaddr;
+        }
+
+        # Now check if the client address falls within this range
+        if ($ip_pass && !$ip_fail)
+        {
+            # Everything's cool, client is in allowed range
+            debug_message("Client $client passed access control rules");
+        }
+#        elsif($client eq "local")
+#        {
+#            # Everything's cool, client is in allowed range
+#            debug_message("Client $client passed access control rules");
+#        }
+        else
+        {
+            # Bzzzt, client is outside allowed range. Send 'em a 403 and bail.
+            badaddr:
+            debug_message("Alert: client $client disallowed by access control");
+
+            &sendrsp(403, "Access to cache prohibited");
+            exit(4);
+        }
+
+    }
+
+    REQUEST:
+    while(!$concloseflag) {
+
+        my $testpath; # temporary, to be set by GET lines, undef on GO
+        my $ifmosince;# to be undef by new GET lines
+        my $send_head_only=0; # to be undef by new GET lines
+        my $tolerated_empty_lines=20;
+        my $rangereq;
+
+        # reading input line by line, trough the secure input method
+        CLIENTLINE: while(1) {
+
+            debug_message("Processing a new request line");
+
+            $_=&getRequestLine;
+            debug_message("got: $_");
+
+            exit if !defined($_);
+
+            if(/^$/) {
+                if(defined($testpath)) {
+                    # done reading request
+                    $path=$testpath;
+                    last CLIENTLINE;
+                }
+                elsif(!$tolerated_empty_lines)   {
+                    &sendrsp(403, "Go away");
+                    exit(4);
+                }
+                else {
+                    $tolerated_empty_lines--;
+                }
+            }
+            else {
+                if(/^(GET|HEAD)\s+(\S+)/) {
+                    if(defined($testpath)) {
+                        &sendrsp(403, "Confusing request");
+                        exit(4);
+                    }
+                    $testpath=$2;
+                    # also support pure HEAD calls
+                    if($1 eq 'HEAD') {
+                        $send_head_only=1;
+                    }
+                }
+                elsif(/^Connection: close/i) {
+                    $concloseflag=1;
+                }
+                elsif(/^Connection: .*TE/) {
+                    $concloseflag=1;
+                }
+                elsif(/^Range/i) {
+                    $rangereq=1;
+                }
+                elsif(/^If-Modified-Since:\s+(.*)/i) {
+                    $ifmosince=$1;
+                }
+                elsif(/^\S+: [^:]*/) {
+                    # whatever, but valid
+                }
+                else {
+                    &sendrsp(403, "Could not understand $_");
+                    exit(4);
+                }
+            }
+        }
+
+        # always resend the file if a part was requested since we don't support ranges
+        $ifmosince=0 if !$rangereq;
+
+        # tolerate CGI specific junk and two slashes in the beginning
+        $path =~ s!^/apt-cacher\??/!/!;
+        $path =~ s!^//!/!;
+        $path =~ s!^http://!!; # allow proxy style
+
+        # Now parse the path
+        if ($path =~ /^\/?report/) {
+            usage_report();
+            exit(0);
+        }
+
+        if ($path !~ m(^/?.+/.+)) {
+            usage_error();
+        }
+
+        REPARSE:
+        
+        my($host,$uri) = ($path =~ m#^/?([^/]+)(/.+)#);
+        
+        if ( !$host || !$uri ) {
+            usage_error();
+        }
+
+        ($filename) = ($uri =~ /\/?([^\/]+)$/);
+
+        if($$cfg{allowed_locations}) {
+            #         debug_message("Doing location check for ".$$cfg{allowed_locations} );
+            my $mess;
+            my $cleanuri=$uri;
+            $cleanuri=~s!/[^/]+/[\.]{2}/!/!g;
+            if ($host eq ".." ) {
+                $mess = "'..' contained in the hostname";
+            }
+            elsif ($cleanuri =~/\/\.\./) {
+                $mess = "File outside of the allowed path";
+            }
+            else {
+                for( split(/\s*,\s*/,$$cfg{allowed_locations}) ) {
+                    debug_message("Testing URI: $host$cleanuri on $_");
+                    goto location_allowed if ("$host$cleanuri" =~ /^$_/);
+                }
+                $mess = "Host '$host' is not configured in the allowed_locations directive";
+            }
+            badguy:
+            debug_message("$mess; access denied");
+            &sendrsp(403, "Access to cache prohibited, $mess");
+            exit(4);
+        }
+        location_allowed:
+
+        $do_import=0;
+        $is_index_file=0;
+
+        if ($filename =~ /(\.deb|\.rpm|\.dsc|\.tar\.gz|\.diff\.gz|\.udeb)$/) {
+            # We must be fetching a .deb or a .rpm, so let's cache it.
+            # Place the file in the cache with just its basename
+            $new_filename = $filename;
+            debug_message("new filename with just basename: $new_filename");
+        } 
+        elsif ($filename =~ /2\d\d\d-\d\d-\d\d.*\.gz$/) {
+            # a patch file. Needs a unique filename but no freshness checks
+            $new_filename = "$host$uri";
+            $new_filename =~ s/\//_/g;
+            debug_message("new long filename: $new_filename");
+        }
+        elsif ($filename =~ /$index_files_regexp/) {
+            $is_index_file=1;
+            # It's a Packages.gz or related file: make a long filename so we can cache these files without
+            # the names colliding
+            $new_filename = "$host$uri";
+            $new_filename =~ s/\//_/g;
+            debug_message("new long filename: $new_filename");
+            # optional checksumming support
+            if ($filename =~ /(Packages|Sources)/) {
+                # warning, an attacker could poison the checksum cache easily
+                $do_import=1;
+            }
+        } else {
+            # Maybe someone's trying to use us as a general purpose proxy / relay.
+            # Let's stomp on that now.
+            debug_message("Sorry, not allowed to fetch that type of file: $filename");
+            &sendrsp(403, "Sorry, not allowed to fetch that type of file: $filename");
+            exit(4);
+        }
+
+        $cached_file = "$$cfg{cache_dir}/packages/$new_filename";
+        $cached_head = "$$cfg{cache_dir}/headers/$new_filename";
+        $complete_file = "$private_dir/$new_filename.complete";
+        $notify_file = "$private_dir/$new_filename.notify";
+
+        my $force_download=0;
+
+        my $cache_status;
+
+        debug_message("looking for $cached_file");
+
+        if ($is_index_file) {
+            debug_message("known as index file: $filename");
+            # in offline mode, deliver it as-is, otherwise check freshness
+            if (-f $cached_file && -f $cached_head && !$$cfg{offline_mode}) {
+                if($$cfg{expire_hours} > 0) {
+                    my $now = time();
+                    my @stat = stat($cached_file);
+                    if (@stat && int(($now - $stat[9])/3600) > $$cfg{expire_hours}) {
+                        debug_message("unlinking $new_filename because it is too old");
+                        # Set the status to EXPIRED so the log file can show it was downloaded again
+                        $cache_status = "EXPIRED";
+                        debug_message("$cache_status");
+                        $force_download=1;
+                    }
+                }
+                else {
+                    # use HTTP timestamping
+                    my ($oldhead, $testfile, $newhead);
+                    my $response = &ua_act(1, $host, $uri);
+                    #my $response = $ua->head("http://$host$uri");
+                    $newhead = $response->header("Last-Modified");
+                    if($newhead && open($testfile, $cached_head)) {
+                        
+                        $newhead =~ s/\n|\r//g;
+
+                        for(<$testfile>){
+                            if(/^.*Last-Modified:\s(.*)(\r|\n)/) {
+                                $oldhead = $1;
+                                last
+                            }
+                        }
+                        close($testfile);
+                    }
+                    if($oldhead && ($oldhead eq $newhead) ) {
+                        # that's ok
+                        debug_message("remote file not changed, $oldhead vs. $newhead");
+                    }
+                    else {
+                        debug_message("unlinking $new_filename because it differs from server's version");
+                        $cache_status = "EXPIRED";
+                        debug_message("$cache_status");
+                        $force_download=1;
+                    }
+                }
+            }
+        }
+
+        # handle if-modified-since in a better way (check the equality of
+        # the time stamps). Do only if download not forced above.
+
+        if($ifmosince && !$force_download) {
+            $ifmosince=~s/\n|\r//g;
+
+            my $oldhead;
+            if(open(my $testfile, $cached_head)) {
+                LINE: for(<$testfile>){
+                    if(/^.*Last-Modified:\s(.*)(\r|\n)/) {
+                        $oldhead = $1;
+                        last LINE;
+                    }
+                }
+                close($testfile);
+            }
+
+            if($oldhead && $ifmosince eq $oldhead) {
+                &sendrsp(304, "Not Modified");
+                debug_message("File not changed: $ifmosince");
+                next REQUEST;
+            }
+        }
+
+        &set_global_lock(": file download decission"); # file state decissions, lock that area
+
+        my $fromfile; # handle for the reader
+
+        # download or not decission. Also releases the global lock
+        dl_check:
+        if( !$force_download && -e $cached_head && -e $cached_file) {
+            if (-f $complete_file) {
+                # not much to do if complete
+                $cache_status = "HIT";
+                debug_message("$cache_status");
+            }
+            else {
+                # a fetcher was either not successfull or is still running
+                # look for activity...
+                sysopen($fromfile, $cached_file, O_RDONLY) || undef $fromfile;
+                if (flock($fromfile, LOCK_EX|LOCK_NB)) {
+                    flock($fromfile, LOCK_UN);
+                    # bad, no fetcher working on this package. Redownload it.
+                    close($fromfile); undef $fromfile;
+                    debug_message("no fetcher running, forcing download");
+                    $force_download=1;
+                    goto dl_check;
+                }
+            }
+
+            &release_global_lock;
+        }
+        else {
+            # bypass for offline mode, no forking, just report the "problem"
+            if($$cfg{offline_mode})
+            {
+                &sendrsp(503, "Apt-Cacher in Offline Mode");
+                next REQUEST;
+            }
+
+            # (re) download them
+            unlink($cached_file, $cached_head, $complete_file, $notify_file);
+            debug_message("file does not exist or so, creating it");
+            # Set the status to MISS so the log file can show it had to be downloaded
+            if(!defined($cache_status)) { # except on special presets from index file checks above
+                $cache_status = "MISS"; 
+                debug_message("$cache_status");
+            }
+
+            # the writer releases the global lock after opening the target file
+            my $pid = fork();
+            if ($pid < 0) {
+                barf("fork() failed");
+            }
+            if ($pid == 0) {
+                # child, the fetcher thread
+                undef %childPids;
+                sysopen($pkfd, $cached_file, O_RDWR|O_CREAT|O_EXCL, 0644) || barf("Unable to store files");
+                open ( $chfd, ">$cached_head");
+
+                if (flock($pkfd, LOCK_EX)) {
+                    # jump from the global lock to a lock on the target file
+                    &release_global_lock;
+
+                    &fetch_store ($host, $uri); 
+
+                    exit 0;
+                }
+                else {
+                    barf("Problem locking the target file!");
+                }
+                # child exiting above, so or so
+            }
+            # parent continues
+            $childPids{$pid}=1;
+            debug_message("registred child process: $pid");
+            # &release_global_lock; to be release by downloader thread, not here
+        }
+
+        debug_message("checks done, can return now");
+        my $ret = &return_file (\$fromfile, $send_head_only);
+        goto dl_check if $ret==2; # retry code
+        debug_message("Package sent");
+
+        # Write all the stuff to the log file
+        writeaccesslog("$cache_status", "$new_filename");
+        if(!$is_index_file && !check_sum($new_filename)) {
+            writeerrorlog("   ALARM!    Faulty package in local cache detected! Removing, to be replaced with the next download.");
+            unlink $cached_file;
+            exit(5);
+        }
+        
+    }
+
+}
+
+
+sub return_file {
+    # At this point the file is open, and it's either complete or somebody
+    # is fetching its contents
+
+    our ($ffref, $send_head_only) =@_;
+    my $fromfile=$$ffref;
+
+    my $header_printed=0;
+
+    data_init();
+    
+    my $abort_time = get_abort_time();
+
+    my $buf;
+
+    my $geslen=0;
+    my $curlen=0;
+    my $explen;
+
+    my $complete_found;
+
+    # needs to print the header first
+    CHUNK: while (1) {
+
+        #debug_message("Send loop iteration:");
+
+        if (time() > $abort_time) {
+            debug_message("abort (timeout)");
+            exit(4);
+        }
+
+        if(! $header_printed) {
+
+            # add this reader to the notification list before printing anything useful to the client
+            if(! -f $complete_file) { # there is no point if the package is already downloaded
+                open(my $nf, ">>$notify_file");
+                flock($nf, LOCK_EX);
+                print $nf "$$\n";
+                flock($nf, LOCK_UN);
+                close($nf);
+            }
+
+            my $headstring;
+            if(-s $cached_head) {
+                # header file seen, protect the reading 
+                &set_global_lock(": reading the header file");
+                if(! -f $cached_head) {
+                    # file removed while waiting for lock - download failure?!
+                    # start over, maybe spawning an own fetcher
+                    &release_global_lock;
+                    return 2;
+                    #goto dl_check;
+                }
+
+                open(my $in, $cached_head);
+                my $code=200;
+                my $msg='';
+                my $headstring='';
+
+                $headstring=<$in>; # read exactly one status line
+
+                ($code, $msg) = ($headstring=~/^HTTP\S+\s+(\d+)\s(.*)/);
+                # alternative for critical errors
+                if(!defined($code)) {
+                    ($code, $msg) = ($headstring=~/^(5\d\d)\s(.*)/);
+                }
+
+                if(!defined($code)) {
+                    writeerrorlog("Faulty header file detected: $cached_head, first line was: $headstring");
+                    unlink $cached_head;
+                    exit 3;
+                }
+
+                # in CGI mode, use alternative status line. Don't print one
+                # for normal data output (apache does not like that) but on
+                # anormal codes, and then exit immediately
+                if($cgi_mode) {
+                    # don't print the head line but a Status on errors instead
+                    $headstring=~s/^HTTP\S+/Status:/;
+                    if($code == 200) {
+                        $headstring=''; # kick headline by default
+                    }
+                    else {
+                        print $con $headstring."\n\n";
+                        exit 1;
+                    }
+                }
+
+                # keep alive or not? Just follow the client
+                $headstring .= "Connection: ".($concloseflag?"Close":"Keep-Alive")."\r\n";
+
+                # keep only parts interesting for apt
+                if($code==200) {
+                    for(<$in>) {
+                        if(/^Last-Modified|Content|Accept/) {
+                            $headstring.=$_;
+                            if(/^Content-Length:\ *(\d+)/) {
+                                $explen=$1;
+                            }
+                        }
+                    }
+                }
+                close($in);
+                &release_global_lock;
+
+                print $con $headstring."\r\n";
+
+                $header_printed=1;
+                debug_message("Header sent: $headstring");
+
+                # Stop after sending the header with errors
+                return if($code != 200); 
+
+            }
+            else {
+                sleep(0.5);
+                next CHUNK;
+            }
+
+            # pure HEAD request, we are done
+            return if $send_head_only;
+            debug_message("ready to send contents of $cached_file");
+        }
+
+        if(! $fromfile) # is the data file open already? open in this iteration if needed
+        {
+            debug_message("opening file first: $cached_file");
+            if( ! -f $cached_file) {
+                sleep(1);
+                next CHUNK;
+            }
+
+            sysopen($fromfile, $cached_file, O_RDONLY); #FIXME, checken
+            next CHUNK;
+        }
+        else
+        {
+            my $n=0;
+            $n = sysread($fromfile, $buf, 65536);
+            debug_message("read $n bytes");
+
+            if(!defined($n)) {
+                debug_message("Error detected, closing connection");
+                exit(4);
+            }
+            
+            if($n==0) {
+                
+                if($complete_found) { # comlete file was found in the previous iteration
+                    # this is the loop exit condition
+                    # 
+                    # some extra error cases
+                    #if($explen && $curlen != $explen) {
+                    #    writeerrorlog("  ALARM!   $cached_file file is smaller than expected ($explen). Renaming to $cached_file.corrupted for further investigation, check your filesystem!");
+                    #    unlink "$cached_file.corrupted";
+                    #    rename($cached_file, "$cached_file.corrupted");
+                    #    exit(5);
+                    #}
+                    last CHUNK;
+                }
+
+                if (-f $complete_file) {
+                    # do another iteration, may need to read remaining data
+                    debug_message("complete file found");
+                    $complete_found=1;
+                    next CHUNK;
+                }
+
+                #debug_message("waiting for new data");
+                # wait for fresh data
+                sleep(0.5);
+                next CHUNK;
+
+            }
+            else {
+                $curlen+=$n;
+                if($explen && $curlen > $explen) {
+                    writeerrorlog("  ALARM!   $cached_file file is larger than expected ($explen). Renaming to $cached_file.corrupted for further investigation, check your filesystem!");
+                    unlink "$cached_file.corrupted";
+                    rename($cached_file, "$cached_file.corrupted");
+                    exit(5);
+                }
+                #debug_message("write $n / $curlen bytes");
+                # send data and update watchdog
+                print $con $buf;
+                debug_message("wrote $n (sum: $curlen) bytes");
+                $abort_time = get_abort_time();
+                data_feed(\$buf);
+            }
+        }
+    }
+}
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+sub barf {
+	my $errs = shift;
+
+	die "--- $0: Fatal: $errs\n";
+}
+
+sub usage_error {
+    &open_log_files;
+	writeerrorlog("--- $0: Usage error");
+
+    if(! defined($$cfg{example_sources_line})) {
+        $$cfg{example_sources_line}="deb&nbsp;http://<b>yourcache.example.com:$$cfg{daemon_port}/</b>ftp.au.debian.org/debian&nbsp;unstable&nbsp;main&nbsp;contrib&nbsp;non-free";
+    }
+
+    &sendrsp(200, "OK", "Content-Type", "text/html", "Expires", 0);
+	print $con <<EOF;
+
+<html>
+<title>Apt-cacher version $version
+</title><style type="text/css"><!--
+a { text-decoration: none; }
+a:hover { text-decoration: underline; }
+h1 { font-family: arial, helvetica, sans-serif; font-size: 18pt; font-weight: bold;}
+h2 { font-family: arial, helvetica, sans-serif; font-size: 14pt; font-weight: bold;}
+body, td { font-family: arial, helvetica, sans-serif; font-size: 10pt; }
+th { font-family: arial, helvetica, sans-serif; font-size: 11pt; font-weight: bold; }
+//--></style>
+</head>
+<body>
+<p>
+<table border=0 cellpadding=8 cellspacing=1 bgcolor="#000000" align="center" width="600">
+<tr bgcolor="#9999cc"><td> <h1>Apt-cacher version $version</h1> </td></tr>
+<tr bgcolor="#cccccc"><td>
+Usage: edit your /etc/apt/sources.list so all your HTTP sources are prepended 
+with the address of your apt-cacher machine and the port, like this:
+<blockquote>deb&nbsp;http://ftp.au.debian.org/debian&nbsp;unstable&nbsp;main&nbsp;contrib&nbsp;non-free</blockquote>
+becomes
+<blockquote>$$cfg{example_sources_line}</blockquote>
+</td></tr>
+</table>
+
+<h2 align="center">config values</h2>
+<table border=0 cellpadding=3 cellspacing=1 bgcolor="#000000" align="center">
+<tr bgcolor="#9999cc"><th> Directive </th><th> Value </th></tr>
+<tr bgcolor="#cccccc"><td bgcolor="#ccccff"> configfile </td><td> $configfile </td></tr>
+<tr bgcolor="#cccccc"><td bgcolor="#ccccff"> admin_email </td><td> <a href="mailto:$$cfg{admin_email}">$$cfg{admin_email}</a> </td></tr>
+<tr bgcolor="#cccccc"><td bgcolor="#ccccff"> generate_reports </td><td> $$cfg{generate_reports} </td></tr>
+<tr bgcolor="#cccccc"><td bgcolor="#ccccff"> cache_dir </td><td> $$cfg{cache_dir} </td></tr>
+<tr bgcolor="#cccccc"><td bgcolor="#ccccff"> logfile </td><td> $$cfg{logfile} </td></tr>
+<tr bgcolor="#cccccc"><td bgcolor="#ccccff"> errorfile </td><td> $$cfg{errorfile} </td></tr>
+<tr bgcolor="#cccccc"><td bgcolor="#ccccff"> expire_hours </td><td> $$cfg{expire_hours} </td></tr>
+<tr bgcolor="#cccccc"><td bgcolor="#ccccff"> http_proxy </td><td> $$cfg{http_proxy} </td></tr>
+<tr bgcolor="#cccccc"><td bgcolor="#ccccff"> use_proxy </td><td> $$cfg{use_proxy} </td></tr>
+<tr bgcolor="#cccccc"><td bgcolor="#ccccff"> use_proxy_auth </td><td> $$cfg{use_proxy_auth} </td></tr>
+<tr bgcolor="#cccccc"><td bgcolor="#ccccff"> debug </td><td> $$cfg{debug} </td></tr>
+</table>
+
+<p>
+<h2 align="center">license</h2>
+<table border=0 cellpadding=8 cellspacing=1 bgcolor="#000000" align="center" width="600">
+<tr bgcolor="#cccccc"><td>
+<p>Apt-cacher is free software; you can redistribute it and/or modify it under the terms of the GNU General 
+Public License as published by the Free Software Foundation; either version 2 of the License, or (at your 
+option) any later version.
+
+<p>Apt-cacher is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the 
+implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public 
+License for more details.
+
+<p>A copy of the GNU General Public License is available as /usr/share/common-licenses/GPL in the Debian 
+GNU/Linux distribution or on the World Wide Web at http://www.gnu.org/copyleft/gpl.html. You can also 
+obtain it by writing to the Free Software Foundation, Inc., 59 Temple Place - Suite 330, Boston, MA 
+02111-1307, USA.
+</td></tr>
+</table>
+</body>
+</html>
+EOF
+
+    exit 1;
+
+}
+
+
+# Jon's extra stuff to write the event to a log file.
+sub writeaccesslog {
+    my $cache_status = shift;
+    my $new_filename = shift;
+
+    # The format is 'time|cache status (HIT, MISS or EXPIRED)|client IP address|file size|name of requested file'
+    my $time = localtime;
+    my ($dev,$ino,$mode,$nlink,$uid,$gid,$rdev,$size,$atime,$mtime,$ctime,$blksize,$blocks) = stat($cached_file);
+    my $file_length = 0;
+    $file_length+=$size if defined($size);
+
+    flock($aclog_fh, LOCK_EX);
+    print $aclog_fh "$time|$client|$cache_status|$file_length|$new_filename\n";
+    flock($aclog_fh, LOCK_UN);
+}
+
+# Jon's extra stuff to write errors to a log file.
+sub writeerrorlog {
+	my $message = shift;
+	
+	my $time = localtime;
+
+    flock($erlog_fh, LOCK_EX);
+    # files may need to be reopened sometimes - reason unknown yet, EBADF
+    # results
+	syswrite($erlog_fh,"$time|$client|$message\n") || &open_log_files;
+    flock($erlog_fh, LOCK_UN);
+}
+
+# Stuff to append debug messages to the error log.
+sub debug_message {
+    if ($$cfg{debug} eq 1) {
+        my $message = shift;
+        &writeerrorlog("debug [$$]: $message");
+    }
+}
+
+sub open_log_files {
+	if(!$erlog_fh)
+    {
+        open($erlog_fh,">>$$cfg{errorfile}") or barf("Unable to open $$cfg{errorfile}");
+    }
+    if(!$aclog_fh) {
+        open($aclog_fh,">>$$cfg{logfile}") or barf("Unable to open $$cfg{logfile}");
+    }
+}
+ 
+sub get_abort_time () {
+  return time () + $$cfg{fetch_timeout}; # five minutes from now
+}
+
+my $header_stored=0;
+
+my $tstart;
+my $geslen;
+
+sub get_callback {
+    my $errors=0;
+
+    my ($data, $response, $proto) = @_;
+#    debug_message("Callback got data\n");
+    if(!$header_stored) {
+        $header_stored=1;
+        my $headstring = $response->as_string;
+
+        # print $con $headstring;
+        
+        &set_global_lock(": Callback, storing the header"); # set the lock before writting the first byte to that file, and release it after the file is closed
+        (scalar print $chfd $headstring ) || $errors++;
+        close($chfd);
+        &release_global_lock;
+
+        if($maxspeed) {
+            $geslen=-$getBufLen; # will be re-added below
+            $tstart = [gettimeofday];
+        }
+
+    }
+    (scalar print $pkfd $data ) || $errors++;
+    #print $con $data;
+
+    data_feed(\$data);
+
+    # delay for rate limiting
+    if($maxspeed) {
+        $geslen+=$getBufLen;
+        my $delta= $geslen/$maxspeed - ( scalar tv_interval ( $tstart ));
+        sleep($delta) if ($delta > 0);
+    }
+
+    if($errors) {
+        writeerrorlog("Write error. Disk full?");
+        # don't just exit here, fetcher needs to handle that
+        die();
+    }
+}
+
+sub fetch_store {
+
+    my ($host, $uri) = @_;
+
+    my $url = "http://$host$uri";
+    debug_message("fetcher: try to fetch $url");
+
+    # for checksumming
+    data_init();
+
+    my $response = &ua_act(0, $host, $uri);
+    #my $response = $ua->get($url, ':content_cb' => \&get_callback, ':read_size_hint' => $getBufLen);
+    #$geslen=0;
+
+    debug_message("Get is back");
+
+    if ($response->is_success && !defined($response->header("X-Died")) )
+    {
+
+        close($pkfd) if $pkfd;
+        undef $pkfd;
+
+        debug_message("stored $url as $cached_file");
+
+        # check missmatch or fetcher failure, could not connect the server
+        if( !$is_index_file && !check_sum($new_filename)) {
+            &set_global_lock(": file corruption report");
+            writeerrorlog("Do00h, checksum mismatch on $new_filename");
+            unlink $cached_file, $cached_head;
+            open(MF, ">$cached_head");
+            print MF "HTTP/1.1 502 Data corruption";
+            close(MF);
+            &kill_readers;
+            &release_global_lock;
+        }
+
+        # assuming here that the filesystem really closes the file and writes
+        # it out to disk before creating the complete flag file
+        
+        debug_message("setting complete flag for $new_filename");
+        # Now create the file to show the pickup is complete, also store the original URL there
+        open(MF, ">$private_dir/$new_filename.complete");
+        print MF $path;
+        close(MF); 
+
+        # index file seen? Get checksums
+        import_sums($cached_file) if $do_import;
+        
+        # store the sum, it may be not available yet but better this one than
+        # nothing. 
+        # disabled for now store_sum($new_filename);
+        # The sum may change on index files but that case is handled
+        # separately, the stored sum is allowed to differ from the data
+        # contents.
+
+    }
+    else
+    {
+        if(defined($response->header("X-Died"))) {
+            $response->code(502);
+            $response->message("Apt-Cacher: Transfer terminated");
+        }
+
+        debug_message("Reporting error: ".$response->code);
+        &set_global_lock(": HTTP error report");
+        open(my $ch, $cached_head);
+        my $headstring = $response->as_string;
+        if($headstring=~/^5\d\d/) { 
+            # work around LWP bug, incorrect status line with internal messages
+            $headstring = "HTTP/1.1 $headstring";
+        }
+        print $chfd $headstring;
+        close($chfd);
+        &release_global_lock;
+        if(defined($response->header("X-Died"))) { # was critical, most likely frozen now
+            &kill_readers;
+        }
+    }
+
+    debug_message("fetcher exiting");
+    unlink $notify_file;
+
+    # reset the shared vars
+    $header_stored=0; # FIXME, really needed? fetcher thread runs only once
+
+    _exit(0);
+}
+
+# FIXME: that sucks. Still needed?!
+sub kill_readers {
+    my $nf;
+    if(open($nf, $notify_file)) {
+        while(<$nf>) {
+            chomp;
+        debug_message("Stopping reader: $_");
+               kill 9, $_; # hard, bypassing the handler
+        }
+        close($nf);
+    }
+    # should be okay to unlink the file after all readers are "notified"
+    unlink $cached_file;
+}
+
+
+# Check if there has been a usage report generated and display it
+sub usage_report {
+	my $usage_file = "$$cfg{logdir}/report.html";
+    &sendrsp(200, "OK", "Content-Type", "text/html", "Expires", 0);
+	if (!-f $usage_file) {
+		print $con <<EOF;
+
+<html>
+<title>Apt-cacher traffic report</title><style type="text/css"><!--
+a { text-decoration: none; }
+a:hover { text-decoration: underline; }
+h1 { font-family: arial, helvetica, sans-serif; font-size: 18pt; font-weight: bold;}
+h2 { font-family: arial, helvetica, sans-serif; font-size: 14pt; font-weight: bold;}
+body, td { font-family: arial, helvetica, sans-serif; font-size: 10pt; }
+th { font-family: arial, helvetica, sans-serif; font-size: 11pt; font-weight: bold; }
+//--></style>
+</head>
+<body>
+<table border=0 cellpadding=8 cellspacing=1 bgcolor="#000000" align="center" width="600">
+<tr bgcolor="#9999cc"><td> <h1>Apt-cacher traffic report</h1> </td></tr>
+</td></tr>
+</table>
+		
+<p><table border=0 cellpadding=3 cellspacing=1 bgcolor="#000000" align="center" width="600">
+<tr bgcolor="#9999cc"><th bgcolor="#9999cc"> An Apt-cacher usage report has not yet been generated </th></tr>
+<tr bgcolor="#cccccc"><td bgcolor="#ccccff"> Reports are generated every 24 hours. If you want reports to be generated, make sure you set '<b>generate_reports=1</b>' in <b>$configfile</b>.</td></tr>
+</table>
+		</body>
+		</html>
+EOF
+
+	}
+	else
+	{
+        open(my $usefile, $usage_file);
+        my @usedata = <$usefile>;
+        close($usefile);
+        print $con @usedata;
+	}
+}
+
+# IP address filtering.
+sub ipv4_addr_in_list ($$)
+{
+	return 0 if $_[0] eq '';
+	debug_message ("testing $_[1]");
+	return 0 unless $$cfg{$_[1]};
+
+	my ($client, $cfitem) = @_;
+	my @allowed_hosts = split(/,\s*/, $$cfg{$cfitem});
+	for my $ahp (@allowed_hosts)
+	{
+		goto unknown if $ahp !~ /^[-\/,.[:digit:]]+$/;
+
+		# single host
+		if ($ahp =~ /^([^-\/]*)$/)
+		{
+			my $ip = $1;
+			debug_message("checking against $ip");
+			defined ($ip = ipv4_normalise($ip)) or goto unknown;
+			return 1 if $ip eq $client;
+		}
+		# range of hosts (netmask)
+		elsif ($ahp =~ /^([^-\/]*)\/([^-\/]*)$/)
+		{
+			my ($base, $mask) = ($1, $2);
+			debug_message("checking against $ahp");
+			defined ($base = ipv4_normalise($base)) or goto unknown;
+			$mask = ($mask =~ /^\d+$/) ? make_mask ($mask, 32)
+																 : ipv4_normalise ($mask);
+			goto unknown unless defined $mask;
+			return 1 if ($client & $mask) eq ($base & $mask);
+		}
+		# range of hosts (start & end)
+		elsif ($ahp =~ /^([^-\/]*)-([^-\/]*)$/)
+		{
+			my ($start, $end) = ($1, $2);
+			debug_message("checking against $start to $end");
+			defined ($start = ipv4_normalise($start)) or goto unknown;
+			defined ($end = ipv4_normalise($end)) or goto unknown;
+			return 1 if $client ge $start && $client le $end;
+		}
+		# unknown
+		else
+		{
+			unknown:
+			debug_message("Alert: $cfitem ($ahp) is bad");
+			&sendrsp(500, "Configuration error");
+			exit(4);
+		}
+	}
+	return 0; # failed
+}
+
+sub ipv6_addr_in_list ($$)
+{
+	return 0 if $_[0] eq '';
+	debug_message ("testing $_[1]");
+	return 0 unless $$cfg{$_[1]};
+
+	my ($client, $cfitem) = @_;
+	my @allowed_hosts = split(/,\s*/, $$cfg{$cfitem});
+	for my $ahp (@allowed_hosts)
+	{
+		goto unknown if $ahp !~ /^[-\/,:[:xdigit:]]+$/;
+
+		# single host
+		if ($ahp =~ /^([^-\/]*)$/)
+		{
+			my $ip = $1;
+			debug_message("checking against $ip");
+			$ip = ipv6_normalise($ip);
+			goto unknown if $ip eq '';
+			return 1 if $ip eq $client;
+		}
+		# range of hosts (netmask)
+		elsif ($ahp =~ /^([^-\/]*)\/([^-\/]*)$/)
+		{
+			my ($base, $mask) = ($1, $2);
+			debug_message("checking against $ahp");
+			$base = ipv6_normalise($base);
+			goto unknown if $base eq '';
+			goto unknown if $mask !~ /^\d+$/ || $mask < 0 || $mask > 128;
+			my $m = ("\xFF" x ($mask / 8));
+			$m .= chr ((-1 << (8 - $mask % 8)) & 255) if $mask % 8;
+			$mask = $m . ("\0" x (16 - length ($m)));
+			return 1 if ($client & $mask) eq ($base & $mask);
+		}
+		# range of hosts (start & end)
+		elsif ($ahp =~ /^([^-\/]*)-([^-\/]*)$/)
+		{
+			my ($start, $end) = ($1, $2);
+			debug_message("checking against $start to $end");
+			$start = ipv6_normalise($start);
+			$end = ipv6_normalise($end);
+			goto unknown if $start eq '' || $end eq '';
+			return 1 if $client ge $start && $client le $end;
+		}
+		# unknown
+		else
+		{
+			unknown:
+			debug_message("Alert: $cfitem ($ahp) is bad");
+            &sendrsp(500, "Configuration error");
+			exit(4);
+		}
+	}
+	return 0; # failed
+}
+
+sub sendrsp {
+    my $code=shift;
+    my $msg=shift;
+    $msg="" if !defined($msg);
+    
+    my $initmsg=
+    $cgi_mode ? 
+    "Status: $code $msg\r\n" :
+    "HTTP/1.1 $code $msg\r\n";
+    
+    $initmsg.="Connection: Keep-Alive\r\nAccept-Ranges: bytes\r\nKeep-Alive: timeout=15, max=100\r\n" if ($code ne 403);
+
+    #debug_message("Sending Response: $initmsg");
+    print $con $initmsg;
+
+    my $altbit=0;
+    for(@_) {
+        $altbit=!$altbit;
+        if($altbit) {
+            #debug_message("$_: ");
+            print $con $_.": ";
+        }
+        else {
+            #debug_message($_."\r\n);
+            print $con $_."\r\n";
+        }
+    }
+    print $con "\r\n";
+
+}
+
+# DOS attack safe input reader
+my @reqLineBuf;
+my $reqTail;
+sub getRequestLine {
+    if($cgi_path) { 
+        push(@reqLineBuf, "GET $cgi_path", "", undef); # undef stops operation
+        undef $cgi_path; # don't re-add it
+    }
+    if(! @reqLineBuf) {
+        my $buf="";
+
+        # after every read at least one line MUST have been found. Read length
+        # is large enough.
+
+        my $n=sysread($source, $buf, 1024);
+        $buf=$reqTail.$buf if(defined($reqTail));
+        undef $reqTail;
+
+        # pushes the lines found into the buffer. The last one may be incomplete,
+        # extra handling below
+        push(@reqLineBuf, split(/\r\n/, $buf, 1000) );
+
+        # buf did not end in a line terminator so the last line is an incomplete
+        # chunk. Does also work if \r and \n are separated
+        if(substr($buf, -2) ne "\r\n") {
+            $reqTail=pop(@reqLineBuf);
+        }
+    }
+    return shift(@reqLineBuf);
+}
+
+# runs the get or head operations on the user agent
+sub ua_act {
+    my ($only_head, $vhost, $uri) = @_;
+
+    my $url="http://$vhost$uri";
+    
+    &setup_agent;
+
+    my $do_hopping = (exists $pathmap{$vhost});
+
+    my $response;
+    my $hostcand;
+
+    RETRY_ACTION:
+
+    # make the virtual hosts real. The list is reduced which is not so smart,
+    # but since the fetcher process dies anyway it does not matter.
+    if($do_hopping) {
+        $hostcand = shift(@{$pathmap{$vhost}});
+        debug_message("Candidate: $hostcand");
+        $url=($hostcand =~ /^http:/?"" : "http://").$hostcand.$uri;
+        #$url="http://$hostcand$uri";
+        #$url="$hostcand$uri" if not $hostcand =~ /:\/\//;
+    }
+
+    debug_message("download agent: getting $url");
+    
+    if($only_head) {
+        $response = $ua->head($url);
+    }
+    else {
+        $response = $ua->get($url, ':content_cb' => \&get_callback, ':read_size_hint' => $getBufLen);
+    }
+
+    if($do_hopping) {
+        # if okay or the last candidate failes, put it back into the list
+        if($response->is_success || ! @{$pathmap{$vhost}} ) { 
+            unshift(@{$pathmap{$vhost}}, $hostcand);
+        }
+        else {
+            goto RETRY_ACTION;
+        }
+    }
+
+    return $response;
+}
+
+
+sub setup_ownership {
+    my $uid=$$cfg{user};
+    my $gid=$$cfg{group};
+
+    if($chroot) {
+        if($uid || $gid) {
+            # open them now, before it is too late
+            # FIXME: reopening won't work, but the lose of file handles needs to be
+            # made reproducible first
+            &open_log_files;
+        }
+        chroot $chroot || die "Unable to chroot, aborting.\n";
+        chdir $chroot;
+    }
+
+    if($gid) {
+        if($gid=~/^\d+$/) {
+            my $name=getgrgid($gid);
+            die "Unknown group ID: $gid (exiting)\n" if !$name;
+        }
+        else {
+            $gid=getgrnam($gid);
+            die "No such group (exiting)\n" if !defined($gid);
+        }
+        $) = $gid;
+        $( = $gid;
+        $) =~ /^$gid\b/ && $( =~ /^$gid\b/ || barf("Unable to change group id");
+    }
+
+    if($uid) {
+        if($uid=~/^\d+$/) {
+            my $name=getpwuid($uid);
+            die "Unknown user ID: $uid (exiting)\n" if !$name;
+        }
+        else {
+            $uid=getpwnam($uid);
+            die "No such user (exiting)\n" if !defined($uid);
+        }
+        $> = $uid;
+        $< = $uid;
+        $> == $uid && $< == $uid || barf("Unable to change user id");
+    }
+}
diff -r 9ce9101b3e6b binary-overlay.xenrt/usr/share/apt-cacher/apt-cacher-cleanup.pl
--- /dev/null	Thu Jan 01 00:00:00 1970 +0000
+++ b/binary-overlay.xenrt/usr/share/apt-cacher/apt-cacher-cleanup.pl	Fri Mar 14 11:52:03 2008 +0000
@@ -0,0 +1,247 @@
+#!/usr/bin/perl -w
+
+# apt-cacher-cleanup.pl
+# Script to clean the cache for the Apt-cacher package caching system.
+#
+# Copyright (C) 2005, Eduard Bloch <blade@debian.org>
+# Copyright (C) 2002-03, Jonathan Oxer <jon@debian.org>
+# Portions  (C) 2002, Jacob Lundberg <jacob@chaos2.org>
+# Distributed under the terms of the GNU Public Licence (GPL).
+
+
+# add one argument like 1 to make it verbose
+
+# do locking, not loosing files because someone redownloaded the index files
+# right then
+# use IO::Handle;
+
+use strict;
+use Cwd 'abs_path';
+
+use Fcntl ':flock';
+use IO::Handle;
+use POSIX;
+use Getopt::Long qw(:config no_ignore_case bundling pass_through);
+
+my $configfile = '/etc/apt-cacher/apt-cacher.conf';
+my $nice_mode=0;
+my $verbose=0;
+my $help;
+my $force;
+
+my %options = (
+    "h|help" => \$help,
+    "n|nice-mode=s"     => \$nice_mode,
+    "v|verbose"           => \$verbose,
+    "f|force"           => \$force,
+    "c|config-file=s"        => \$configfile
+);
+
+
+&help unless ( GetOptions(%options));
+&help if ($help);
+
+$configfile=abs_path($configfile);
+
+sub help {
+    die <<EOM
+    Usage: $0 [ -n ] [ -v ] [ -c configfile ]
+    -n : nice mode, refresh index files first, then renice to 20 and continue
+    -v : verbose mode
+    -f : force executing, disable santity checks
+EOM
+    ;
+}
+
+sub printmsg {
+   print @_ if $verbose;
+}
+
+#use strict;
+#############################################################################
+### configuration ###########################################################
+# Include the library for the config file parser
+require '/usr/share/apt-cacher/apt-cacher-lib.pl';
+# Read in the config file and set the necessary variables
+
+my $configref;
+eval {
+        $configref = read_config($configfile);
+};
+my %config = %$configref;
+
+# not sure what to do if we can't read the config file...
+die "Could not read config file: $@" if $@;
+
+my $globlockfile="$config{cache_dir}/private/exlock";
+
+# check whether we're actually meant to clean the cache
+if ( $config{clean_cache} ne 1 ) {
+	exit 0;
+}
+
+#############################################################################
+
+my $refresh=1;
+
+my %valid;
+
+my $tempdir="$config{cache_dir}/temp";
+mkdir $tempdir if !-d $tempdir;
+die "Could not create tempdir $tempdir\n" if !-d $tempdir;
+unlink (<$tempdir/*>);
+
+### Preparation of the package lists ########################################
+
+chdir "$config{cache_dir}/packages" && -w "." || die "Could not enter the cache dir";
+
+if($> == 0 && !$config{user} && !$force) {
+    die "Running $0 as root\nand no effective user has been specified. Aborting.\nPlease set the effective user in $configfile\n";
+}
+
+sub get {
+    my ($path_info, $filename) = @_;
+
+    my $fh;
+    #print "| /usr/share/apt-cacher/apt-cacher.pl -i -c $configfile >/dev/null";
+    open($fh, "| REMOTE_ADDR=CLEANUPREFRESH /usr/share/apt-cacher/apt-cacher -i -c $configfile >/dev/null");
+    printmsg "GET $path_info\n";
+    #printmsg("REMOTE_ADDR=CLEANUPREFRESH /usr/share/apt-cacher/apt-cacher -i -c $configfile >/dev/null\n");
+    print $fh "GET $path_info\r\nConnection: Close\r\n\r\n";
+    close($fh);
+    if($? && ! $force) {
+        die "Unable to update $path_info . Network problems?\nRun $0 with -v to get more details.\nCleanup aborted since cached data may be damaged.\n";
+    }
+}
+
+
+
+# file state decissions, lock that area
+open(my $lck, $globlockfile);
+flock($lck, LOCK_EX);
+my @ifiles=(<*es.gz>, <*es.bz2>, <*es>, <*_Index>);
+flock($lck, LOCK_UN);
+close($lck);
+
+for (@ifiles) {
+
+   # preserve the index files
+   $valid{$_}=1;
+
+   # now refresh them, unless disabled by the setting above
+   if($refresh) {
+       printmsg "D: $_\n";
+      # if the path is stored there, better use that
+      if(-s "../private/$_.complete") {
+         open(my $tmp, "../private/$_.complete");
+         my $url=<$tmp>;
+         &get($url);
+         close $tmp;
+      }
+      else {
+         my $tmp=$_;
+         $tmp=~s/^/\//;
+         $tmp=~s/_/\//g;
+         &get($tmp);
+      }
+   }
+}
+
+setpriority 0, 0, 20 if $nice_mode;
+
+# use the list of config files we already know
+for my $file (@ifiles) { 
+    printmsg "R: $file\n";
+
+    # get both locks and create a temp. copy
+    my $tmpfile= "$tempdir/$file";
+    open(my $glck, $globlockfile);
+    flock($glck, LOCK_EX);
+    open(my $lck, $file);
+    flock($lck, LOCK_EX);
+    link($file, $tmpfile);
+    flock($lck, LOCK_UN);
+    close($lck);
+    flock($glck, LOCK_UN);
+    close($glck);
+
+    if(-e $tmpfile && ! -s $tmpfile && $tmpfile=~/bz2$/) {
+        # moo, junk, empty file, most likely leftovers from previous versions
+        # of apt-cacher-cleanup where the junk was "protected" from beeing
+        # deleted. Purge later by not having in %valid.
+        # delete $valid{$file}; <- will be recreated RSN either way
+        print "Ignoring empty index file $file, apparently undownloadable\n" if $verbose;
+    }
+    else {
+        extract_sums($tmpfile, \%valid) || die("Error processing $file in $config{cache_dir}/packages, cleanup stopped.\nRemove the file if the repository is no longer interesting and the packages pulled from it are to be removed.\n");
+    }
+}
+
+printmsg "Found ".scalar (keys %valid)." valid file entries\n";
+#print join("\n",keys %valid);
+
+for(<*.deb>, <*.udeb>, <*.bz2>, <*.gz>, <*.dsc>) {
+    # should affect source packages but not index files which are added to the
+    # valid list above
+    if(! defined($valid{$_})) {
+        unlink $_, "../headers/$_", "../private/$_.complete";
+        printmsg "Removing source: $_ and company...\n";
+    }
+}
+
+# similar thing for possibly remaining cruft
+chdir "$config{cache_dir}/headers" && -w "." || die "Could not enter the cache dir";
+
+# headers for previosly expired files
+for(<*.deb>, <*.bz2>, <*.gz>, <*.dsc>) {
+   if(! defined($valid{$_})) {
+      unlink $_, "../private/$_.complete";
+      printmsg "Removing expired headers: $_ and company...\n";
+   }
+}
+
+# also remove void .complete files, created by broken versions of apt-cacher in rare conditions
+chdir "$config{cache_dir}/private" && -w "." || die "Could not enter the cache dir";
+for(<*.deb.complete>, <*.bz2.complete>, <*.gz.complete>, <*.dsc.complete>) {
+   s/.complete$//;
+   if(! (defined($valid{$_}) && -e "../packages/$_" && -e "../headers/$_") ) {
+      printmsg "Removing: $_.complete\n";
+      unlink "$_.complete";
+   }
+}
+
+# last step, kill some zombies
+
+my $now = time();
+for(<*.notify>) {
+    my @info = stat($_);
+    # even the largest package should be downloadable in two days or so
+    if(int(($now - $info[9])/3600) > 48) {
+        printmsg "Removing orphaned notify file: $_\n";
+        unlink $_;
+    }
+}
+
+#define_global_lockfile("$config{cache_dir}/exlock");
+#&set_global_lock(": cleanup zombies");
+
+chdir "$config{cache_dir}/packages";
+
+for(<*>) {
+    # must be empty and not complete and beeing downloaded right now
+    if(!-s $_) {
+        my $fromfile;
+        if(open($fromfile, $_) && flock($fromfile, LOCK_EX|LOCK_NB)) {
+            # double-check, may have changed while locking
+            if(!-s $_) {
+                printmsg "Removing zombie files: $_ and company...\n";
+                unlink $_, "../headers/$_", "../private/$_.complete";
+                flock($fromfile, LOCK_UN);
+                close($fromfile);
+            }
+        }
+    }
+}
+
+unlink (<$tempdir/*>);
+
diff -r 9ce9101b3e6b binary-overlay.xenrt/usr/share/apt-cacher/apt-cacher-format-transition.pl
--- /dev/null	Thu Jan 01 00:00:00 1970 +0000
+++ b/binary-overlay.xenrt/usr/share/apt-cacher/apt-cacher-format-transition.pl	Fri Mar 14 11:52:03 2008 +0000
@@ -0,0 +1,36 @@
+#!/usr/bin/perl
+die "Please specify the cache directory!\n" if !$ARGV[0];
+
+chdir $ARGV[0] || die "Could not enter the cache directory!";
+
+@info = stat("private");
+
+mkdir "packages";
+mkdir "headers";
+chown $info[4], $info[5], "packages", "headers";
+
+for $fname (<*.deb>, <*pgp>, <*gz>, <*bz2>, <*Release>) {
+   my $data=0;
+   my $size=0;
+   open(in, $fname);
+   open(daten, ">packages/$fname");
+   open(header, ">headers/$fname");
+   while(<in>) {
+      if($data) { print daten $_; next; };
+      print header $_;
+      $size=$1 if /^Content-Length: (\d+)/;
+      $data=1 if /^$/;
+   }
+   close(daten);
+   close(header);
+   @statinfo = stat("packages/$fname");
+   if($size == $statinfo[7]) {
+      chown $info[4], $info[5], "packages/$fname", "headers/$fname";
+      utime $statinfo[9], $statinfo[9], "packages/$fname", "headers/$fname";
+      unlink $fname;
+   }
+   else {
+      unlink "packages/$fname";
+      unlink "headers/$fname";
+   }
+}
diff -r 9ce9101b3e6b binary-overlay.xenrt/usr/share/apt-cacher/apt-cacher-import.pl
--- /dev/null	Thu Jan 01 00:00:00 1970 +0000
+++ b/binary-overlay.xenrt/usr/share/apt-cacher/apt-cacher-import.pl	Fri Mar 14 11:52:03 2008 +0000
@@ -0,0 +1,187 @@
+#!/usr/bin/perl
+
+# apt-cacher-import.pl
+# Script to import .deb packages into the Apt-cacher package caching system.
+# This script does not need to be run when setting up Apt-cacher for the first
+# time: its purpose is to initialise .deb packages that have been copied in
+# from some other source, such as a local mirror. Apt-cacher doesn't store
+# it's cached .debs in plain format, it prepends HTTP headers to them to send
+# out to clients when a package is requested. It also keeps track of which
+# packages are fully downloaded by touching a '.complete' file in the 'private'
+# directory in the cache. If .debs are just copied straight into the cache
+# dir Apt-cacher won't use them because it thinks they are both corrupt (no
+# headers) and incomplete (no .complete file). This script allows you to
+# copy a bunch of .debs into an import dir, then run this script to prepend
+# the HTTP headers and touch the .complete file after moving them to the cache
+# dir.
+#
+# Usage:
+# 1. Place your plain debs into /var/cache/apt-cacher/import (or where-ever
+#    you set the cache dir to be)
+# 2. Run this script: /usr/share/apt-cacher-import.pl
+#
+# Copyright (C) 2004, Jonathan Oxer <jon@debian.org>
+# Copyright (C) 2005, Eduard Bloch <blade@debian.org>
+
+# Distributed under the terms of the GNU Public Licence (GPL).
+
+#use strict;
+#############################################################################
+### configuration ###########################################################
+# Include the library for the config file parser
+require '/usr/share/apt-cacher/apt-cacher-lib.pl';
+
+use Getopt::Long qw(:config no_ignore_case bundling pass_through);
+use File::Basename;
+use File::Copy;
+use Cwd 'abs_path';
+use HTTP::Date;
+
+use strict;
+use warnings;
+
+my $configfile = '/etc/apt-cacher/apt-cacher.conf';
+my $help;
+my $quiet; # both not used yet
+my $noact;
+my $recmode;
+my $ro_mode;
+my $symlink_mode;
+
+my %options = (
+    "h|help" => \$help,
+    "q|quiet"           => \$quiet,
+    "n|no-act"          => \$noact,
+    "R|recursive"       => \$recmode,
+    "r|readonly"       => \$ro_mode,
+    "s|symlinks"       => \$symlink_mode,
+    "c|cfgfile=s"        => \$configfile
+);
+
+&help unless ( GetOptions(%options));
+&help if ($help);
+
+#$configfile=abs_path($configfile);
+
+my $cfg;
+eval {
+        $cfg = read_config($configfile);
+};
+
+# not sure what to do if we can't read the config file...
+die "Could not read config file: $@" if $@;
+
+my $private_dir = "$$cfg{cache_dir}/private";
+my $import_dir = "$$cfg{cache_dir}/import";
+my $target_dir = "$$cfg{cache_dir}/packages";
+my $header_dir = "$$cfg{cache_dir}/headers";
+
+my $packagesimported = 0;
+
+#############################################################################
+
+if(!$ARGV[0]) {
+   syswrite(STDOUT, "No import directory specified as the first argument, using $import_dir\n") if !$quiet;
+   sleep 2;
+}
+else {
+   $import_dir=$ARGV[0];
+}
+
+die "Cannot write to $target_dir - permission denied?\n" if !-w $target_dir;
+die "Cannot write to $header_dir - permission denied?\n" if !-w $header_dir;
+
+# common for all files
+my @info = stat($private_dir);
+my $headerdate = time2str();
+
+sub importrec {
+    my $import_dir=shift;
+    chdir($import_dir) || die "apt-cacher-import.pl: can't open the import directory ($import_dir)";
+    #print "Entering: $import_dir\n";
+
+    if($recmode) {
+        my $cwd=Cwd::getcwd();
+        for(<*>) {
+            if(-d $_ && ! -l $_) {
+                importrec($_) if -d $_;
+                chdir $cwd;
+                #print "Back in $cwd\n";
+            }
+        }
+    }
+
+    ### Loop through all the .debs in the import dir
+    foreach my $packagefile ( <*.deb>, <*.udeb>, <*.dsc>, <*.diff.gz>, <*_*tar.gz>, <*diff.bz2>, <*_*.tar.bz2> ) {
+
+        # Get some things we need to insert into the header
+        my $headerlength = (stat($packagefile))[7];
+        my $headeretag = int(rand(100000))."-".int(rand(1000))."-".int(rand(100000000));
+        $headeretag =~ s/^\s*(.*?)\s*$/$1/;
+        my $frompackagefile=$packagefile; # backup of the original name
+        $packagefile=~s/_\d+%3a/_/;
+
+	# Generate a header
+	my $httpheader = "HTTP/1.1 200 OK
+Date: ".$headerdate."
+Server: Apache \(Unix\) apt-cacher
+Last-Modified: ".$headerdate."
+ETag: \"".$headeretag."\"
+Accept-Ranges: bytes
+Content-Length: ".$headerlength."
+Keep-Alive: timeout=10, max=128
+Connection: Keep-Alive
+Content-Type: application/x-debian-package
+
+"
+; # there are TWO new lines
+
+        # Then cat the header to a temp file
+        print "Importing: $packagefile\n" if !$quiet;
+        unlink "$header_dir/$packagefile", "$target_dir/$packagefile",  "$private_dir/$packagefile.complete"; # just to be sure
+        if($symlink_mode) {
+            symlink(abs_path($frompackagefile), "$target_dir/$packagefile") ||
+            (unlink("$target_dir/$packagefile") && symlink(abs_path($frompackagefile), "$target_dir/$packagefile")) ||
+            die "Failed to create the symlink $target_dir/$packagefile";
+        }
+        elsif($ro_mode) {
+            link($frompackagefile, "$target_dir/$packagefile") || copy($frompackagefile, "$target_dir/$packagefile") || die "Failed to copy $frompackagefile";
+        }
+        else {
+            rename($frompackagefile, "$target_dir/$packagefile");
+        }
+
+        open(my $headfile, ">$header_dir/$packagefile");
+        print $headfile $httpheader;
+        close $headfile;
+
+        my $completefile = "$private_dir/$packagefile.complete";
+        open(MF, ">$completefile");
+        close(MF);
+        # copy the ownership of the private directory
+        chown $info[4], $info[5], "$header_dir/$packagefile", "$target_dir/$packagefile",  "$private_dir/$packagefile.complete";
+
+        $packagesimported++;
+    }
+}
+
+importrec($import_dir);
+
+print "Done.\n" if !$quiet;
+print "Packages imported: $packagesimported\n" if !$quiet;
+
+# Woohoo, all done!
+exit 0;
+
+sub help {
+    die "Usage: $0 [ -c apt-cacher.conf ] [ -q | --quiet ] [ -R | --recursive ] [ -r | --readonly ] [ -s | --symlinks ] [ package-source-dir ]
+
+If -c is omited, '-c /etc/apt-cacher/apt-cacher.conf' is assumed.
+If package-source-dir is omited, the filename from apt-cacher.conf is used.
+-R means descending into subdirectories while discovering pacakge files.
+-r tells to not move the source files. Instead, hardlinks or real copies are
+   created.
+-s tells to create symlinks to the source files and not move them. If the
+   target symlink exists, it will be removed.
+";
+}
diff -r 9ce9101b3e6b binary-overlay.xenrt/usr/share/apt-cacher/apt-cacher-lib-cs.pl
--- /dev/null	Thu Jan 01 00:00:00 1970 +0000
+++ b/binary-overlay.xenrt/usr/share/apt-cacher/apt-cacher-lib-cs.pl	Fri Mar 14 11:52:03 2008 +0000
@@ -0,0 +1,91 @@
+#! /usr/bin/perl
+
+# this are hook methods overload the hooks in apt-cacher-lib.pl and implement
+# data checksumming methods
+
+use DBI;
+use Fcntl ':flock';
+use IO::Handle;
+use POSIX;
+use Digest::MD5 qw(md5_hex);
+
+
+my $ctx;
+my $dbfile;
+my $dbh;
+my $dblck;
+
+sub dbauf {
+   open($dblck, $dbfile);
+   flock($dblck, LOCK_EX);
+   $dbh = DBI->connect("dbi:SQLite:dbname=$dbfile","", "",
+   { RaiseError => 1, AutoCommit => 0 } );
+}
+
+sub dbzu {
+   $dbh->disconnect;
+   flock($dblck, LOCK_UN);
+   close($dblck);
+}
+
+# arg: filename
+sub store_sum {
+    dbauf();
+    $dbh->do('REPLACE INTO sums VALUES(?,?);', undef, shift, $ctx->hexdigest);
+    $dbh->commit;
+    dbzu();
+}
+
+# arg: file to be scanned and added to DB
+sub import_sums {
+   my %sumhash;
+   extract_sums(shift, \%sumhash);
+   dbauf();
+   for(keys %sumhash) {
+      $dbh->do("replace into sums values(?,?);",undef,$_,$sumhash{$_});
+   }
+   $dbh->commit;
+   dbzu();
+}
+
+sub db_init {
+   $dbfile=shift;
+   if(!-s $dbfile) { 
+      open $db, ">$dbfile"; close $db; # touch it
+      dbauf();
+      $dbh->do("CREATE TABLE sums (file varchar PRIMARY KEY, sum varchar(32) NOT NULL);");
+      $dbh->commit;
+      dbzu();
+   }
+}
+
+# purpose: create hasher object
+sub data_init {
+   $ctx = Digest::MD5->new;
+   return 1;
+}
+
+# purpose: append data to be scanned
+sub data_feed {
+   $ref=shift;
+   $ctx->add($$ref);
+}
+
+# arg: filename
+sub check_sum {
+   my $digest = $ctx->hexdigest;
+   dbauf();
+   my @sqlar = $dbh->selectrow_array("select sum from sums where file=?", undef, shift);
+   dbzu();
+   if(defined($sqlar[0]) && $sqlar[0] ne '') {
+       # FIXME: do not check SHA1 summs, not supported yet
+       return 1 if(length($sqlar[0]) == 40);
+
+      # now find the faulty deb
+      return ($sqlar[0] eq $digest);
+   }
+   return 1;
+}
+
+
+1;
diff -r 9ce9101b3e6b binary-overlay.xenrt/usr/share/apt-cacher/apt-cacher-lib.pl
--- /dev/null	Thu Jan 01 00:00:00 1970 +0000
+++ b/binary-overlay.xenrt/usr/share/apt-cacher/apt-cacher-lib.pl	Fri Mar 14 11:52:03 2008 +0000
@@ -0,0 +1,226 @@
+#! /usr/bin/perl
+# This is a library file for Apt-cacher to allow code
+# common to Apt-cacher itself plus its supporting scripts
+# (apt-cacher-report.pl and apt-cacher-cleanup.pl) to be
+# maintained in one location.
+
+# This function reads the given config file into the
+# given hash ref. The key and value are separated by
+# a '=' and will have all the leading and trailing 
+# spaces removed.
+sub read_config
+{
+	# set the default config variables
+	my %config = (
+			cache_dir => '/var/log/cache/apt-cacher',
+			logdir => '/var/log/apt-cacher',
+			admin_email => 'root@localhost',
+			generate_reports => 0,
+			expire_hours => 0,
+			http_proxy => 'proxy.example.com:8080',
+			use_proxy => 0,
+			http_proxy_auth => 'proxyuser:proxypass',
+			use_proxy_auth => 0,
+			debug => 0,
+			clean_cache => 0,
+            allowed_hosts_6 => '*',
+            allowed_hosts => '*',
+            limit => 0,
+            daemon_port => 3142
+        );
+
+	($config_file) = @_;
+
+	open CONFIG, $config_file or die $!;
+
+    read(CONFIG, $buf, 50000);
+    $buf=~s/\\\n#/\n#/mg; # fix broken multilines
+    $buf=~s/\\\n//mg; # merge multilines
+
+    for(split(/\n/, $buf))
+	{
+        next if(/^#/); # weed out whole comment lines immediately
+
+        s/#.*//;   # kill off comments
+        s/^\s+//;	# kill off leading spaces
+        s/\s+$//;	# kill off trailing spaces
+
+		if ($_)
+		{
+			my ($key, $value) = split(/\s*=\s*/);	# split into key and value pair
+			$value = 0 unless ($value);
+            #print "key: $key, value: $value\n";
+			$config{$key} = $value;
+            #print "$config{$key}\n";
+		}
+	}
+
+	close CONFIG;
+
+	return \%config;
+}
+
+# Convert a human-readable IPv4 address to raw form (4-byte string)
+# Returns undef if the address is invalid
+sub ipv4_normalise ($)
+{
+	return undef if $_[0] =~ /:/;
+	my @in = split (/\./, $_[0]);
+	return '' if $#in != 3;
+	my $out = '';
+	foreach my $num (@in)
+	{
+		return undef if $num !~ /^[[:digit:]]{1,3}$/o;
+		$out .= pack ("C", $num);
+	}
+	return $out;
+}
+
+# Convert a human-readable IPv6 address to raw form (16-byte string)
+# Returns undef if the address is invalid
+sub ipv6_normalise ($)
+{
+	return "\0" x 16 if $_[0] eq '::';
+	return undef if $_[0] =~ /^:[^:]/  || $_[0] =~ /[^:]:$/ || $_[0] =~ /::.*::/;
+	my @in = split (/:/, $_[0]);
+	return undef if $#in > 7;
+	shift @in if $#in >= 1 && $in[0] eq '' && $in[1] eq ''; # handle ::1 etc.
+	my $num;
+	my $out = '';
+	my $tail = '';
+	while (defined ($num = shift @in) && $num ne '')
+	{
+		return undef if $num !~ /^[[:xdigit:]]{1,4}$/o;
+		$out .= pack ("n", hex $num);
+	}
+	foreach $num (@in)
+	{
+		return undef if $num !~ /^[[:xdigit:]]{1,4}$/o;
+		$tail .= pack ("n", hex $num);
+	}
+	my $l = length ($out.$tail);
+	return $out.("\0" x (16 - $l)).$tail if $l < 16;
+	return $out.$tail if $l == 16;
+	return undef;
+}
+
+# Make a netmask from a CIDR network-part length and the IP address length
+sub make_mask ($$)
+{
+	my ($mask, $bits) = @_;
+	return undef if $mask < 0 || $mask > $bits;
+	my $m = ("\xFF" x ($mask / 8));
+	$m .= chr ((-1 << (8 - $mask % 8)) & 255) if $mask % 8;
+	return $m . ("\0" x ($bits / 8 - length ($m)));
+}
+
+sub extract_sums {
+   my ($name, $hashref) = @_;
+   my ($cat, $listpipe, $indexbase);
+
+   $cat = ($name=~/bz2$/ ? "bzcat" : ($name=~/gz$/ ? "zcat" : "cat"));
+
+   if($name=~/^(.*_)Index$/) {
+       $indexbase=$1;
+       $indexbase=~s!.*/!!g;
+   }
+
+   open($listpipe, "-|", $cat, $name);
+   my $file;
+   while(<$listpipe>) {
+      if(/^\s(\w{40})\s+\d+\s(\S+)\n/) {
+         $sum=$1;
+         # Index format similar to Sources but filenames need to be corrected
+         # FIXME: this is sha1, not md5. Different format, can be detected by
+         # the length (40), though
+         $file=$indexbase.$2.".gz";
+     }
+     elsif(/^\s(\w{32})\s\d+\s(\S+)\n/) {
+         $sum=$1;
+         $file=$2;
+      }
+      elsif(/^MD5sum:\s+(.*)$/) {
+         $sum=$1;
+      }
+      elsif(/^Filename:\s+(.*)$/) {
+         $file=$1;
+         $file=~s/.*\///;
+      }
+      if(defined($file) && defined($sum)) {
+         $$hashref{$file}=$sum;
+         undef $file;
+         undef $sum;
+      }
+   };
+   close($listpipe);
+   my $ret = ! ($? >> 8);
+   return $ret;
+}
+
+
+my $exlock;
+my $exlockfile;
+
+sub define_global_lockfile {
+    $exlockfile=shift;
+}
+
+sub set_global_lock {
+
+    die ("Global lock file unknown") if !defined($exlockfile);
+
+    my $msg=shift;
+    $msg="" if !defined($msg);
+
+    debug_message("Entering critical section $msg");
+
+    #may need to create it if the file got lost
+    my $createstr = (-f $exlockfile) ? "" : '>';
+
+    open($exlock, $createstr.$exlockfile);
+    if ( !$exlock || !flock($exlock, LOCK_EX)) {
+        debug_message("unable to achieve a lock on $exlockfile: $!");
+        die "Unable to achieve lock on $exlockfile: $!";
+    }
+}
+
+sub release_global_lock {
+                    debug_message("Exiting critical section");
+   flock($exlock, LOCK_UN);
+}
+
+
+######### HOOKS ###########
+#
+# arg: file to be scanned and added to DB
+sub import_sums {
+   return 1;
+}
+
+# purpose: ?create?, lock the DB file and establish DB connection
+sub db_init {
+   return 1;
+}
+
+# purpose: create hasher object
+sub data_init {
+   return 1;
+}
+
+# purpose: append data to be scanned
+sub data_feed {
+   return 1;
+}
+
+# args: filename only or filename and sum
+sub check_sum {
+   return 1;
+}
+
+# args: filename and sum
+sub store_sum {
+}
+
+
+
+1;
diff -r 9ce9101b3e6b binary-overlay.xenrt/usr/share/apt-cacher/apt-cacher-precache.pl
--- /dev/null	Thu Jan 01 00:00:00 1970 +0000
+++ b/binary-overlay.xenrt/usr/share/apt-cacher/apt-cacher-precache.pl	Fri Mar 14 11:52:03 2008 +0000
@@ -0,0 +1,189 @@
+#!/usr/bin/perl
+
+##
+# apt-cacher-precache.pl
+# Script for pre-fetching of package data that may be used by users RSN
+#
+# Copyright (C) 2005, Eduard Bloch <blade@debian.org>
+# Distributed under the terms of the GNU Public Licence (GPLv2).
+
+use Getopt::Long qw(:config no_ignore_case bundling pass_through);
+#use File::Basename;
+use Cwd 'abs_path';
+
+use strict;
+
+my $distfilter='testing|etch';
+my $quiet=0;
+my $priofilter='';
+#my $expireafter=0;
+my $help;
+my $noact=0;
+my $uselists=0;
+my $configfile = '/etc/apt-cacher/apt-cacher.conf';
+
+my %options = (
+    "h|help" => \$help,
+    "d|dist-filter=s"     => \$distfilter,
+    "q|quiet"           => \$quiet,
+    "p|by-priority=s"     => \$priofilter,
+    "n|no-act"          => \$noact,
+    "c|cfgfile=s"        => \$configfile,
+    "l|list-dir=s"        => \$uselists
+);
+ 
+
+&help unless ( GetOptions(%options));
+&help if ($help);
+
+# Include the library for the config file parser
+require '/usr/share/apt-cacher/apt-cacher-lib.pl';
+my $cfgref;
+eval {
+        $cfgref = read_config($configfile);
+};
+# not sure what to do if we can't read the config file...
+die "Could not read config file: $@" if $@;
+
+$configfile=abs_path($configfile);
+
+# now pick up what we need
+my $cachedir=$$cfgref{cache_dir};
+
+sub help {
+print "
+USAGE: $0 [ options ]
+Options:
+ -d, --dist-filter=RE  Perl regular experession, applied to the URL of Packages
+                       files to select only special versions. Example:
+                       'sid|unstable|experimental'
+                       (default: 'testing|etch')
+ -q, --quiet           suppress verbose output
+ -l, --list-dir=DIR    also use pure/compressed files from the specified dir
+                       (eg. /var/log/apt-cacher) to get the package names from.
+                       Words before | are ignored (in apt-cacher logs). To
+                       create a such list from clients, see below.
+ -p, --by-priority=RE  Perl regular expression for priorities to be looked for
+                       when selecting packages. Implies threating all packages
+                       with this priority as installation candidates.
+                       (default: scanning the cache for candidates without
+                       looking at priority)
+
+NOTE: the options may change in the future.
+You can feed existing package lists or old apt-cacher logs into the selection
+algorithm by using the -l option above. If the version is omited (eg. for lists
+created with \"dpkg --get-selections\" then the packages may be redownloaded).
+To avoid this, use following one-liner to fake a list with version infos:
+
+dpkg -l | perl -ne 'if(/^(i.|.i)\\s+(\\S+)\\s+(\\S+)/) { print \"\$2_\$3_i386.deb\\n\$2_\$3_all.deb\\n\"}'
+
+"; exit 1;};
+
+syswrite(STDOUT,
+"This is an experimental script. You have been warned.
+Run before apt-cacher-cleanup.pl, otherwise it cannot track old downloads.
+") if !$quiet;
+
+my $pcount=0;
+
+chdir "$cachedir/packages" || die "cannot enter $cachedir/packages" ;
+
+my %having; # remember seen packages, just for debugging/noact, emulate what -f would do for us otherwise
+
+sub get() {
+   my ($path_info, $filename) = @_;
+   if(!defined $having{$filename}) {
+      print "I: downloading $path_info\n" if !$quiet;
+      $pcount++;
+   }
+
+   $having{$filename}=1;
+
+   if(!$noact) {
+      open(fh, "| REMOTE_ADDR=PRECACHING /usr/share/apt-cacher/apt-cacher -i -c $configfile >/dev/null");
+      print fh "GET /$path_info\r\nConnection: Close\r\n\r\n";
+      close(fh);
+   }
+}
+
+my %pkgs;
+for (<*>) { 
+   s/_.*//g;
+   $pkgs{$_}=1;
+}
+
+if($uselists) {
+   for(<$uselists/*>) {
+      my $cat = (/bz2$/ ? "bzcat" : (/gz$/ ? "zcat" : "cat"));
+      #open(catlists, "/bin/cat $$cfg{logdir}/access.log $$cfg{logdir}/access.log.1 2>/dev/null ; zcat $$cfg{logdir}/access.log.*.gz 2>/dev/null |");
+      if(open(catlists,"-|",$cat,$_)) {
+         while(<catlists>){
+            chomp;
+            s/.*\|//g;
+            s/\s.*//g;
+            $having{$_}=1; # filter the packages we already have installed
+            s/_.*//g;
+            $pkgs{$_}=1;
+         }
+      }
+   }
+}
+
+
+PKGITER: for my $pgz (<*Packages*>) {
+
+    # ignore broken files
+    next PKGITER if(!-f "../private/$pgz.complete");
+
+   if(length($distfilter)) {
+      if($pgz =~ /$distfilter/) {
+         print "I: distfilter passed, $pgz\n" if !$quiet;
+      }
+      else {
+         next PKGITER;
+      }
+   }
+   
+   my $pgz_path_info=$pgz;
+   $pgz_path_info =~ s!_!/!g;
+   my $root_path_info = $pgz_path_info;
+   $root_path_info =~ s!/dists/.*!!g; # that sucks, pure guessing
+   $root_path_info =~ s!/project/experimental/.*!!g; # that sucks, pure guessing
+
+   my ($cat, $listpipe);
+   $_=$pgz;
+   $cat = (/bz2$/ ? "bzcat" : (/gz$/ ? "zcat" : "cat"));
+   
+   &get($pgz_path_info, $_);
+
+   print "I: processing $_\n" if !$quiet;
+   if(open(pfile,"-|",$cat,$pgz)) {
+
+      my $prio;
+      while(<pfile>) {
+         chomp;
+         if(/^Priority:\s+(.*)/) { $prio=$1; }
+         if(s/^Filename:.//) {
+            my $deb_path_info="$root_path_info/$_";
+            # purify the name
+            s!.*/!!g;
+            my $filename=$_;
+            s!_.*!!g;
+            my $pkgname=$_;
+            
+            if(length($priofilter)) {
+               if(!-e $filename && $prio=~/$priofilter/ ) {
+                  &get($deb_path_info, $filename);
+               }
+            }
+            elsif($pkgs{$pkgname}) {
+               if(!-e $filename) {
+                  &get($deb_path_info, $filename);
+               }
+            }
+         }
+      }
+   }
+}
+
+print "Downloaded: $pcount files.\n" if !$quiet;
diff -r 9ce9101b3e6b binary-overlay.xenrt/usr/share/apt-cacher/apt-cacher-report.pl
--- /dev/null	Thu Jan 01 00:00:00 1970 +0000
+++ b/binary-overlay.xenrt/usr/share/apt-cacher/apt-cacher-report.pl	Fri Mar 14 11:52:03 2008 +0000
@@ -0,0 +1,234 @@
+#!/usr/bin/perl -w
+
+# apt-cacher-report.pl
+# Script to generate usage reports for the Apt-cacher package caching system.
+#
+# Copyright (C) 2002,2004 Jonathan Oxer <jon@debian.org>
+# Distributed under the terms of the GNU Public Licence (GPL).
+
+#use strict;
+#############################################################################
+### configuration ###########################################################
+# Include the library for the config file parser
+require '/usr/share/apt-cacher/apt-cacher-lib.pl';
+use POSIX qw(strftime);
+
+
+# Read in the config file and set the necessary variables
+my $configfile = '/etc/apt-cacher/apt-cacher.conf';
+
+my $configref;
+eval {
+        $configref = read_config($configfile);
+};
+my %config = %$configref;
+
+# not sure what to do if we can't read the config file...
+die "Could not read config file: $@" if $@;
+
+# check whether we're actually meant to generate a report
+if ( $config{generate_reports} ne 1 ){
+	exit 0;
+}
+
+# Now set some things from the config file
+# $logfile used to be set in the config file: now we derive it from $logdir
+my $logfile = "$config{logdir}/access.log";
+
+
+###################################################
+# Read in the logfiles if they exist, from oldest to newest
+
+# First we look for rolled and compressed logfiles, from
+# /var/log/apt-cacher/access.log.12.gz to access.log.2.gz
+$logcount = 12;
+while ($logcount > 1)
+{
+	if (-f "${logfile}.$logcount.gz") {
+		$logdataraw = `zcat ${logfile}.$logcount.gz`;
+		push (@logdata, split("\n", $logdataraw));
+	}
+	$logcount--;
+}
+
+# Then the immediately rolled (but uncompressed) log
+if (-f "${logfile}.1") {
+	open(LOGFILE, "<${logfile}.1");
+	#@logdata = <LOGFILE>;
+	push(@logdata, <LOGFILE>);
+	close(LOGFILE);
+}
+
+# Then finally the current working log
+if (-f "${logfile}") {
+	open(LOGFILE, "<$logfile");
+	push(@logdata, <LOGFILE>);
+	close(LOGFILE);
+}
+
+#read current time
+#($second,$minute,$hour,$day,$month,$year,$null,$null,$null)=localtime(time);
+my $datetime = strftime("%Y-%m-%d %H:%M:%S", localtime());
+
+#$year = $year + 1900;
+#$month=$month + 1;
+
+my $hit_count = 0;
+my $hit_bytes = 0;
+my $miss_count = 0;
+my $miss_bytes = 0;
+
+#parse logfile:
+foreach $logfile_line (@logdata)
+{
+	#$logfile_line =~ s/ /\+/g;
+	@line = split /\|/, $logfile_line;
+	$req_date = $line[0];
+#	$req_ip   = $line[1];
+	$req_result = $line[2];
+	$req_bytes  = $line[3];
+#	$req_object = $line[4];
+
+	$lastrecord = $req_date;
+	if(!$firstrecord) {
+		$firstrecord = $req_date;
+	}
+	if ( $req_result eq "HIT" )
+	{
+		$hit_count++;
+		$hit_bytes += $req_bytes;
+	}
+	else
+	{
+		$miss_count++;
+		$miss_bytes += $req_bytes;
+	}
+
+}
+
+my $total_count = $hit_count + $miss_count;
+
+if($total_count eq 0)
+{
+	$hit_count_percent = 0;
+	$miss_count_percent = 0;
+} else {
+	$hit_count_percent = (int(($hit_count / $total_count) * 10000)) / 100;
+	$miss_count_percent = (int(($miss_count / $total_count) * 10000)) / 100;
+}
+
+$total_bytes = $hit_bytes + $miss_bytes;
+
+##################################################
+# At this point we have hit/miss/total counts, and hit/miss/total traffic
+# So now we need to decide what units to use for each one, and set a
+# human-readable string. Displays as MB unless > 2000MB, in which case it
+# displays as GB.
+# Yes, I know this really should be a subroutine. Sigh. One day. Maybe.
+
+if($total_bytes > 2097152000)
+{
+	$tx = (int(($total_bytes/1073741824) * 1000)) / 1000;
+	$total_trafficstring = "$tx GB";
+} else {
+	$tx = (int(($total_bytes/1048576) * 1000)) / 1000;
+	$total_trafficstring = "$tx MB";
+}
+
+if($hit_bytes > 2097152000)
+{
+        $tx = (int(($hit_bytes/1073741824) * 1000)) / 1000;
+        $hit_trafficstring = "$tx GB";
+} else {
+        $tx = (int(($hit_bytes/1048576) * 1000)) / 1000;
+        $hit_trafficstring = "$tx MB";
+}
+
+if($miss_bytes > 2097152000)
+{
+        $tx = (int(($miss_bytes/1073741824) * 1000)) / 1000;
+        $miss_trafficstring = "$tx GB";
+} else {
+        $tx = (int(($miss_bytes/1048576) * 1000)) / 1000;
+        $miss_trafficstring = "$tx MB";
+}
+
+
+##################################################
+# Set percentages to 0 if no records, otherwise calculate
+if($total_bytes eq 0)
+{
+	$hit_data_percent = 0;
+	$miss_data_percent = 0;
+} else {
+	$hit_data_percent = (int(($hit_bytes / $total_bytes) * 10000)) / 100;
+	$miss_data_percent = (int(($miss_bytes / $total_bytes) * 10000)) / 100;
+}
+
+##################################################
+# If there weren't actually any logfiles processed these will be null, so we'll
+# set them to strings
+if(!$firstrecord)
+{
+	$firstrecord = "unknown";
+}
+if(!$lastrecord)
+{
+	$lastrecord = "unknown";
+}
+
+##################################################
+# spit out the report
+$output = "
+<html>
+<title>Apt-cacher traffic report</title><style type=\"text/css\"><!--
+a { text-decoration: none; }
+a:hover { text-decoration: underline; }
+h1 { font-family: arial, helvetica, sans-serif; font-size: 18pt; font-weight: bold;}
+h2 { font-family: arial, helvetica, sans-serif; font-size: 14pt; font-weight: bold;}
+body, td { font-family: arial, helvetica, sans-serif; font-size: 10pt; }
+th { font-family: arial, helvetica, sans-serif; font-size: 11pt; font-weight: bold; }
+//--></style>
+</head>
+<body>";
+
+#	print "<html><head><title>Apt-cacher traffic report</title></head>\n";
+#	print "<body bgcolor=\"#ffffff\">\n";
+
+$output .= "<p>
+<table border=0 cellpadding=8 cellspacing=1 bgcolor=\"#000000\" align=\"center\" width=\"600\">
+<tr bgcolor=\"#9999cc\"><td> <h1>Apt-cacher traffic report</h1> </td></tr>
+<tr bgcolor=\"#cccccc\"><td>For more information on apt-cacher visit <a href=\"http://packages.debian.org/apt-cacher\">http://packages.debian.org/apt-cacher</a>.
+</td></tr>
+</table>";
+
+$output .= "<h2 align=\"center\">summary</h2>
+<table border=0 cellpadding=3 cellspacing=1 bgcolor=\"#000000\" align=\"center\" width=\"600\">
+<tr bgcolor=\"#9999cc\"><th bgcolor=\"#9999cc\"> Item </th><th> Value </th></tr>
+<tr bgcolor=\"#cccccc\"><td bgcolor=\"#ccccff\"> Report generated </td><td> $datetime </td></tr>
+<tr bgcolor=\"#cccccc\"><td bgcolor=\"#ccccff\"> Administrator </td><td> <a href=\"mailto:$config{admin_email}\">$config{admin_email}</a> </td></tr>";
+$output .= "<tr bgcolor=\"#cccccc\"><td bgcolor=\"#ccccff\"> First request </td><td> $firstrecord </td></tr>";
+$output .= "<tr bgcolor=\"#cccccc\"><td bgcolor=\"#ccccff\"> Last request </td><td> $lastrecord </td></tr>";
+$output .= "<tr bgcolor=\"#cccccc\"><td bgcolor=\"#ccccff\"> Total requests </td><td> $total_count </td></tr>";
+$output .= "<tr bgcolor=\"#cccccc\"><td bgcolor=\"#ccccff\"> Total traffic </td><td> $total_trafficstring </td></tr>";
+$output .= "</table>";
+
+$output .= "<h2 align=\"center\">cache efficiency</h2>
+<table border=0 cellpadding=3 cellspacing=1 bgcolor=\"#000000\" align=\"center\" width=\"600\">
+<tr bgcolor=\"#9999cc\"><th></th><th>Cache hits</th><th>Cache misses</th><th>Total</th></tr>\n
+<tr bgcolor=\"#cccccc\"><td bgcolor=\"#ccccff\"> Requests </td><td>$hit_count ($hit_count_percent%)</td><td>$miss_count ($miss_count_percent%)</td><td>$total_count</td></tr>\n
+<tr bgcolor=\"#cccccc\"><td bgcolor=\"#ccccff\"> Transfers </td><td>$hit_trafficstring ($hit_data_percent%)</td><td>$miss_trafficstring ($miss_data_percent%)</td><td>$total_trafficstring</td></tr>\n
+</table>";
+	
+$output .= "</body></html>\n";
+
+#print $output;
+my $report_file = "$config{logdir}/report.html";
+`touch $report_file`;
+open(REPORT,">$report_file") or die;
+print REPORT "$output\n";
+close REPORT;
+
+
+exit 0;
+
diff -r 9ce9101b3e6b binary-overlay.xenrt/usr/share/apt-cacher/apt-cacher.pl
--- /dev/null	Thu Jan 01 00:00:00 1970 +0000
+++ b/binary-overlay.xenrt/usr/share/apt-cacher/apt-cacher.pl	Fri Mar 14 11:52:03 2008 +0000
@@ -0,0 +1,9 @@
+#!/usr/bin/perl
+# apt-cacher.pl - CGI to provide a local cache for debian packages and
+# release files and .deb files. Actually just a wrapper to set CGI mode flag
+# for the real script.
+
+$ENV{CGI_MODE}=1;
+
+# identify as CGI and run the actuall script
+require "/usr/share/apt-cacher/apt-cacher";
diff -r 9ce9101b3e6b binary-overlay.xenrt/usr/share/apt-cacher/apt-proxy-to-apt-cacher
--- /dev/null	Thu Jan 01 00:00:00 1970 +0000
+++ b/binary-overlay.xenrt/usr/share/apt-cacher/apt-proxy-to-apt-cacher	Fri Mar 14 11:52:03 2008 +0000
@@ -0,0 +1,167 @@
+#!/usr/bin/perl
+
+use strict;
+
+use Getopt::Long qw(:config no_ignore_case bundling pass_through);
+use Cwd 'abs_path';
+
+my $help;
+my $configfile = '/etc/apt-cacher/apt-cacher.conf';
+my $apconfigfile = '/etc/apt-proxy/apt-proxy-v2.conf';
+
+my %options = (
+    "h|help" => \$help,
+    "c|cfgfile=s"        => \$configfile,
+    "C|apconfigfile=s"        => \$apconfigfile,
+);
+
+&help unless ( GetOptions(%options));
+&help if ($help);
+
+sub help {
+die "
+USAGE: $0 [ options ]
+Transforms configuration and cached data from apt-proxy v2 to apt-cacher 1.x
+
+Options:
+ -c     apt-cacher's config file
+ -C     apt-proxy's  config file
+";
+}
+
+print "Reading apt-proxy's configuration from $apconfigfile\n";
+
+open(my $apc, $apconfigfile) || die "Could not open $apconfigfile. Use the -C option\n";
+
+my %config;
+
+print "Adopting options:\n";
+my $cache_dir;
+
+my $prevkey;
+LINE: while (<$apc>)
+{
+    chomp;
+    if ( /^\t(.*)$/ && defined $prevkey ) {
+        $config{$prevkey}.= " $1 ";
+        next LINE;
+    }
+
+    s/^;.*$//;   # kill off comments
+    s/^\s+//;	# kill off leading spaces
+    s/\s+$//;	# kill off trailing spaces
+
+    next if /^\[DEFAULT/;
+    
+    if(/^\[(.*)\]/) {
+        $config{path_map} .=" ; " if $config{path_map};
+        $config{path_map} .= " $1 ";
+    }
+
+    if ($_)
+    {
+        my ($key, $value) = split(/\s*=\s*/);	# split into key and value pair
+        #print "key: $key, value: $value\n";
+        $prevkey=$key;
+        if($key eq "port") {
+            $config{daemon_port} = $value;
+            print "Port: $value\n";
+        }
+        if($key eq "address") {
+            $config{daemon_addr} = $value;
+            print "Address: $value\n";
+        }
+        if($key eq "http_proxy") {
+            $config{http_proxy} = $value;
+            $config{use_proxy} = 1;
+            print "Proxy: $value\n";
+        }
+        if($key eq "backends") {
+            $prevkey = "path_map";
+            $config{path_map} .= " $value ";
+        }
+        if($key eq "cache_dir") {
+            $cache_dir=$value;
+        }
+    }
+}
+
+my @map = split(/\s+/, $config{path_map});
+for(@map) {
+    # just try to use http on ftp servers and drop rsync versions
+    # s#^ftp:#http:#;
+    # s#^rsync.*##;
+    s#^.*://##;
+}
+$config{path_map} = join(" ", @map);
+
+#for(keys %config) {
+#    print "hm, $_: $config{$_}\n";
+#}
+
+print "Reading apt-cacher's configuration from $configfile\n";
+
+open(CONFIG, $configfile) || die "Unable to open the apt-cacher config file template\n";
+
+my $buf;
+read(CONFIG, $buf, 50000);
+close(CONFIG);
+$buf=~s/\\\n#/\n#/mg; # fix broken multilines
+$buf=~s/\\\n//mg; # merge multilines
+
+my @out = ("# This file has been modified by $0\n# Some lines may have been appended at the bottom of this file\n");
+
+for(split(/\n/, $buf))
+{
+    my $orig=$_;
+
+    s/#.*//;   # kill off comments
+    s/^\s+//;	# kill off leading spaces
+    s/\s+$//;	# kill off trailing spaces
+
+    if ($_)
+    {
+        my ($key, $value) = split(/\s*=\s*/);	# split into key and value pair
+        if(exists $config{$key}) {
+            push @out, "$key = $config{$key}\n";
+            delete $config{$key};
+        }
+        else {
+            push @out, "$orig\n";
+        }
+    }
+    else {
+        push @out, "$orig\n";
+    }
+}
+
+# append the remaining settings
+for(keys %config) {
+    push @out, "\n# extra setting from apt-proxy configuration\n$_ = $config{$_}\n";
+}
+
+print "\n$0 will now modify the apt-cacher.conf file\nand import the data from apt-proxy's cache. Do you wish to continue? [y/n] ";
+my $answer= <STDIN>;
+if($answer eq "y\n") {
+
+    open(CONFIG, ">$configfile") || die "Unable to write apt-cacher config file\n";
+    print CONFIG @out;
+    close(CONFIG);
+    #print join(" ", "Running: ", "/usr/share/apt-cacher/apt-cacher-import.pl", "-c", $configfile, "-r", "-R" , $cache_dir, "\n");
+
+    system("/usr/share/apt-cacher/apt-cacher-import.pl", "-c", $configfile, "-r", "-R" , $cache_dir);
+}
+    
+print "\nStop apt-proxy and start apt-cacher now? [y/n] ";
+$answer= <STDIN>;
+if($answer eq "y\n") {
+    system "/etc/init.d/apt-proxy stop";
+    system "echo AUTOSTART=1 >> /etc/default/apt-cacher";
+    system "/etc/init.d/apt-cacher restart";
+}
+    
+print "\nDisable the apt-proxy in the init configuration (update-rc.d remove)? [y/n] ";
+$answer= <STDIN>;
+if($answer eq "y\n") {
+    system "update-rc.d -f apt-proxy remove";
+}
diff -r 9ce9101b3e6b binary-overlay.xenrt/usr/share/apt-cacher/install.pl
--- /dev/null	Thu Jan 01 00:00:00 1970 +0000
+++ b/binary-overlay.xenrt/usr/share/apt-cacher/install.pl	Fri Mar 14 11:52:03 2008 +0000
@@ -0,0 +1,209 @@
+#!/usr/bin/perl -w
+#	@(#) setup.pl -- Setup script for apt-cacher.pl
+#	$ Revision: $
+#	$ Source: $
+#	$ Date: $
+#
+#	Safe to run multiple times; later versions of this script will
+#	remove obsolete directories or files and not touch required
+#	directories or files.
+#
+
+umask 0022;
+
+#############################################################################
+### configuration ###########################################################
+# Include the library for the config file parser
+require '/usr/share/apt-cacher/apt-cacher-lib.pl';
+
+# Read in the config file and set the necessary variables
+my $configfile = '/etc/apt-cacher/apt-cacher.conf';
+
+my $configref;
+eval {
+        $configref = read_config($configfile);
+};
+my %config = %$configref;
+
+# not sure what to do if we can't read the config file...
+die "Could not read config file: $@" if $@;
+
+# Now set some things from the config file
+# $logfile used to be set in the config file: now we derive it from $logdir
+$config{logfile} = "$config{logdir}/access.log";
+
+# $errorfile used to be set in the config file: now we derive it from $logdir
+$config{errorfile} = "$config{logdir}/error.log";
+
+my $private_dir = "$config{cache_dir}/private";
+
+################################################
+# Check that the cache_dir has been set and continue on (note: this should never happen
+# because cache_dir is preset to a default value prior to loading the config file)
+die "Warning: config file could not be parsed ($configfile)/ (cache_dir is not set)\n" if ($config{cache_dir} eq '');
+
+
+@info=getpwnam("www-data");
+my @permcmd;
+if(-e $config{cache_dir}) {
+   @permcmd = ("chown", "--reference", $config{cache_dir});
+}
+elsif(@info) {
+   print "Assuming www-data is the user ID used to run apt-cacher\n";
+   @permcmd = ("chown", "$info[2]:$info[3]");
+}
+else {
+   @permcmd = ("/bin/echo", "User account for apt-cacher/http daemon unknown, plese set ownership for the following files manually:");
+}
+
+for ("README", "README.txt") {
+   my $file=$config{cache_dir}."/$_";
+   if (-f $file) {
+      print "Found obsolete file $file - removing.\n";
+      unlink($file);
+   }
+}
+
+foreach my $dir ($config{cache_dir}, $config{logdir}, "$config{cache_dir}/private", "$config{cache_dir}/import",
+    "$config{cache_dir}/packages", "$config{cache_dir}/headers", "$config{cache_dir}/temp") {
+	if (!-d $dir) {
+		print "Doing mkdir($dir, 0755)\n";
+		mkdir($dir, 0755);
+    system (@permcmd, $dir);
+	}
+	if (!-w $dir) {
+		die "Warning, $dir exists but is not is not writeable for apt-cacher!\n";
+	}
+}
+
+# Remove these directories if they exist (obsolete)
+foreach my $rmdir ("$config{cache_dir}/tmp", "$config{cache_dir}/head") {
+	if (-d $rmdir) {
+		print "Doing 'rm -rf $rmdir' (obsolete)\n";
+		system("rm -rf $rmdir");
+	}
+}
+
+# At the moment we need to create empty access and error logs so apt-cacher
+# doesn't barf the first time it's run. Probably should change apt-cacher
+# so it can handle missing logs, and create them itself if required.
+for $file ($config{logfile}, $config{errorfile}) {
+   if(!-e $file) {
+      open(my $tmp, ">$file");
+      close($tmp);
+      system @permcmd, $file;
+   }
+}
+
+# These ownership changes are a cludge: need to make them check httpd.conf for the Apache
+# user and set ownership to that, and do it with Perl instead of shell
+# EB: fsck that, this may simply overwritte changes by the admin
+# `chown -R www-data.www-data $config{cache_dir}`;
+
+# We used to tack a line onto the end of apache.conf. Now we just symlink into conf.d
+if(-d "/etc/apache/conf.d" ){
+	symlink("/etc/apt-cacher/apache.conf","/etc/apache/conf.d/apt-cacher");
+}
+
+if(-d "/etc/apache-ssl/conf.d" ){
+	symlink("/etc/apt-cacher/apache.conf","/etc/apache-ssl/conf.d/apt-cacher");
+}
+
+if(-d "/etc/apache2/conf.d" ){
+	rename("/etc/apache2/conf.d/apt-cacher", "/etc/apache2/conf.d/apt-cacher.conf") || symlink("/etc/apt-cacher/apache.conf","/etc/apache2/conf.d/apt-cacher.conf");
+}
+
+# Apache2 needs the cgi module installed, which it isn't by default.
+if(-d "/etc/apache2/mods-enabled"){
+	symlink("/etc/apache2/mods-available/cgi.load","/etc/apache2/mods-enabled/cgi.load");
+}
+
+
+#vvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvv
+# Just for now we still have to try nuking old entries in httpd.conf,
+# because they may have been left behind previously. After a couple
+# more releases this should be removed from here and remove.pl
+
+# Remove the include lines from Apache's httpd.conf
+my $httpdconf = "/etc/apache/httpd.conf";
+if (-f $httpdconf) {
+	$old = $httpdconf;
+	$new = "$httpdconf.tmp.$$";
+	$bak = "$httpdconf.bak";
+	
+	open(OLD, "< $old")         or die "can't open $old: $!";
+	open(NEW, "> $new")         or die "can't open $new: $!";
+	
+	while (<OLD>) {
+		s/# This line has been appended by the Apt\-cacher install script/ /;
+		s/Include \/etc\/apt\-cacher\/apache.conf/ /;
+		(print NEW $_)          or die "can't write to $new: $!";
+	}
+	
+	close(OLD)                  or die "can't close $old: $!";
+	close(NEW)                  or die "can't close $new: $!";
+	
+	rename($old, $bak)          or die "can't rename $old to $bak: $!";
+	rename($new, $old)          or die "can't rename $new to $old: $!";
+	if (-f "/etc/init.d/apache")
+	{
+		`/etc/init.d/apache restart`;
+	}
+}
+
+# Remove the include lines from Apache-SSL's httpd.conf
+$httpdconf = "/etc/apache-ssl/httpd.conf";
+if (-f $httpdconf) {
+	$old = $httpdconf;
+	$new = "$httpdconf.tmp.$$";
+	$bak = "$httpdconf.bak";
+	
+	open(OLD, "< $old")         or die "can't open $old: $!";
+	open(NEW, "> $new")         or die "can't open $new: $!";
+	
+	while (<OLD>) {
+		s/# This line has been appended by the Apt\-cacher install script/ /;
+		s/Include \/etc\/apt\-cacher\/apache.conf/ /;
+		(print NEW $_)          or die "can't write to $new: $!";
+	}
+	
+	close(OLD)                  or die "can't close $old: $!";
+	close(NEW)                  or die "can't close $new: $!";
+	
+	rename($old, $bak)          or die "can't rename $old to $bak: $!";
+	rename($new, $old)          or die "can't rename $new to $old: $!";
+	if (-f "/etc/init.d/apache-ssl")
+	{
+		`/etc/init.d/apache-ssl restart`;
+	}
+}
+
+# Remove the include lines from Apache2's apache2.conf
+$httpdconf = "/etc/apache2/apache2.conf";
+if (-f $httpdconf) {
+        $old = $httpdconf;
+        $new = "$httpdconf.tmp.$$";
+        $bak = "$httpdconf.bak";
+
+        open(OLD, "< $old")         or die "can't open $old: $!";
+        open(NEW, "> $new")         or die "can't open $new: $!";
+
+        while (<OLD>) {
+                s/# This line has been appended by the Apt\-cacher install script/ /;
+                s/Include \/etc\/apt\-cacher\/apache.conf/ /;
+                (print NEW $_)          or die "can't write to $new: $!";
+        }
+
+        close(OLD)                  or die "can't close $old: $!";
+        close(NEW)                  or die "can't close $new: $!";
+
+        rename($old, $bak)          or die "can't rename $old to $bak: $!";
+        rename($new, $old)          or die "can't rename $new to $old: $!";
+	if (-f "/etc/init.d/apache2")
+	{
+		`/etc/init.d/apache2 restart`;
+	}
+}
+#^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
+
+exit(0);
diff -r 9ce9101b3e6b binary-overlay.xenrt/usr/share/apt-cacher/remove.pl
--- /dev/null	Thu Jan 01 00:00:00 1970 +0000
+++ b/binary-overlay.xenrt/usr/share/apt-cacher/remove.pl	Fri Mar 14 11:52:03 2008 +0000
@@ -0,0 +1,142 @@
+#!/usr/bin/perl -w
+#	@(#) remove.pl -- Remove script for apt-cacher
+#	$ Revision: $
+#	$ Source: $
+#	$ Date: $
+#
+
+my $path = $ENV{PATH_INFO};
+#############################################################################
+### configuration ###########################################################
+# Include the library for the config file parser
+require '/usr/share/apt-cacher/apt-cacher-lib.pl';
+
+# Read in the config file and set the necessary variables
+my $configfile = '/etc/apt-cacher/apt-cacher.conf';
+
+my $configref;
+eval {
+        $configref = read_config($configfile);
+};
+my %config = %$configref;
+
+# not sure what to do if we can't read the config file...
+die "Could not read config file: $@" if $@;
+
+# Now set some things from the config file
+# $logfile used to be set in the config file: now we derive it from $logdir
+$config{logfile} = "$config{logdir}/access.log";
+
+# $errorfile used to be set in the config file: now we derive it from $logdir
+$config{errorfile} = "$config{logdir}/error.log";
+
+my $private_dir = "$config{cache_dir}/private";
+
+################################################
+
+# Now set some things from the config file
+$config{reportfile} = "$config{logdir}/report.html";
+
+
+
+# Remove the include lines from Apache's httpd.conf
+# Thankfully this is a lot easier now we're just symlinking our config file!
+if(-d "/etc/apache/conf.d/" ){
+	unlink("/etc/apache/conf.d/apt-cacher");
+}
+
+if(-d "/etc/apache-ssl/conf.d/" ){
+	unlink("/etc/apache-ssl/conf.d/apt-cacher");
+}
+
+if(-d "/etc/apache2/conf.d/" ){
+	unlink("/etc/apache2/conf.d/apt-cacher");
+	unlink("/etc/apache2/conf.d/apt-cacher.conf");
+}
+
+
+# Delete the cache directory and everything in it, in the purge step
+#system("rm", "-rf", $config{cache_dir});
+
+# Delete the two log files (leaving the directory behind for now)
+unlink($config{logfile});
+unlink($config{errorfile});
+unlink($config{reportfile});
+
+#vvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvv
+# Just for now we still have to try nuking old entries in httpd.conf,
+# because they may have been left behind previously. After a couple
+# more releases this should be removed from here and install.pl
+
+# Remove the include lines from Apache's httpd.conf
+my $httpdconf = "/etc/apache/httpd.conf";
+if (-f $httpdconf) {
+	$old = $httpdconf;
+	$new = "$httpdconf.tmp.$$";
+	$bak = "$httpdconf.bak";
+	
+	open(OLD, "< $old")         or die "can't open $old: $!";
+	open(NEW, "> $new")         or die "can't open $new: $!";
+	
+	while (<OLD>) {
+		s/# This line has been appended by the Apt\-cacher install script/ /;
+		s/Include \/etc\/apt\-cacher\/apache.conf/ /;
+		(print NEW $_)          or die "can't write to $new: $!";
+	}
+	
+	close(OLD)                  or die "can't close $old: $!";
+	close(NEW)                  or die "can't close $new: $!";
+	
+	rename($old, $bak)          or die "can't rename $old to $bak: $!";
+	rename($new, $old)          or die "can't rename $new to $old: $!";
+}
+
+# Remove the include lines from Apache-SSL's httpd.conf
+$httpdconf = "/etc/apache-ssl/httpd.conf";
+if (-f $httpdconf) {
+	$old = $httpdconf;
+	$new = "$httpdconf.tmp.$$";
+	$bak = "$httpdconf.bak";
+	
+	open(OLD, "< $old")         or die "can't open $old: $!";
+	open(NEW, "> $new")         or die "can't open $new: $!";
+	
+	while (<OLD>) {
+		s/# This line has been appended by the Apt\-cacher install script/ /;
+		s/Include \/etc\/apt\-cacher\/apache.conf/ /;
+		(print NEW $_)          or die "can't write to $new: $!";
+	}
+	
+	close(OLD)                  or die "can't close $old: $!";
+	close(NEW)                  or die "can't close $new: $!";
+	
+	rename($old, $bak)          or die "can't rename $old to $bak: $!";
+	rename($new, $old)          or die "can't rename $new to $old: $!";
+}
+
+# Remove the include lines from Apache2's apache2.conf
+$httpdconf = "/etc/apache2/apache2.conf";
+if (-f $httpdconf) {
+        $old = $httpdconf;
+        $new = "$httpdconf.tmp.$$";
+        $bak = "$httpdconf.bak";
+
+        open(OLD, "< $old")         or die "can't open $old: $!";
+        open(NEW, "> $new")         or die "can't open $new: $!";
+
+        while (<OLD>) {
+                s/# This line has been appended by the Apt\-cacher install script/ /;
+                s/Include \/etc\/apt\-cacher\/apache.conf/ /;
+                (print NEW $_)          or die "can't write to $new: $!";
+        }
+
+        close(OLD)                  or die "can't close $old: $!";
+        close(NEW)                  or die "can't close $new: $!";
+
+        rename($old, $bak)          or die "can't rename $old to $bak: $!";
+        rename($new, $old)          or die "can't rename $new to $old: $!";
+}
+#^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
+
+
+exit(0);
diff -r 9ce9101b3e6b binary-overlay.xenrt/usr/share/apt-cacher/upgrade.pl
--- /dev/null	Thu Jan 01 00:00:00 1970 +0000
+++ b/binary-overlay.xenrt/usr/share/apt-cacher/upgrade.pl	Fri Mar 14 11:52:03 2008 +0000
@@ -0,0 +1,124 @@
+#!/usr/bin/perl -w
+#	@(#) remove.pl -- Upgrade script for apt-cacher
+#	$ Revision: $
+#	$ Source: $
+#	$ Date: $
+# This script is actually almost identical to the remove script, except that
+# on upgrade we don't want to nuke the cache contents so that part is commented
+# out. We also don't want to restart Apache twice (it already gets done by the
+# install script that gets run at the end of the upgrade, and even that's not
+# necessary).
+
+my $path = $ENV{PATH_INFO};
+#############################################################################
+### configuration ###########################################################
+# Include the library for the config file parser
+require '/usr/share/apt-cacher/apt-cacher-lib.pl';
+
+# Read in the config file and set the necessary variables
+my $configfile = '/etc/apt-cacher/apt-cacher.conf';
+
+my $configref;
+eval {
+        $configref = read_config($configfile);
+};
+my %config = %$configref;
+
+# not sure what to do if we can't read the config file...
+die "Could not read config file: $@" if $@;
+
+# Now set some things from the config file
+# $logfile used to be set in the config file: now we derive it from $logdir
+$config{logfile} = "$config{logdir}/access.log";
+
+# $errorfile used to be set in the config file: now we derive it from $logdir
+$config{errorfile} = "$config{logdir}/error.log";
+
+my $private_dir = "$config{cache_dir}/private";
+
+################################################
+
+# Now set some things from the config file
+$config{reportfile} = "$config{logdir}/report.html";
+
+
+
+
+# Remove the include lines from Apache's httpd.conf
+# This should really be turned into a function so I don't have to
+# copy the whole lot for Apache-SSL!
+my $httpdconf = "/etc/apache/httpd.conf";
+if (-f $httpdconf) {
+	$old = $httpdconf;
+	$new = "$httpdconf.tmp.$$";
+	$bak = "$httpdconf.bak";
+	
+	open(OLD, "< $old")         or die "can't open $old: $!";
+	open(NEW, "> $new")         or die "can't open $new: $!";
+	
+	while (<OLD>) {
+		s/# This line has been appended by the Apt\-cacher install script/ /;
+		s/Include \/etc\/apt\-cacher\/apache.conf/ /;
+		(print NEW $_)          or die "can't write to $new: $!";
+	}
+	
+	close(OLD)                  or die "can't close $old: $!";
+	close(NEW)                  or die "can't close $new: $!";
+	
+	rename($old, $bak)          or die "can't rename $old to $bak: $!";
+	rename($new, $old)          or die "can't rename $new to $old: $!";
+	
+	## Restart Apache
+	#if ( -f "/etc/init.d/apache" ) {
+	#	print "Restarting Apache (if you have an SSL cert password, enter it now):";
+	#	`/etc/init.d/apache restart`;
+	#	print "... done.\n";
+	#} else {
+	#	print "Apache startup script was not found. Please restart Apache manually.\n";
+	#}
+}
+
+# Remove the include lines from Apache-SSL's httpd.conf
+# This should really be turned into a function so I don't have to
+# copy the whole lot for Apache-SSL!
+$httpdconf = "/etc/apache-ssl/httpd.conf";
+if (-f $httpdconf) {
+	$old = $httpdconf;
+	$new = "$httpdconf.tmp.$$";
+	$bak = "$httpdconf.bak";
+	
+	open(OLD, "< $old")         or die "can't open $old: $!";
+	open(NEW, "> $new")         or die "can't open $new: $!";
+	
+	while (<OLD>) {
+		s/# This line has been appended by the Apt\-cacher install script/ /;
+		s/Include \/etc\/apt\-cacher\/apache.conf/ /;
+		(print NEW $_)          or die "can't write to $new: $!";
+	}
+	
+	close(OLD)                  or die "can't close $old: $!";
+	close(NEW)                  or die "can't close $new: $!";
+	
+	rename($old, $bak)          or die "can't rename $old to $bak: $!";
+	rename($new, $old)          or die "can't rename $new to $old: $!";
+	
+	## Restart Apache-SSL
+	#if ( -f "/etc/init.d/apache-ssl" ) {
+	#	print "Restarting Apache-SSL (if you have an SSL cert password, enter it now):";
+	#	`/etc/init.d/apache-ssl restart`;
+	#	print "... done.\n";
+	#} else {
+	#	print "Apache-SSL startup script was not found. Please restart Apache-SSL manually.\n";
+	#}
+}
+
+
+## Delete the cache directory and everything in it
+#system("rm -rf $config{cache_dir}");
+#
+## Delete the two log files (leaving the directory behind for now)
+#unlink($config{logfile});
+#unlink($config{errorfile});
+#unlink($config{reportfile});
+
+exit(0);
diff -r 9ce9101b3e6b binary-overlay.xenrt/usr/local/share/apt-cacher/etc/apache.conf
--- a/binary-overlay.xenrt/usr/local/share/apt-cacher/etc/apache.conf	Wed Feb 27 12:23:56 2008 +0000
+++ /dev/null	Thu Jan 01 00:00:00 1970 +0000
@@ -1,15 +0,0 @@
-Alias /apt-cacher /usr/local/share/apt-cacher/lib/apt-cacher.pl
-
-<DirectoryMatch /usr/local/share/apt-cacher/lib/>
-	Options ExecCGI
-	AddHandler cgi-script .pl
-	AllowOverride None
-	order allow,deny
-	allow from all
-</DirectoryMatch>
-
-RewriteEngine on
-RewriteRule ^/debian-security/(.*) /apt-cacher/security.debian.org/$1 [PT]
-RewriteRule ^/debian-amd64/(.*) /apt-cacher/amd64.debian.net/debian-amd64/$1 [PT]
-RewriteRule ^/debian/(.*) /apt-cacher/ftp.us.debian.org/debian/$1 [PT]
-RewriteRule ^/debian-backports/(.*) /apt-cacher/www.backports.org/debian/$1 [PT]
diff -r 9ce9101b3e6b binary-overlay.xenrt/usr/local/share/apt-cacher/etc/apt-cacher.conf
--- a/binary-overlay.xenrt/usr/local/share/apt-cacher/etc/apt-cacher.conf	Wed Feb 27 12:23:56 2008 +0000
+++ /dev/null	Thu Jan 01 00:00:00 1970 +0000
@@ -1,95 +0,0 @@
-#################################################################
-# This is the config file for apt-cacher. On most Debian systems
-# you can safely leave the defaults alone.
-#################################################################
-
-# cache_dir is used to set the location of the local cache. This can
-# become quite large, so make sure it is somewhere with plenty of space.
-cache_dir=/local/apt-cache
-
-# The email address of the administrator is displayed in the info page
-# and traffic reports.
-admin_email=admin@example.com
-
-# If your apt-cacher machine is directly exposed to the Internet and you are
-# worried about unauthorised machines fetching packages through it, you can
-# specify a list of IPv4 addresses which are allowed to use it and another
-# list of IPv4 addresses which aren't.
-# Localhost (127.0.0.1) is always allowed. Other addresses must be matched
-# by allowed_hosts and not by denied_hosts to be permitted to use the cache.
-# Setting allowed_hosts to "*" means "allow all".
-# Otherwise the format is a comma-separated list containing addresses,
-# optionally with masks (like 10.0.0.0/22), or ranges of addresses (two
-# addresses separated by a hyphen, no masks, like '192.168.0.3-192.168.0.56').
-allowed_hosts=*
-denied_hosts=
-
-# And similiarly for IPv6 with allowed_hosts_6 and denied_hosts_6.
-# Note that IPv4-mapped IPv6 addresses (::ffff:w.x.y.z) are truncated to
-# w.x.y.z and are handled as IPv4.
-allowed_hosts_6=fec0::/16
-denied_hosts_6=
-
-# This thing can be done by Apache but is much simplier here - limit access to
-# Debian mirrors based on server names in the URLs
-#allowed_locations=ftp.uni-kl.de,ftp.nerim.net,debian.tu-bs.de
-
-# Apt-cacher can generate usage reports every 24 hours if you set this
-# directive to 1. You can view the reports in a web browser by pointing
-# to your cache machine with '/apt-cacher/report' on the end, like this:
-#      http://yourcache.example.com/apt-cacher/report
-# Generating reports is very fast even with many thousands of logfile
-# lines, so you can safely turn this on without creating much 
-# additional system load.
-generate_reports=0
-
-# Apt-cacher can clean up its cache directory every 24 hours if you set
-# this directive to 1. Cleaning the cache can take some time to run
-# (generally in the order of a few minutes) and removes all package
-# files that are not mentioned in any existing 'Packages' lists. This
-# has the effect of deleting packages that have been superseded by an
-# updated 'Packages' list.
-clean_cache=0
-
-# The directory to use for apt-cacher access and error logs.
-# The access log records every request in the format:
-# date-time|client ip address|HIT/MISS/RELOAD|object size|object name
-# The error log is slightly more free-form, and is also used for debug
-# messages if debug mode is turned on.
-# Note that the old 'logfile' and 'errorfile' directives are
-# deprecated: if you set them explicitly they will be honoured, but it's
-# better to just get rid of them from old config files.
-logdir=/var/log/httpd/apt-cache
-
-# apt-cacher can use different methods to decide whether package lists need to
-# be updated,
-# A) looking at the age of the cached files
-# B) getting HTTP header from server and comparing that with cached data. This
-# method is more reliable and avoids desynchronisation of data and index files
-# but needs to transfer few bytes from the server every time somebody requests
-# the files ("apt-get update")
-# Set the following value to the maximum age (in hours) for method A or to 0
-# for method B
-expire_hours=0
-
-# Apt-cacher can pass all its requests to an external http proxy like
-# Squid, which could be very useful if you are using an ISP that blocks
-# port 80 and requires all web traffic to go through its proxy. The
-# format is 'hostname:port', eg: 'proxy.example.com:8080'.
-http_proxy=proxy.example.com:8080
-
-# Use of an external proxy can be turned on or off with this flag.
-# Value should be either 0 (off) or 1 (on):
-use_proxy=0
-
-# Rate limiting sets the maximum bandwidth in bytes per second to use
-# for fetching packages. Syntax is fully defined in 'man wget'.
-# Use 'k' or 'm' to use kilobits or megabits / second: eg, 'limit=25k'.
-# Use 0 or a negative value for no rate limiting.
-limit=0
-
-# Debug mode makes apt-cacher spew a lot of extra debug junk to the
-# error log (whose location is defined with the 'logdir' directive).
-# Leave this off unless you need it, or your error log will get very
-# big. Acceptable values are 0 or 1.
-debug=0
diff -r 9ce9101b3e6b binary-overlay.xenrt/usr/local/share/apt-cacher/etc/checksumming.conf
--- a/binary-overlay.xenrt/usr/local/share/apt-cacher/etc/checksumming.conf	Wed Feb 27 12:23:56 2008 +0000
+++ /dev/null	Thu Jan 01 00:00:00 1970 +0000
@@ -1,8 +0,0 @@
-# To enable data checksumming, install libdbd-sqlite3-perl and uncomment the
-# line below. Then wait untill the Packages/Sources files have been refreshed
-# once (and so the database has been built up). You can also nuke them in the
-# cache to trigger the update.
-# require '/usr/share/apt-cacher/apt-cacher-lib-cs.pl';
-
-# don't touch the following line
-1;
diff -r 9ce9101b3e6b binary-overlay.xenrt/usr/local/share/apt-cacher/lib/apt-cacher-cleanup.pl
--- a/binary-overlay.xenrt/usr/local/share/apt-cacher/lib/apt-cacher-cleanup.pl	Wed Feb 27 12:23:56 2008 +0000
+++ /dev/null	Thu Jan 01 00:00:00 1970 +0000
@@ -1,145 +0,0 @@
-#!/usr/bin/perl -w
-
-# apt-cacher-cleanup.pl
-# Script to clean the cache for the Apt-cacher package caching system.
-# For more information visit www.apt-cacher.org
-#
-# Copyright (C) 2005, Eduard Bloch <blade@debian.org>
-# Copyright (C) 2002-03, Jonathan Oxer <jon@debian.org>
-# Portions  (C) 2002, Jacob Lundberg <jacob@chaos2.org>
-# Distributed under the terms of the GNU Public Licence (GPL).
-
-
-# add one argument like 1 to make it verbose
-
-# do locking, not loosing files because someone redownloaded the index files
-# right then
-# use IO::Handle;
-use Fcntl ':flock';
-use IO::Handle;
-use POSIX;
-
-for(@ARGV) {
-   if($_ eq "-n") { $nice_mode=1; }
-   elsif ($_ eq "-v") { $verbose=1;}
-   else {
-      die <<EOM
-Usage: $0 [ -n ] [ -v ]
-      -n : nice mode, refresh index files first, then renice to 20 and continue
-      -v : verbose mode
-EOM
-      ;
-   }
-}
-
-sub printmsg {
-   print @_ if $verbose;
-}
-
-#use strict;
-#############################################################################
-### configuration ###########################################################
-# Include the library for the config file parser
-require '/usr/local/share/apt-cacher/lib/apt-cacher-lib.pl';
-
-# Read in the config file and set the necessary variables
-my $configfile = '/usr/local/share/apt-cacher/etc/apt-cacher.conf';
-
-my $configref;
-eval {
-        $configref = read_config($configfile);
-};
-my %config = %$configref;
-
-# not sure what to do if we can't read the config file...
-die "Could not read config file: $@" if $@;
-
-# check whether we're actually meant to clean the cache
-if ( $config{clean_cache} ne 1 ) {
-	exit 0;
-}
-
-#############################################################################
-
-my $refresh=1;
-
-#my %valid;
-
-@info = stat $config{cache_dir};
-
-#if ($< != $info[4]) {
-#   $refresh=0;
-#   print "Not running with apt-cacher's user ID, won't refresh the index files.
-#Try sth. like su -c /usr/share/apt-cacherapt-cacher-cleanup.pl www-data
-#";
-#   # that's not critical, will just hurt the apt-qupdate/apt-dupdate users
-#}
-#
-#
-### Preparation of the package lists ########################################
-
-chdir "$config{cache_dir}/packages" && -w "." || die "Could not enter the cache dir";
-
-@ifiles=(<*es.gz>, <*es.bz2>, <*es>);
-for (@ifiles) {
-   printmsg "Processing index: $_\n";
-   die "Someone is cheating, bad filename found: $_" if /[^.\-\w]/;
-
-   # preserve the index files
-   $valid{$_}=1;
-
-   # now refresh them, unless disabled by the setting above
-   if($refresh) {
-      $ENV{"REMOTE_ADDR"}="local";
-      # if the path is stored there, better use that
-      if(-s "../private/$_.complete") {
-         open(my $tmp, "../private/$_.complete");
-         $ENV{"PATH_INFO"}=<$tmp>;
-         close $tmp;
-      }
-      if(!$ENV{"PATH_INFO"}) {
-         my $tmp=$_;
-         $tmp=~s/^/\//;
-         $tmp=~s/_/\//;
-      }
-      if($ENV{"PATH_INFO"}) {
-         system "/usr/local/share/apt-cacher/lib/apt-cacher.pl >/dev/null";
-         # fix the permissions, apt-cacher can have been executed as root
-         chown $info[4], $info[5], $_, "../private/$_.complete", "../headers/$_";
-      }
-   }
-}
-
-setpriority 0, 0, 20 if $nice_mode;
-
-# use the list of config files we already know
-for(@ifiles) { extract_sums($_, \%valid);}
-
-printmsg "Found ".scalar (keys %valid)." valid file entries\n";
-#print join("\n",keys %valid);
-
-for(<*.deb>, <*.bz2>, <*.gz>, <*.dsc>) {
-   if(! defined($valid{$_})) {
-      unlink $_, "../headers/$_", "../private/$_.complete";
-      printmsg "Removing: $_ and company...\n";
-   }
-}
-
-# similar thing for possibly remaining cruft
-chdir "$config{cache_dir}/headers" && -w "." || die "Could not enter the cache dir";
-
-for(<*.deb>, <*.bz2>, <*.gz>, <*.dsc>) {
-   if(! defined($valid{$_})) {
-      unlink $_, "../private/$_.complete";
-      printmsg "Removing: $_ and company...\n";
-   }
-}
-
-chdir "$config{cache_dir}/private" && -w "." || die "Could not enter the cache dir";
-for(<*.deb.complete>, <*.bz2.complete>, <*.gz.complete>, <*.dsc.complete>) {
-   s/.complete$//;
-   if(! defined($valid{$_})) {
-      printmsg "Removing: $_.complete\n";
-      unlink "$_.complete";
-   }
-}
diff -r 9ce9101b3e6b binary-overlay.xenrt/usr/local/share/apt-cacher/lib/apt-cacher-format-transition.pl
--- a/binary-overlay.xenrt/usr/local/share/apt-cacher/lib/apt-cacher-format-transition.pl	Wed Feb 27 12:23:56 2008 +0000
+++ /dev/null	Thu Jan 01 00:00:00 1970 +0000
@@ -1,36 +0,0 @@
-#!/usr/bin/perl
-die "Please specify the cache directory!\n" if !$ARGV[0];
-
-chdir $ARGV[0] || die "Could not enter the cache directory!";
-
-@info = stat("private");
-
-mkdir "packages";
-mkdir "headers";
-chown $info[4], $info[5], "packages", "headers";
-
-for $fname (<*.deb>, <*pgp>, <*gz>, <*bz2>, <*Release>) {
-   my $data=0;
-   my $size=0;
-   open(in, $fname);
-   open(daten, ">packages/$fname");
-   open(header, ">headers/$fname");
-   while(<in>) {
-      if($data) { print daten $_; next; };
-      print header $_;
-      $size=$1 if /^Content-Length: (\d+)/;
-      $data=1 if /^$/;
-   }
-   close(daten);
-   close(header);
-   @statinfo = stat("packages/$fname");
-   if($size == $statinfo[7]) {
-      chown $info[4], $info[5], "packages/$fname", "headers/$fname";
-      utime $statinfo[9], $statinfo[9], "packages/$fname", "headers/$fname";
-      unlink $fname;
-   }
-   else {
-      unlink "packages/$fname";
-      unlink "headers/$fname";
-   }
-}
diff -r 9ce9101b3e6b binary-overlay.xenrt/usr/local/share/apt-cacher/lib/apt-cacher-import.pl
--- a/binary-overlay.xenrt/usr/local/share/apt-cacher/lib/apt-cacher-import.pl	Wed Feb 27 12:23:56 2008 +0000
+++ /dev/null	Thu Jan 01 00:00:00 1970 +0000
@@ -1,121 +0,0 @@
-#!/usr/bin/perl -w
-
-# apt-cacher-import.pl
-# Script to import .deb packages into the Apt-cacher package caching system.
-# This script does not need to be run when setting up Apt-cacher for the first
-# time: its purpose is to initialise .deb packages that have been copied in
-# from some other source, such as a local mirror. Apt-cacher doesn't store
-# it's cached .debs in plain format, it prepends HTTP headers to them to send
-# out to clients when a package is requested. It also keeps track of which
-# packages are fully downloaded by touching a '.complete' file in the 'private'
-# directory in the cache. If .debs are just copied straight into the cache
-# dir Apt-cacher won't use them because it thinks they are both corrupt (no
-# headers) and incomplete (no .complete file). This script allows you to
-# copy a bunch of .debs into an import dir, then run this script to prepend
-# the HTTP headers and touch the .complete file after moving them to the cache
-# dir.
-#
-# Usage:
-# 1. Place your plain debs into /var/cache/apt-cacher/import (or where-ever
-#    you set the cache dir to be)
-# 2. Run this script: /usr/share/apt-cacher-import.pl
-#
-# For more information visit www.apt-cacher.org
-#
-# Copyright (C) 2004, Jonathan Oxer <jon@debian.org>
-# Distributed under the terms of the GNU Public Licence (GPL).
-
-#use strict;
-#############################################################################
-### configuration ###########################################################
-# Include the library for the config file parser
-require '/usr/local/share/apt-cacher/lib/apt-cacher-lib.pl';
-
-# Read in the config file and set the necessary variables
-my $configfile = '/usr/local/share/apt-cacher/etc/apt-cacher.conf';
-
-my $configref;
-eval {
-        $configref = read_config($configfile);
-};
-my %config = %$configref;
-
-# not sure what to do if we can't read the config file...
-die "Could not read config file: $@" if $@;
-
-my $private_dir = "$config{cache_dir}/private";
-my $import_dir = "$config{cache_dir}/import";
-my $target_dir = "$config{cache_dir}/packages";
-my $header_dir = "$config{cache_dir}/headers";
-
-my $packagesimported = 0;
-
-#############################################################################
-
-if(!$ARGV[0]) {
-   syswrite(STDOUT, "No import directory specified as the first argument, using $import_dir\n");
-   sleep 2;
-}
-else {
-   $import_dir=$ARGV[0];
-}
-
-die "Cannot write to $target_dir" if !-w $target_dir;
-die "Cannot write to $header_dir" if !-w $header_dir;
-
-@info = stat($private_dir);
-
-# Move to the import dir to chomp on the actual .deb packages
-chdir("$import_dir") || die "apt-cacher-import.pl: can't open the import directory ($import_dir)";
-
-### Loop through all the .debs in the import dir
-foreach $packagefile ( <*.deb>, <*.gz>, <*.bz2> ) {
-	
-	
-	# Get some things we need to insert into the header
-	$headerdate = `date +"%a, %d %b %Y %X %Z"`;
-	$headerdate =~ s/^\s*(.*?)\s*$/$1/;
-	($jk,$jk,$jk,$jk,$jk,$jk,$jk,$headerlength,$jk,$jk,$jk,$jk,$jk) = stat($packagefile);
-	$headeretag = `date +%H%m%s%N`;
-	$headeretag =~ s/^\s*(.*?)\s*$/$1/;
-	#print "d: $headerdate, l: $headerlength, e: $headeretag\n";
-  $frompackagefile=$packagefile; # backup of the original name
-  $packagefile=~s/_\d+%3a/_/;
-		
-	# Generate a header
-	$httpheader = "HTTP/1.1 200 OK
-Date: ".$headerdate."
-Server: Apache \(Unix\) apt-cacher
-Last-Modified: ".$headerdate."
-ETag: \"".$headeretag."\"
-Accept-Ranges: bytes
-Content-Length: ".$headerlength."
-Keep-Alive: timeout=10, max=128
-Connection: Keep-Alive
-Content-Type: application/x-debian-package
-
-"; # there are TWO new lines
-		
-	# Then cat the header to a temp file
-	print "Importing: $packagefile\n";
-  unlink "$header_dir/$packagefile", "$target_dir/$packagefile",  "$private_dir/$packagefile.complete"; # just to be sure
-  rename($frompackagefile, "$target_dir/$packagefile");
-  open($headfile, ">$header_dir/$packagefile");
-  print $headfile $httpheader;
-  close $headfile;
-		
-	$completefile = "$private_dir/$packagefile.complete";
-	open(MF, ">$completefile");
-  close(MF);
-  # copy the ownership of the private directory
-  chown $info[4], $info[5], "$header_dir/$packagefile", "$target_dir/$packagefile",  "$private_dir/$packagefile.complete";
-
-	$packagesimported++;
-}
-
-print "Done.\n";
-print "Packages imported: $packagesimported\n";
-
-# Woohoo, all done!
-exit 0;
-
diff -r 9ce9101b3e6b binary-overlay.xenrt/usr/local/share/apt-cacher/lib/apt-cacher-lib-cs.pl
--- a/binary-overlay.xenrt/usr/local/share/apt-cacher/lib/apt-cacher-lib-cs.pl	Wed Feb 27 12:23:56 2008 +0000
+++ /dev/null	Thu Jan 01 00:00:00 1970 +0000
@@ -1,82 +0,0 @@
-#! /usr/bin/perl
-
-# this are hooks the overload the methods in apt-cacher-lib.pl and implement
-# data checksumming methods
-
-use DBI;
-use Fcntl ':flock';
-use IO::Handle;
-use POSIX;
-use Digest::MD5 qw(md5_hex);
-
-
-my $ctx;
-my $dbfile;
-my $dbh;
-my $dblck;
-
-sub dbauf {
-   open($dblck, $dbfile);
-   flock($dblck, LOCK_EX);
-   $dbh = DBI->connect("dbi:SQLite:dbname=$dbfile","", "",
-   { RaiseError => 1, AutoCommit => 0 } );
-}
-
-sub dbzu {
-   $dbh->disconnect;
-   flock($dblck, LOCK_UN);
-   close($dblck);
-}
-
-# arg: file to be scanned and added to DB
-sub import_sums {
-   my %sumhash;
-   extract_sums(shift, \%sumhash);
-   dbauf();
-   for(keys %sumhash) {
-      #$dbh->do("insert or ignore into sums values(\"$_\", \"$sumhash{sum}\");");
-      $dbh->do("replace into sums values(\"$_\", \"".$sumhash{$_}."\");");
-   }
-   $dbh->commit;
-   dbzu();
-}
-
-sub db_init {
-   $dbfile=shift;
-   if(!-s $dbfile) { 
-      open $db, ">$dbfile"; close $db; # touch it
-      dbauf();
-      $dbh->do("CREATE TABLE sums (file varchar PRIMARY KEY, sum varchar(32) NOT NULL);");
-      $dbh->commit;
-      dbzu();
-   }
-}
-
-# purpose: create hasher object
-sub data_init {
-   $ctx = Digest::MD5->new;
-   return 1;
-}
-
-# purpose: append data to be scanned
-sub data_feed {
-   $ref=shift;
-   $ctx->add($$ref);
-}
-
-# arg: filename
-sub check_sum {
-   my $file=shift;
-   my $digest = $ctx->hexdigest;
-   dbauf();
-   my @sqlar = $dbh->selectrow_array("select sum from sums where file='$file'");
-   dbzu();
-   if(defined($sqlar[0]) && $sqlar[0] ne '') {
-      # now find the faulty deb
-      return ($sqlar[0] eq $digest);
-   }
-   return 1;
-}
-
-
-1;
diff -r 9ce9101b3e6b binary-overlay.xenrt/usr/local/share/apt-cacher/lib/apt-cacher-lib.pl
--- a/binary-overlay.xenrt/usr/local/share/apt-cacher/lib/apt-cacher-lib.pl	Wed Feb 27 12:23:56 2008 +0000
+++ /dev/null	Thu Jan 01 00:00:00 1970 +0000
@@ -1,167 +0,0 @@
-#! /usr/bin/perl
-# This is a library file for Apt-cacher to allow code
-# common to Apt-cacher itself plus its supporting scripts
-# (apt-cacher-report.pl and apt-cacher-cleanup.pl) to be
-# maintained in one location.
-
-# This function reads the given config file into the
-# given hash ref. The key and value are separated by
-# a '=' and will have all the leading and trailing 
-# spaces removed.
-sub read_config
-{
-	# set the default config variables
-	my $config = {
-			cache_dir => '/var/log/cache/apt-cacher',
-			logdir => '/var/log/apt-cacher',
-			admin_email => 'root@localhost',
-			generate_reports => 0,
-			expire_hours => 36,
-			http_proxy => 'proxy.example.com:8080',
-			use_proxy => 0,
-			debug => 0,
-			clean_cache => 0,
-	};
-
-	($config_file) = @_;
-
-	open CONFIG, $config_file or die $!;
-
-	while (<CONFIG>)
-	{
-		s/#.*$//;	# kill off comments
-		s/^\s+//;	# kill off leading spaces
-		s/\s+$//;	# kill off trailing spaces
-		if ($_)
-		{
-			my ($key, $value) = split(/\s*=\s*/);	# split into key and value pair
-			$value = 0 unless ($value);
-			#print "key: $key, value: $value\n";
-			$config->{$key} = $value;
-			#print "$config{$key}\n";
-		}
-	}
-
-	close CONFIG;
-
-	return $config;
-}
-
-# Convert a human-readable IPv4 address to raw form (4-byte string)
-# Returns undef if the address is invalid
-sub ipv4_normalise ($)
-{
-	return undef if $_[0] =~ /:/;
-	my @in = split (/\./, $_[0]);
-	return '' if $#in != 3;
-	my $out = '';
-	foreach my $num (@in)
-	{
-		return undef if $num !~ /^[[:digit:]]{1,3}$/o;
-		$out .= pack ("C", $num);
-	}
-	return $out;
-}
-
-# Convert a human-readable IPv6 address to raw form (16-byte string)
-# Returns undef if the address is invalid
-sub ipv6_normalise ($)
-{
-	return "\0" x 16 if $_[0] eq '::';
-	return undef if $_[0] =~ /^:[^:]/  || $_[0] =~ /[^:]:$/ || $_[0] =~ /::.*::/;
-	my @in = split (/:/, $_[0]);
-	return undef if $#in > 7;
-	shift @in if $#in >= 1 && $in[0] eq '' && $in[1] eq ''; # handle ::1 etc.
-	my $num;
-	my $out = '';
-	my $tail = '';
-	while (defined ($num = shift @in) && $num ne '')
-	{
-		return undef if $num !~ /^[[:xdigit:]]{1,4}$/o;
-		$out .= pack ("n", hex $num);
-	}
-	foreach $num (@in)
-	{
-		return undef if $num !~ /^[[:xdigit:]]{1,4}$/o;
-		$tail .= pack ("n", hex $num);
-	}
-	my $l = length ($out.$tail);
-	return $out.("\0" x (16 - $l)).$tail if $l < 16;
-	return $out.$tail if $l == 16;
-	return undef;
-}
-
-# Make a netmask from a CIDR network-part length and the IP address length
-sub make_mask ($$)
-{
-	my ($mask, $bits) = @_;
-	return undef if $mask < 0 || $mask > $bits;
-	my $m = ("\xFF" x ($mask / 8));
-	$m .= chr ((-1 << (8 - $mask % 8)) & 255) if $mask % 8;
-	return $m . ("\0" x ($bits / 8 - length ($m)));
-}
-
-sub extract_sums {
-   $_=shift;
-   $hashref=shift;
-
-   my ($cat, $listpipe);
-   $cat = (/bz2$/ ? "bzcat" : (/gz$/ ? "zcat" : "cat"));
-
-   # lock it or wait
-   open($lck, $_);
-   flock($lck, LOCK_EX);
-
-   open($listpipe, "-|", $cat, $_);
-   my $file;
-   while(<$listpipe>) {
-      if(/^\s(\w{32})\s\d+\s(\S+)\n/) {
-         $sum=$1;
-         $file=$2;
-      }
-      elsif(/^MD5sum:\s+(.*)$/) {
-         $sum=$1;
-      }
-      elsif(/^Filename:\s+(.*)$/) {
-         $file=$1;
-         $file=~s/.*\///;
-      }
-      if(defined($file) && defined($sum)) {
-         $$hashref{$file}=$sum;
-         undef $file;
-         undef $sum;
-      }
-   };
-   flock($lck, LOCK_UN);
-}
-
-######### HOOKS ###########
-#
-# arg: file to be scanned and added to DB
-sub import_sums {
-   return 1;
-}
-
-# purpose: ?create?, lock the DB file and establish DB connection
-sub db_init {
-   return 1;
-}
-
-# purpose: create hasher object
-sub data_init {
-   return 1;
-}
-
-# purpose: append data to be scanned
-sub data_feed {
-   return 1;
-}
-
-# args: filename only or filename and sum
-sub check_sum {
-   return 1;
-}
-
-
-
-1;
diff -r 9ce9101b3e6b binary-overlay.xenrt/usr/local/share/apt-cacher/lib/apt-cacher-report.pl
--- a/binary-overlay.xenrt/usr/local/share/apt-cacher/lib/apt-cacher-report.pl	Wed Feb 27 12:23:56 2008 +0000
+++ /dev/null	Thu Jan 01 00:00:00 1970 +0000
@@ -1,231 +0,0 @@
-#!/usr/bin/perl -w
-
-# apt-cacher-report.pl
-# Script to generate usage reports for the Apt-cacher package caching system.
-#
-# Copyright (C) 2002,2004 Jonathan Oxer <jon@debian.org>
-# Distributed under the terms of the GNU Public Licence (GPL).
-
-#use strict;
-#############################################################################
-### configuration ###########################################################
-# Include the library for the config file parser
-require '/usr/local/share/apt-cacher/lib/apt-cacher-lib.pl';
-
-# Read in the config file and set the necessary variables
-my $configfile = '/usr/local/share/apt-cacher/etc/apt-cacher.conf';
-
-my $configref;
-eval {
-        $configref = read_config($configfile);
-};
-my %config = %$configref;
-
-# not sure what to do if we can't read the config file...
-die "Could not read config file: $@" if $@;
-
-# check whether we're actually meant to generate a report
-if ( $config{generate_reports} ne 1 ){
-	exit 0;
-}
-
-# Now set some things from the config file
-# $logfile used to be set in the config file: now we derive it from $logdir
-my $logfile = "$config{logdir}/access.log";
-
-
-###################################################
-# Read in the logfiles if they exist, from oldest to newest
-
-# First we look for rolled and compressed logfiles, from
-# /var/log/apt-cacher/access.log.12.gz to access.log.2.gz
-$logcount = 12;
-while ($logcount > 1)
-{
-	if (-f "${logfile}.$logcount.gz") {
-		$logdataraw = `zcat ${logfile}.$logcount.gz`;
-		push (@logdata, split("\n", $logdataraw));
-	}
-	$logcount--;
-}
-
-# Then the immediately rolled (but uncompressed) log
-if (-f "${logfile}.1") {
-	open(LOGFILE, "<${logfile}.1");
-	#@logdata = <LOGFILE>;
-	push(@logdata, <LOGFILE>);
-	close(LOGFILE);
-}
-
-# Then finally the current working log
-if (-f "${logfile}") {
-	open(LOGFILE, "<$logfile");
-	push(@logdata, <LOGFILE>);
-	close(LOGFILE);
-}
-
-#read current time
-($second,$minute,$hour,$day,$month,$year,$null,$null,$null)=localtime(time);
-
-$year = $year + 1900;
-$month=$month + 1;
-
-my $hit_count = 0;
-my $hit_bytes = 0;
-my $miss_count = 0;
-my $miss_bytes = 0;
-
-#parse logfile:
-foreach $logfile_line (@logdata)
-{
-	#$logfile_line =~ s/ /\+/g;
-	@line = split /\|/, $logfile_line;
-	$req_date = $line[0];
-#	$req_ip   = $line[1];
-	$req_result = $line[2];
-	$req_bytes  = $line[3];
-#	$req_object = $line[4];
-
-	$lastrecord = $req_date;
-	if(!$firstrecord) {
-		$firstrecord = $req_date;
-	}
-	if ( $req_result eq "HIT" )
-	{
-		$hit_count++;
-		$hit_bytes += $req_bytes;
-	}
-	else
-	{
-		$miss_count++;
-		$miss_bytes += $req_bytes;
-	}
-
-}
-
-my $total_count = $hit_count + $miss_count;
-
-if($total_count eq 0)
-{
-	$hit_count_percent = 0;
-	$miss_count_percent = 0;
-} else {
-	$hit_count_percent = (int(($hit_count / $total_count) * 10000)) / 100;
-	$miss_count_percent = (int(($miss_count / $total_count) * 10000)) / 100;
-}
-
-$total_bytes = $hit_bytes + $miss_bytes;
-
-##################################################
-# At this point we have hit/miss/total counts, and hit/miss/total traffic
-# So now we need to decide what units to use for each one, and set a
-# human-readable string. Displays as MB unless > 2000MB, in which case it
-# displays as GB.
-# Yes, I know this really should be a subroutine. Sigh. One day. Maybe.
-
-if($total_bytes > 2097152000)
-{
-	$tx = (int(($total_bytes/1073741824) * 1000)) / 1000;
-	$total_trafficstring = "$tx GB";
-} else {
-	$tx = (int(($total_bytes/1048576) * 1000)) / 1000;
-	$total_trafficstring = "$tx MB";
-}
-
-if($hit_bytes > 2097152000)
-{
-        $tx = (int(($hit_bytes/1073741824) * 1000)) / 1000;
-        $hit_trafficstring = "$tx GB";
-} else {
-        $tx = (int(($hit_bytes/1048576) * 1000)) / 1000;
-        $hit_trafficstring = "$tx MB";
-}
-
-if($miss_bytes > 2097152000)
-{
-        $tx = (int(($miss_bytes/1073741824) * 1000)) / 1000;
-        $miss_trafficstring = "$tx GB";
-} else {
-        $tx = (int(($miss_bytes/1048576) * 1000)) / 1000;
-        $miss_trafficstring = "$tx MB";
-}
-
-
-##################################################
-# Set percentages to 0 if no records, otherwise calculate
-if($total_bytes eq 0)
-{
-	$hit_data_percent = 0;
-	$miss_data_percent = 0;
-} else {
-	$hit_data_percent = (int(($hit_bytes / $total_bytes) * 10000)) / 100;
-	$miss_data_percent = (int(($miss_bytes / $total_bytes) * 10000)) / 100;
-}
-
-##################################################
-# If there weren't actually any logfiles processed these will be null, so we'll
-# set them to strings
-if(!$firstrecord)
-{
-	$firstrecord = "unknown";
-}
-if(!$lastrecord)
-{
-	$lastrecord = "unknown";
-}
-
-##################################################
-# spit out the report
-$output = "
-<html>
-<title>Apt-cacher traffic report</title><style type=\"text/css\"><!--
-a { text-decoration: none; }
-a:hover { text-decoration: underline; }
-h1 { font-family: arial, helvetica, sans-serif; font-size: 18pt; font-weight: bold;}
-h2 { font-family: arial, helvetica, sans-serif; font-size: 14pt; font-weight: bold;}
-body, td { font-family: arial, helvetica, sans-serif; font-size: 10pt; }
-th { font-family: arial, helvetica, sans-serif; font-size: 11pt; font-weight: bold; }
-//--></style>
-</head>
-<body>";
-
-#	print "<html><head><title>Apt-cacher traffic report</title></head>\n";
-#	print "<body bgcolor=\"#ffffff\">\n";
-
-$output .= "<p>
-<table border=0 cellpadding=8 cellspacing=1 bgcolor=\"#000000\" align=\"center\" width=\"600\">
-<tr bgcolor=\"#9999cc\"><td> <h1>Apt-cacher traffic report</h1> </td></tr>
-<tr bgcolor=\"#cccccc\"><td>For more information on apt-cacher visit <a href=\"http://packages.debian.org/apt-cacher\">http://packages.debian.org/apt-cacher</a>.
-</td></tr>
-</table>";
-
-$output .= "<h2 align=\"center\">summary</h2>
-<table border=0 cellpadding=3 cellspacing=1 bgcolor=\"#000000\" align=\"center\" width=\"600\">
-<tr bgcolor=\"#9999cc\"><th bgcolor=\"#9999cc\"> Item </th><th> Value </th></tr>
-<tr bgcolor=\"#cccccc\"><td bgcolor=\"#ccccff\"> Report generated </td><td> $hour:$minute:$second $day/$month/$year </td></tr>
-<tr bgcolor=\"#cccccc\"><td bgcolor=\"#ccccff\"> Administrator </td><td> <a href=\"mailto:$config{admin_email}\">$config{admin_email}</a> </td></tr>";
-$output .= "<tr bgcolor=\"#cccccc\"><td bgcolor=\"#ccccff\"> First request </td><td> $firstrecord </td></tr>";
-$output .= "<tr bgcolor=\"#cccccc\"><td bgcolor=\"#ccccff\"> Last request </td><td> $lastrecord </td></tr>";
-$output .= "<tr bgcolor=\"#cccccc\"><td bgcolor=\"#ccccff\"> Total requests </td><td> $total_count </td></tr>";
-$output .= "<tr bgcolor=\"#cccccc\"><td bgcolor=\"#ccccff\"> Total traffic </td><td> $total_trafficstring </td></tr>";
-$output .= "</table>";
-
-$output .= "<h2 align=\"center\">cache efficiency</h2>
-<table border=0 cellpadding=3 cellspacing=1 bgcolor=\"#000000\" align=\"center\" width=\"600\">
-<tr bgcolor=\"#9999cc\"><th></th><th>Cache hits</th><th>Cache misses</th><th>Total</th></tr>\n
-<tr bgcolor=\"#cccccc\"><td bgcolor=\"#ccccff\"> Requests </td><td>$hit_count ($hit_count_percent%)</td><td>$miss_count ($miss_count_percent%)</td><td>$total_count</td></tr>\n
-<tr bgcolor=\"#cccccc\"><td bgcolor=\"#ccccff\"> Transfers </td><td>$hit_trafficstring ($hit_data_percent%)</td><td>$miss_trafficstring ($miss_data_percent%)</td><td>$total_trafficstring</td></tr>\n
-</table>";
-	
-$output .= "</body></html>\n";
-
-#print $output;
-my $report_file = "$config{logdir}/report.html";
-`touch $report_file`;
-open(REPORT,">$report_file") or die;
-print REPORT "$output\n";
-close REPORT;
-
-
-exit 0;
-
diff -r 9ce9101b3e6b binary-overlay.xenrt/usr/local/share/apt-cacher/lib/apt-cacher.pl
--- a/binary-overlay.xenrt/usr/local/share/apt-cacher/lib/apt-cacher.pl	Wed Feb 27 12:23:56 2008 +0000
+++ /dev/null	Thu Jan 01 00:00:00 1970 +0000
@@ -1,1075 +0,0 @@
-#!/usr/bin/perl
-#	apt-cacher.pl - CGI to provide a local cache for debian packages and release files and .deb files
-#
-#  $Revision: 1.11 $
-#  $Source: /xenu/nick/CVS-TREE/Src/Apt-cacher/apt-cacher.pl,v $
-#  $Date: 2002/01/24 23:11:12 $
-#
-#  Usage: run from apache, which provides this environment variable:
-#	PATH_INFO=/www.domain.name/some/path/filename
-
-=head1 NAME
-
- apt-cacher.pl - CGI to provide a cache for downloaded Debian packages
-
- Copyright (C) 2001 Nick Andrew <nick@zeta.org.au>
- Copyright (C) 2002-2004 Jonathan Oxer <jon@debian.org>
- Copyright (C) 2002 Raphael Goulais <raphael@nicedays.net>
- Copyright (C) 2002 Jacob Luna Lundberg <jacob@chaos2.org>
- Copyright (C) 2003 Daniel Stone <dstone@kde.org>
- Copyright (C) 2003 Adam Moore <adam@ihug.co.nz>
- Copyright (C) 2003 Andreas Boeckler <abo@netlands.de>
- Copyright (C) 2003 Stephan Niemz <st.n@gmx.net>
- Copyright (C) 2005 Darren Salt <linux@youmustbejoking.demon.co.uk>
- Copyright (C) 2005 Eduard Bloch <blade@debian.org>
- Distributed under the terms of the GNU Public Licence (GPL).
-
-=head1 SYNOPSIS
-
- copy apt-cacher.pl to your apache cgi-bin directory
- ./setup.pl /home/me/cache
- edit /etc/apt/sources.list
- apt-get update
- apt-get -u upgrade
-
-=head1 DESCRIPTION
-
-If you have two or more Debian GNU/Linux machines on a fast local
-network and you wish to upgrade packages from the Internet, you
-don't want to download every package several times.
-
-apt-cacher.pl is a CGI which will keep a cache on disk of Debian Packages
-and Release files (including .deb files) which have been received from Debian
-distribution servers on the Internet. When an apt-get client issues
-a request for a file to apt-cacher.pl, if the file is already on disk
-it is served to the client immediately, otherwise it is fetched from
-the Internet, saved on disk, and then served to the client. This means
-that several Debian machines can be upgraded but each package need be
-downloaded only once.
-
-To use this CGI you need a web server which supports CGI and a local
-directory with plenty of free space (100 Mbytes or more, depends on the
-requirements of the cache using client systems).
-
-=head1 INSTALLATION
-
-Assuming your web server is called B<www.myserver.com:80>
-and your cache directory is called B</home/me/cache>, then:
-
-1. Copy apt-cacher.pl to your web server's cgi-bin directory
-
-2. Make sure apt-cacher.pl is executable (chmod a+rx apt-cacher.pl)
-
-3. Edit apt-cacher.pl and set $cache_dir to /home/me/cache
-
-4. Make sure apt-cacher.pl is ok to run (B<perl -Mstrict -wc apt-cacher.pl>)
-
-5. Run B<./setup.pl /home/me/cache> to create necessary directories
-
-6. Make sure your client machines can access http://www.myserver.com:80/cgi-bin/apt-cacher.pl
-
-If the CGI is executed without arguments, it will return a text/plain
-error message.
-
-7. Edit your /etc/apt/sources.list files, as follows. Where a line says
-something like:
-
-deb http://http.us.debian.org/debian testing main contrib non-free
-
-change this to:
-
-deb http://www.myserver.com:80/cgi-bin/apt-cacher.pl/http.us.debian.org/debian testing main contrib non-free
-
-8. Do "apt-get update" as root. This will prime the cache directory with the
-Package or Package.gz and Release files from the servers you used to use
-directly.
-
-9. Do "ls -laR /home/me/cache" to verify that files have been received and
-stored. The "/home/me/cache/tmp" directory should be empty after downloads
-have completed.
-
-10. Do "apt-get update; apt-get -u upgrade" to start upgrading each machine.
-
-=head1 CACHE DIRECTORY CONTENTS
-
-apt-cacher.pl considers all .deb files with exactly the same filename
-should be the same package (for example vim-rt_5.8.007-4_all.deb) no
-matter where they are downloaded from, so these files are stored in
-the cache directory using just the filename.
-
-Packages and Release files (including Packages.gz) are potentially
-different for every server and directory, so these files are stored
-in the cache directory with the full hostname and path to the file,
-with all slashes B</> changed to underscores B<_> (in the same
-manner as apt-get names the files in B</var/lib/apt/lists>).
-
-=head1 BUGS and FEATURES
-
-1. Only HTTP is supported at present (i.e. apt-cacher.pl cannot access an
-FTP URL)
-
-2. apt-cacher.pl probably only works with the Apache webserver, because
-it relies on the webserver supplying the PATH_INFO environment variable. There
-is alternative method with standard compliant CGI environment but it needs more
-testing, and it needs additonal config on the client side to work around APT's
-bugs.
-
-3. apt-cacher.pl uses B<curl> to retrieve files, so wget must be
-installed.
-
-4. (this bug has been squashed)
-
-5. (this bug has been squashed)
-
-6. (this bug has been squashed)
-
-7. (this bug has been squashed)
-
-8. apt-get can resume a partial failed transfer, however apt-cacher.pl
-cannot.
-
-9. (fixed)
-
-10. (fixed)
-
-11. (fixed)
-
-12. (this bug has been squashed)
-
-=head1 ENVIRONMENT VARIABLES
-
-B<PATH_INFO> is used to find the full URL for the requested file
-
-B<QUERY_STRING> fallback path to get host/url from, for non-apache http daemons
-
-=head1 UPDATES
-
-Please email bug fixes and enhancements using Debian's bug tracking system, http://bugs.debian.org/.
-
-=cut
-# ----------------------------------------------------------------------------
-# use strict;
-use warnings;
-# Set the version number (displayed on the info page)
-my $version='0.8.6';
-
-my $path = $ENV{PATH_INFO};
-
-my $addq='';
-if(!$path) {
-   $path = $ENV{QUERY_STRING};
-   $addq = '?';
-}
-
-
-my @index_files = (
-	'Packages.gz',
-	'Packages.bz2',
-	'Release',
-	'Release.gpg',
-	'Sources.gz',
-	'Sources.bz2',
-	'Contents-.+\.gz',
-);
-my $index_files_regexp = '(' . join('|', @index_files) . ')$';
-
-
-# Include the library for the config file parser
-require '/usr/local/share/apt-cacher/lib/apt-cacher-lib.pl';
-require '/usr/local/share/apt-cacher/etc/checksumming.conf';
-
-# Read in the config file and set the necessary variables
-my $configfile = '/usr/local/share/apt-cacher/etc/apt-cacher.conf';
-
-my $configref;
-eval {
-        $configref = read_config($configfile);
-};
-my %config = %$configref;
-
-# not sure what to do if we can't read the config file...
-die "Could not read config file: $@" if $@;
-
-# Now set some things from the config file
-# $logfile used to be set in the config file: now we derive it from $logdir
-$config{logfile} = "$config{logdir}/access.log";
-
-# $errorfile used to be set in the config file: now we derive it from $logdir
-$config{errorfile} = "$config{logdir}/error.log";
-
-# don't block access unless explicitely requrested. This was the old default behaviour.
-$config{allowed_hosts_6} = '*' if !defined($config{allowed_hosts_6});
-$config{allowed_hosts} = '*' if !defined($config{allowed_hosts});
-
-my $private_dir = "$config{cache_dir}/private";
-my $exlockfile = "$private_dir/exlock";
-my $exlock;
-
-#my $do_lock = 0;
-
-# use IO::Handle;
-use Fcntl ':flock';
-use IO::Handle;
-use POSIX;
-
-#optional checksumming support
-db_init("$config{cache_dir}/md5sums.sl3");
-
-# Output data as soon as we print it
-$| = 1;
-
-# Function prototypes
-sub ipv4_addr_in_list ($$);
-sub ipv6_addr_in_list ($$);
-
-# ----------------------------------------------------------------------------
-# Die if we have not been configured correctly
-die "apt-cacher.pl: No cache_dir directory!\n" if (!-d $config{cache_dir});
-die "apt-cacher.pl: No cache_dir/tmp directory!\n" if (!-d "$config{cache_dir}/tmp");
-die "apt-cacher.pl: No cache_dir/private directory!\n" if (!-d $private_dir);
-
-# ----------------------------------------------------------------------------
-# Let's do some security checking. We only want to respond to clients within an
-# authorised address range (127.0.0.1 and ::1 are always allowed).
-
-my $ip_pass = 1;
-my $ip_fail = 0;
-my $client = $ENV{REMOTE_ADDR};
-my $clientaddr;
-
-# allowed_hosts == '*' means allow all ('' means deny all)
-# denied_hosts == '' means don't explicitly deny any
-# localhost is always accepted
-# otherwise host must be in allowed list and not in denied list to be accepted
-
-if ($client =~ /:/) # IPv6?
-{
-   defined ($clientaddr = ipv6_normalise ($client)) or goto badaddr;
-   if (substr ($clientaddr, 0, 12) eq "\0\0\0\0\0\0\0\0\0\0\xFF\xFF")
-   {
-      $clientaddr = substr ($clientaddr, 12);
-      goto is_ipv4;
-   }
-   elsif ($clientaddr eq "\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\1")
-   {
-      debug_message("client is localhost");
-   }
-   else
-   {
-      $ip_pass = ($config{allowed_hosts_6} =~ /^\*?$/) ||
-      ipv6_addr_in_list ($clientaddr, 'allowed_hosts_6');
-      $ip_fail = ipv6_addr_in_list ($clientaddr, 'denied_hosts_6');
-   }
-}
-elsif (defined ($clientaddr = ipv4_normalise ($client))) # IPv4?
-{
-   is_ipv4:
-   if ($clientaddr eq "\x7F\0\0\1")
-   {
-      debug_message("client is localhost");
-   }
-   else
-   {
-      $ip_pass = ($config{allowed_hosts} =~ /^\*?$/) ||
-      ipv4_addr_in_list ($clientaddr, 'allowed_hosts');
-      $ip_fail = ipv4_addr_in_list ($clientaddr, 'denied_hosts');
-   }
-}
-else
-{
-   goto badaddr;
-}
-
-# Now check if the client address falls within this range
-if ($ip_pass && !$ip_fail)
-{
-	# Everything's cool, client is in allowed range
-	debug_message("Client $client passed access control rules");
-}
-elsif($client eq "local")
-{
-	# Everything's cool, client is in allowed range
-	debug_message("Client $client passed access control rules");
-}
-else
-{
-	# Bzzzt, client is outside allowed range. Send 'em a 403 and bail.
-	badaddr:
-	debug_message("Alert: client $client disallowed by access control");
-	write_to_server("Status: 403 Access to cache prohibited\n\n");
-	exit(4);
-}
-
-# ----------------------------------------------------------------------------
-# Data also used by child processes
-
-my $unique_filename;
-my $child_pid;
-my $child_completed;
-my $child_rc;
-
-# ----------------------------------------------------------------------------
-
-# $SIG{'PIPE'} = sub { open(E, ">>$cache_dir/errs"); print E "$$ received SIGPIPE\n"; close(E); };
-# $SIG{'PIPE'} = 'IGNORE';
-my $sigpipe_received = 0;
-
-$SIG{'PIPE'} = sub {
-	#print STDERR "--- apt-cacher.pl: received SIGPIPE\n";
-	debug_message("received SIGPIPE");
-	$sigpipe_received = 1;
-};
-
-sub term_handler {
-	#print STDERR "--- apt-cacher.pl: received SIGTERM, terminating\n";
-	debug_message("received SIGTERM, terminating");
-	
-	# Kill the wget process if running and unlink its output file
-
-	kill('TERM', $child_pid) if ($child_pid);
-	unlink($unique_filename) if ($unique_filename);
-	exit(8);
-};
-
-$SIG{'TERM'} = \&term_handler;
-
-$SIG{'QUIT'} = sub { writeerrorlog("received SIGQUIT"); };
-$SIG{'INT'}  = sub { writeerrorlog("received SIGINT");  };
-
-#$SIG{'CHLD'} = sub {
-#	#print STDERR "--- apt-cacher.pl: received SIGCHLD\n";
-#	debug_message("received SIGCHLD");
-#	wait();
-#	$child_rc = $?;
-#	# undef $child_pid;
-#	$child_completed = 1;
-#	$moo = getpid();
-#	if(!$child_pid) { $child_pid = "null"; }
-#	debug_message("pids are $moo - $child_pid - child_rc is $child_rc");
-#};
-
-#print STDERR "\n--- apt-cacher.pl: called with $path\n";
-debug_message("called with $path");
-
-#$debug = 1 if (-f "$cache_dir/debug");
-
-`touch $exlockfile` if ! -f $exlockfile;
-
-# Who t.f. really needs that?
-#if ($do_lock) {
-#	open(LOCK, ">$config{cache_dir}/lock") or die "apt-cacher.pl: Unable to open $config{cache_dir}/lock for write: $!\n";
-#	if (!flock(LOCK, LOCK_EX)) {
-#		debug_message("unable to achieve a lock on $config{cache_dir}/lock: $!");
-#		die "Unable to achieve lock on $config{cache_dir}/lock: $!\n";
-#	}
-#
-#	#print STDERR "--- apt-cacher.pl: Lock achieved\n";
-#	debug_message("lock achieved");
-#	# keep LOCK open so that at most one apt-cacher.pl can be running at any time
-#}
-
-
-# Now parse the path
-if ($path =~ /^\/?report/) {
-       usage_report();
-       exit(0);
-}
-
-if ($path !~ m(^/?.+/.+)) {
-	usage_error();
-	exit(4);
-}
-
-
-my($host,$uri) = ($path =~ m(^/?([^/]+)(/.+)));
-
-if ($host eq '' || $uri eq '') {
-	usage_error();
-	exit(4);
-}
-
-my ($filename) = ($uri =~ /\/?([^\/]+)$/);
-my $new_filename;
-
-my $is_open = 0;	# Is the file currently open by us?
-my $is_incomplete = 0;	# Is the file contents complete?
-
-if(defined($config{allowed_locations})) {
-   my $mess;
-   if ("$host$uri" =~ /\.\./){
-      $mess = "'..' contained in URL";
-   } else {
-      for(split(/,/,$config{allowed_locations})) {
-         goto location_allowed if ("$host$uri" =~ /^$_/);
-      }
-      $mess = "Host '$host' is not configured in the allowed_locations directive";
-   }
-   badguy:
-   debug_message("$mess; access denied");
-   write_to_server("Status: 403 Forbidden.\n\n$mess.\n\n");
-   exit(4);
-}
-location_allowed:
-
-my $do_import=0;
-
-if ($filename =~ /(\.deb|\.rpm|\.dsc|\.tar\.gz|\.diff\.gz|\.udeb)$/) {
-	# We must be fetching a .deb or a .rpm, so let's cache it.
-	# Place the file in the cache with just its basename
-	$new_filename = $filename;
-	debug_message("new filename with just basename: $new_filename");
-} elsif ($filename =~ /$index_files_regexp/) {
-	# It's a Packages.gz or related file: make a long filename so we can cache these files without
-	# the names colliding
-	$new_filename = "$host$uri";
-	$new_filename =~ s/\//_/g;
-  debug_message("new long filename: $new_filename");
-  # optional checksumming support
-  if ($filename =~ /(Packages|Sources)/) {
-     # warning, an attacker could poison the checksum cache easily
-     $do_import=1;
-  }
-} else {
-	# Maybe someone's trying to use us as a general purpose proxy / relay.
-	# Let's stomp on that now.
-	debug_message("Sorry, not allowed to fetch that type of file: $filename");
-	write_to_server("Status: 403 Forbidden. Not allowed to fetch that type of file\n\n");
-	exit(4);
-}
-
-my $cached_file = "$config{cache_dir}/packages/$new_filename";
-my $cached_head = "$config{cache_dir}/headers/$new_filename";
-my $errflagfile = "$cached_head.error";
-
-debug_message("looking for $cached_file");
-
-if ($filename =~ /$index_files_regexp/) {
-	debug_message("known as index file: $filename");
-#  setlock; global lock used here sucks, to deep impact on performance for possible (low) risk scenarios
-	if (-f _) {
-     if($config{expire_hours} > 0) {
-        my $now = time();
-        my @stat = stat($cached_file);
-        if (@stat && int(($now - $stat[9])/3600) > $config{expire_hours}) {
-           #print STDERR "--- Unlinking $new_filename because it is too old\n";
-           debug_message("unlinking $new_filename because it is too old");
-           # Set the status to EXPIRED so the log file can show it was downloaded again
-           $cache_status = "EXPIRED";
-           debug_message("$cache_status");
-           unlink $cached_file, $cached_head, "$private_dir/$new_filename.complete";
-        }
-     }
-     else {
-        # use HTTP timestamping
-        my ($oldhead, $testfile, $newhead);
-        open(my $fhead, "-|", "/usr/bin/curl", "-I", "http://$host$uri", '-D-', '--stderr', "/dev/null");
-        while(<$fhead>) {
-           $newhead = $1 if /.*Last-Modified:([^\n\r]+).*/;
-        }
-        close($fhead);
-
-        if(open($testfile, $cached_head)) {
-           for(<$testfile>){
-              if(/^.*Last-Modified:(.*)(\r|\n)/) {
-                 $oldhead = $1;
-                 last
-              }
-           }
-           close($testfile);
-        }
-        if($oldhead && $newhead && ($oldhead eq $newhead) ) {
-           # that's ok
-           debug_message("remote file not changed, $oldhead vs. $newhead");
-        }
-        else {
-           #print STDERR "--- Unlinking $new_filename because it is too old\n";
-           debug_message("unlinking $new_filename because it differs from server's version");
-           $cache_status = "EXPIRED";
-           debug_message("$cache_status");
-           unlink $cached_file, $cached_head, "$private_dir/$new_filename.complete";
-        }
-     }
-  }
-#  unlock;
-}
-
-&setlock; # better lock such things to reduce risk from cludges
-if (!-f $cached_file) {
-	# File does not exist, so try to create it
-	# KLUDGE ... probably a race condition here
-	unlink("$private_dir/$new_filename.complete");
-	#print STDERR "--- File does not exist, create it\n";
-	debug_message("file does not exist, creating it");
-	# Set the status to MISS so the log file can show it had to be downloaded
-	$cache_status = "MISS";
-	debug_message("$cache_status");
-	if (sysopen(CF, $cached_file, O_RDWR|O_CREAT|O_EXCL, 0644)) {
-		$is_open = 1;
-	}
-	# If open fails, maybe we came 2nd in a race
-	# ... KLUDGE ... continue here
-} else {
-	# Set the status to HIT so the log file can show it came from cache
-	### check variable scope
-	$cache_status = "HIT";
-	debug_message("$cache_status");
-}
-
-
-
-if (!-f $cached_file) {
-	barf("Tried to create $cached_file, but failed");
-}
-
-# Ok, the file exists. Open it if we didn't already.
-if (!$is_open) {
-	#print STDERR "--- Open $cached_file\n";
-	debug_message("open $cached_file");
-	
-	if (!sysopen(CF, $cached_file, O_RDWR)) {
-		writeerrorlog("unable to open incomplete $cached_file: $!");
-		barf("Unable to open incomplete $cached_file: $!");
-	}
-	$is_open = 1;
-}
-
-# Is it incomplete?
-if (!-f "$private_dir/$new_filename.complete") {
-   $is_incomplete = 1;
-   #print STDERR "--- File is not complete\n";
-   debug_message("file is not complete");
-   if (flock(CF, LOCK_EX|LOCK_NB)) {
-      # file locked, nobody's touching it ...
-      # Have to truncate it, because we can't rely on "resume"
-      truncate(CF, 0);
-      # we can fetch, remove the error file
-      unlink $errflagfile;
-      &try_pickup;
-   }
-}
-
-&unlock; # that must cover the complete checks/creation
-
-# At this point the file is open, and it's either complete or somebody
-# is fetching its contents
-
-
-#print STDERR "--- Starting to return $cached_file\n";
-debug_message("starting to return $cached_file");
-
-my $first_line = 1;
-my($buf,$n);
-my $abort_timer = 300;
-my $nodata_count = 0;
-my $header_printed=0;
-
-
-# reopen the file to not share the lock with the fetcher
-my $fromfile;
-if (!sysopen($fromfile, $cached_file, O_RDWR)) {
-   # don't barf. If there are network problems, they are signaled via errorfile
-   # below, but not here
-#   writeerrorlog("weird, unable to open incomplete $cached_file: $!");
-#   barf("weird, Unable to open incomplete $cached_file: $!");
-}
-
-data_init();
-while (1) {
-	if ($sigpipe_received) {
-		#print STDERR "--- Exit (SIGPIPE)\n";
-		debug_message("exit (SIGPIPE)");
-		exit(4);
-	}
-	
-  my $n=0;
-  my $buf;
-  my @statinfo=stat($cached_head);
-  
-  # 100 should be enough as flag, since
-  # hopefully the headers files are always small enough to be written to the
-  # disk atomicaly
-  if(@statinfo && $statinfo[7]>100) {      
-     $n = sysread($fromfile, $buf, 65536);
-     barf("Oops, read failed!") if (!defined $n);
-  }
-  else {
-     debug_message("no header yet...\n");
-  }
-
-	debug_message("read $n bytes");
-
-	if ($n < 0) {
-		#print STDERR "--- Exit (read fail)\n";
-		debug_message("exit (read failed)");
-		exit(4);
-	}
-
-  my $code;
-  if (-f $errflagfile) {
-     open(my $in, $errflagfile); $code=<$in>;
-     debug_message("exit (file failed, $code)");
-     if(!$header_printed) { # don't return crap, status as data
-        write_to_server("Status: $code Error trying to fetch the file\n\n");
-     }
-     writeaccesslog("MISS", "$new_filename");
-     exit(0);
-  }
-
-  if(!$header_printed && $n>0) {
-     $header_printed=1;
-     # prepend the header in the first chunk
-     my $head;
-     if($cached_head && open(my $in, $cached_head)) {
-        <$in>; # drop the status and date lines
-        $head=join("", <$in>);
-     }
-     if(!$head) {
-        debug_message("Header squashed!");
-        write_to_server("Status: 502 Error trying to fetch the file\n\n");
-        unlink $cached_file; #FIXME
-        exit 0;
-     }
-     write_to_server($head);
-  }
-
-  if ($n == 0) {
-     # if the fetcher is done, we can lock/unlock it
-     if (flock($fromfile, LOCK_EX|LOCK_NB)) {
-        flock($fromfile, LOCK_UN);
-        # Looks like file is complete!
-        # Finish up
-        #print STDERR "--- Exit (file completed)\n";
-        debug_message("exit (file completed)");
-
-        last;
-     }
-
-     $nodata_count += 2;
-     if ($nodata_count >= $abort_timer) {
-        #print STDERR "--- Abort (timeout)\n";
-        debug_message("abort (timeout)");
-        exit(4);
-     }
-     sleep(2);
-     next;
-  }
-
-
-		write_to_server($buf);
-    data_feed(\$buf);
-		#print STDERR "Wrote ", length($buf), " bytes\n" if ($debug);
-		debug_message("wrote " . length($buf) . " bytes");
-}
-
-# Write all the stuff to the log file
-writeaccesslog("$cache_status", "$new_filename");
-if(!check_sum($new_filename)) {
-   debug_message("ALARM! Faulty package in local cache detected! Replacing: $new_filename");
-   unlink $cached_file;
-   exit(4);
-}
-# We're done!
-exit(0);
-
-#####################################################################
-# End of the main program
-#####################################################################
-
-sub barf {
-	my $errs = shift;
-
-	die "--- apt-cacher.pl: Fatal: $errs\n";
-}
-
-sub usage_error {
-	print STDERR "--- apt-cacher.pl: Usage error\n";
-
-	print <<EOF;
-Content-Type: text/html
-Expires: 0
-
-<html>
-<title>Apt-cacher version $version
-</title><style type="text/css"><!--
-a { text-decoration: none; }
-a:hover { text-decoration: underline; }
-h1 { font-family: arial, helvetica, sans-serif; font-size: 18pt; font-weight: bold;}
-h2 { font-family: arial, helvetica, sans-serif; font-size: 14pt; font-weight: bold;}
-body, td { font-family: arial, helvetica, sans-serif; font-size: 10pt; }
-th { font-family: arial, helvetica, sans-serif; font-size: 11pt; font-weight: bold; }
-//--></style>
-</head>
-<body>
-<p>
-<table border=0 cellpadding=8 cellspacing=1 bgcolor="#000000" align="center" width="600">
-<tr bgcolor="#9999cc"><td> <h1>Apt-cacher version $version</h1> </td></tr>
-<tr bgcolor="#cccccc"><td>
-Usage: edit your /etc/apt/sources.list so all your HTTP sources are prepended 
-with the address of your apt-cacher machine and 'apt-cacher', like this:
-<blockquote>deb&nbsp;http://ftp.au.debian.org/debian&nbsp;unstable&nbsp;main&nbsp;contrib&nbsp;non-free</blockquote>
-becomes
-<blockquote>deb&nbsp;http://<b>yourcache.example.com/apt-cacher$addq/</b>ftp.au.debian.org/debian&nbsp;unstable&nbsp;main&nbsp;contrib&nbsp;non-free</blockquote>
-</td></tr>
-</table>
-
-<h2 align="center">config values</h2>
-<table border=0 cellpadding=3 cellspacing=1 bgcolor="#000000" align="center">
-<tr bgcolor="#9999cc"><th> Directive </th><th> Value </th></tr>
-<tr bgcolor="#cccccc"><td bgcolor="#ccccff"> configfile </td><td> $configfile </td></tr>
-<tr bgcolor="#cccccc"><td bgcolor="#ccccff"> admin_email </td><td> <a href="mailto:$config{admin_email}">$config{admin_email}</a> </td></tr>
-<tr bgcolor="#cccccc"><td bgcolor="#ccccff"> generate_reports </td><td> $config{generate_reports} </td></tr>
-<tr bgcolor="#cccccc"><td bgcolor="#ccccff"> cache_dir </td><td> $config{cache_dir} </td></tr>
-<tr bgcolor="#cccccc"><td bgcolor="#ccccff"> logfile </td><td> $config{logfile} </td></tr>
-<tr bgcolor="#cccccc"><td bgcolor="#ccccff"> errorfile </td><td> $config{errorfile} </td></tr>
-<tr bgcolor="#cccccc"><td bgcolor="#ccccff"> expire_hours </td><td> $config{expire_hours} </td></tr>
-<tr bgcolor="#cccccc"><td bgcolor="#ccccff"> http_proxy </td><td> $config{http_proxy} </td></tr>
-<tr bgcolor="#cccccc"><td bgcolor="#ccccff"> use_proxy </td><td> $config{use_proxy} </td></tr>
-<tr bgcolor="#cccccc"><td bgcolor="#ccccff"> debug </td><td> $config{debug} </td></tr>
-</table>
-
-<p>
-<h2 align="center">license</h2>
-<table border=0 cellpadding=8 cellspacing=1 bgcolor="#000000" align="center" width="600">
-<tr bgcolor="#cccccc"><td>
-<p>Apt-cacher is free software; you can redistribute it and/or modify it under the terms of the GNU General 
-Public License as published by the Free Software Foundation; either version 2 of the License, or (at your 
-option) any later version.
-
-<p>Apt-cacher is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the 
-implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public 
-License for more details.
-
-<p>A copy of the GNU General Public License is available as /usr/share/common-licenses/GPL in the Debian 
-GNU/Linux distribution or on the World Wide Web at http://www.gnu.org/copyleft/gpl.html. You can also 
-obtain it by writing to the Free Software Foundation, Inc., 59 Temple Place - Suite 330, Boston, MA 
-02111-1307, USA.
-</td></tr>
-</table>
-</body>
-</html>
-EOF
-
-}
-
-sub try_pickup {
-
-	my $pid = fork();
-	if ($pid < 0) {
-		barf("fork() failed");
-	}
-
-	if ($pid > 0) {
-		# parent
-		return;
-	}
-
-	# child
-
-	my $url = "http://$host$uri";
-
-  # using curl, but separating the header manually to make sure that it is
-  # stored on disk before the data is stored
-  #
-  debug_message("fetcher: try to pick up $url");
-  @elist=("/usr/bin/curl", '-D-', 
-  '--stderr', "/dev/null",
-  $url);
-
-  # for checksumming
-  data_init();
-
-  # Check whether a proxy is to be used, and set the appropriate environment variable
-  if ( $config{use_proxy} eq 1 && $config{http_proxy}) {
-     push(@elist, "-x", "http://$config{http_proxy}");
-  }
-  # Check if we need to set a rate limiting value: otherwise make it null
-  push(@elist,"--limit-rate", $config{limit}) if ($config{limit} > 0);
-  debug_message("Executing @elist"); 
-  # Run the command we've built up
-  my ($data, $getpipe, $chfd);
-  open($chfd, ">$cached_head");
-  open($getpipe, "-|", @elist);
-  while(<$getpipe>) {
-     if($data) { 
-        data_feed(\$_) if !$do_import; # checksum passed data if not an meta file
-        print CF $_;
-        next ; 
-     }
-     s/\r//;
-     print $chfd $_;
-     if(/^$/) {
-        close($chfd);
-        $data=1;
-     }
-  }
-  close($getpipe);
-  my $rc=($?>>8);
-
-	#print STDERR "--- Pick up $url as $cached_file, return code $rc\n";
-	debug_message("pick up $url as $cached_file, return code $rc");
-
-  # check missmatch or fetcher failure, could not connect the server
-  if(!check_sum($new_filename)) {
-     debug_message("Do00h, checksum mismatch on $new_filename");
-     $rc=123;
-  }
-  if ($rc != 0) {
-     unlink $cached_file, $cached_head;
-     open(MF, ">$errflagfile");
-     print MF 502;
-     close(MF);
-     exit(0);
-  }
-
-  open($tmp, $cached_head);
-  my $code = <$tmp>;
-  $code =~ s/HTTP\S+\s(\d+).*/$1/s;
-  close($tmp);
-  
-  if($code =~ /^[45]/) {
-     open(MF, ">$errflagfile");
-     print MF $code;
-     close(MF);
-     unlink $cached_file, $cached_head;
-     exit(0);
-  }
-
-	# Touch the new file to fix the timestamp (this fixes the bug that was previously
-	# causing apt-cacher to re-download files that it thought had expired, but which
-	# were actually new: thanks Raphael!)
-	my $now = time;
-	utime $now, $now, $cached_file;
-
-	# Now create the file to show the pickup is complete, also store the original URL there
-	open(MF, ">$private_dir/$new_filename.complete");
-  print MF $path;
-	close(MF);
-
-  flock(CF, LOCK_UN); # release it, notifying the readers
-
-  import_sums($cached_file) if $do_import;
-		
-	#print STDERR "--- Fetcher exiting\n";
-	debug_message("fetcher exiting");
-
-	exit(0);
-}
-
-
-# Check if there has been a usage report generated and display it
-sub usage_report{
-	$usage_file = "$config{logdir}/report.html";
-	if (!-f $usage_file) {
-		print <<EOF;
-Content-Type: text/html
-
-<html>
-<title>Apt-cacher traffic report</title><style type="text/css"><!--
-a { text-decoration: none; }
-a:hover { text-decoration: underline; }
-h1 { font-family: arial, helvetica, sans-serif; font-size: 18pt; font-weight: bold;}
-h2 { font-family: arial, helvetica, sans-serif; font-size: 14pt; font-weight: bold;}
-body, td { font-family: arial, helvetica, sans-serif; font-size: 10pt; }
-th { font-family: arial, helvetica, sans-serif; font-size: 11pt; font-weight: bold; }
-//--></style>
-</head>
-<body>
-<table border=0 cellpadding=8 cellspacing=1 bgcolor="#000000" align="center" width="600">
-<tr bgcolor="#9999cc"><td> <h1>Apt-cacher traffic report</h1> </td></tr>
-<tr bgcolor="#cccccc"><td>For more information on apt-cacher visit <a href="http://www.apt-cacher.org/">www.apt-cacher.org</a>.
-</td></tr>
-</table>
-		
-<p><table border=0 cellpadding=3 cellspacing=1 bgcolor="#000000" align="center" width="600">
-<tr bgcolor="#9999cc"><th bgcolor="#9999cc"> An Apt-cacher usage report has not yet been generated </th></tr>
-<tr bgcolor="#cccccc"><td bgcolor="#ccccff"> Reports are generated every 24 hours. If you want reports to be generated, make sure you set '<b>generate_reports=1</b>' in <b>$configfile</b>.</td></tr>
-</table>
-		</body>
-		</html>
-EOF
-
-	}
-	else
-	{
-		my $usage_report = `cat $usage_file`;
-		print <<EOF;
-Content-Type: text/html
-
-		$usage_report
-EOF
-	}
-}
-
-
-# Wrapper to write to the web server, to make it clearer when we are doing so.
-sub write_to_server {
-	my $message = shift;
-  syswrite(STDOUT,$message);
-}
-
-
-# Jon's extra stuff to write the event to a log file.
-sub writeaccesslog {
-	my $cache_status = shift;
-	my $new_filename = shift;
-
-	# The format is 'time|cache status (HIT, MISS or EXPIRED)|client IP address|file size|name of requested file'
-	my $time = localtime;
-  my $client_ip = $ENV{REMOTE_ADDR};
-  my $cached_file = "$config{cache_dir}/packages/$new_filename";
-	my ($dev,$ino,$mode,$nlink,$uid,$gid,$rdev,$size,$atime,$mtime,$ctime,$blksize,$blocks) = stat($cached_file);
-	my $file_length = 0;
-  $file_length+=$size if defined($size);
-
-	open(LOGFILE,">>$config{logfile}") or die;
-	print LOGFILE "$time|$client_ip|$cache_status|$file_length|$new_filename\n";
-	close LOGFILE;
-}
-
-# Jon's extra stuff to write errors to a log file.
-sub writeerrorlog {
-	my $message = shift;
-	
-	my $time = localtime;
-	my $client_ip = $ENV{REMOTE_ADDR};
-
-	open(ERRORFILE,">>$config{errorfile}") or die;
-	print ERRORFILE "$time|$client_ip|$message\n";
-	close ERRORFILE;
-}
-
-# IP address filtering.
-sub ipv4_addr_in_list ($$)
-{
-	return 0 if $_[0] eq '';
-	debug_message ("testing $_[1]");
-	return 0 unless $config{$_[1]};
-
-	my ($client, $cfitem) = @_;
-	my @allowed_hosts = split(/,\s*/, $config{$cfitem});
-	for my $ahp (@allowed_hosts)
-	{
-		goto unknown if $ahp !~ /^[-\/,.[:digit:]]+$/;
-
-		# single host
-		if ($ahp =~ /^([^-\/]*)$/)
-		{
-			my $ip = $1;
-			debug_message("checking against $ip");
-			defined ($ip = ipv4_normalise($ip)) or goto unknown;
-			return 1 if $ip eq $client;
-		}
-		# range of hosts (netmask)
-		elsif ($ahp =~ /^([^-\/]*)\/([^-\/]*)$/)
-		{
-			my ($base, $mask) = ($1, $2);
-			debug_message("checking against $ahp");
-			defined ($base = ipv4_normalise($base)) or goto unknown;
-			$mask = ($mask =~ /^\d+$/) ? make_mask ($mask, 32)
-																 : ipv4_normalise ($mask);
-			goto unknown unless defined $mask;
-			return 1 if ($client & $mask) eq ($base & $mask);
-		}
-		# range of hosts (start & end)
-		elsif ($ahp =~ /^([^-\/]*)-([^-\/]*)$/)
-		{
-			my ($start, $end) = ($1, $2);
-			debug_message("checking against $start to $end");
-			defined ($start = ipv4_normalise($start)) or goto unknown;
-			defined ($end = ipv4_normalise($end)) or goto unknown;
-			return 1 if $client ge $start && $client le $end;
-		}
-		# unknown
-		else
-		{
-			unknown:
-			debug_message("Alert: $cfitem ($ahp) is bad");
-			write_to_server("Status: 500 Configuration error\n\n");
-			exit(4);
-		}
-	}
-	return 0; # failed
-}
-
-sub ipv6_addr_in_list ($$)
-{
-	return 0 if $_[0] eq '';
-	debug_message ("testing $_[1]");
-	return 0 unless $config{$_[1]};
-
-	my ($client, $cfitem) = @_;
-	my @allowed_hosts = split(/,\s*/, $config{$cfitem});
-	for my $ahp (@allowed_hosts)
-	{
-		goto unknown if $ahp !~ /^[-\/,:[:xdigit:]]+$/;
-
-		# single host
-		if ($ahp =~ /^([^-\/]*)$/)
-		{
-			my $ip = $1;
-			debug_message("checking against $ip");
-			$ip = ipv6_normalise($ip);
-			goto unknown if $ip eq '';
-			return 1 if $ip eq $client;
-		}
-		# range of hosts (netmask)
-		elsif ($ahp =~ /^([^-\/]*)\/([^-\/]*)$/)
-		{
-			my ($base, $mask) = ($1, $2);
-			debug_message("checking against $ahp");
-			$base = ipv6_normalise($base);
-			goto unknown if $base eq '';
-			goto unknown if $mask !~ /^\d+$/ || $mask < 0 || $mask > 128;
-			my $m = ("\xFF" x ($mask / 8));
-			$m .= chr ((-1 << (8 - $mask % 8)) & 255) if $mask % 8;
-			$mask = $m . ("\0" x (16 - length ($m)));
-			return 1 if ($client & $mask) eq ($base & $mask);
-		}
-		# range of hosts (start & end)
-		elsif ($ahp =~ /^([^-\/]*)-([^-\/]*)$/)
-		{
-			my ($start, $end) = ($1, $2);
-			debug_message("checking against $start to $end");
-			$start = ipv6_normalise($start);
-			$end = ipv6_normalise($end);
-			goto unknown if $start eq '' || $end eq '';
-			return 1 if $client ge $start && $client le $end;
-		}
-		# unknown
-		else
-		{
-			unknown:
-			debug_message("Alert: $cfitem ($ahp) is bad");
-			write_to_server("Status: 500 Configuration error\n\n");
-			exit(4);
-		}
-	}
-	return 0; # failed
-}
-
-# Stuff to append debug messages to the error log.
-sub debug_message {
-	if ($config{debug} eq 1) {
-		my $message = shift;
-
-		my $time = localtime;
-		my $client_ip = $ENV{REMOTE_ADDR};
-
-		open(ERRORFILE,">>$config{errorfile}") or die;
-		print ERRORFILE "$time|$client_ip|debug: $message\n";
-		close ERRORFILE;
-	}
-}
-
-sub setlock {
-   open($exlock, $exlockfile);
-   if (!flock($exlock, LOCK_EX)) {
-      debug_message("unable to achieve a lock on $exlockfile: $!");
-      die "Unable to achieve lock on $exlockfile: $!";
-   }
-}
-
-sub unlock {
-   flock($exlock, LOCK_UN);
-}
-
diff -r 9ce9101b3e6b binary-overlay.xenrt/usr/local/share/apt-cacher/lib/apt-precache.pl
--- a/binary-overlay.xenrt/usr/local/share/apt-cacher/lib/apt-precache.pl	Wed Feb 27 12:23:56 2008 +0000
+++ /dev/null	Thu Jan 01 00:00:00 1970 +0000
@@ -1,71 +0,0 @@
-#!/usr/bin/perl
-
-##
-my $curl="curl"; # or echo curl
-
-syswrite(STDOUT,"This is an experimental script. You have been warned.\n");
-
-use strict;
-
-my ($cachedir, $baseurl, $verbose, $prios) = @ARGV;
-die "USAGE: apt-precache apt-cacher-cachedir apt-cacher-base-url [ verbosity forced-prios ]
-Examples:
-apt-precache /var/cache/apt-cacher http://proxy/apt-cacher/
-apt-precache /data/apt-cacher http://proxy/apt-cacher/ 1 required,important
-NOTE: the options may change in the future
-" if ! ($cachedir && $baseurl);
-
-my $tmp=`mktemp`;
-my $pcount=0;
-chomp $tmp;
-
-chdir "$cachedir/packages" || die "cannot enter $cachedir/packages" ;
-
-my %pkgs;
-for (<*>) { my $pn=$_; $pn=~s/_.*//g; $pkgs{$pn}=$_; }
-
-for my $pgz (<*Packages*>) {
-   my $acurl=$pgz;
-   $acurl =~ s!_!/!g;
-   my $pgzurl = "$baseurl/$acurl";
-   $acurl =~ s!^!$baseurl/!;
-   $acurl =~ s!/dists/.*!!; # that sucks, pure guessing
-
-   
-   my ($cat, $listpipe);
-   $_=$pgz;
-   $cat = (/bz2$/ ? "bzcat" : (/gz$/ ? "zcat" : "cat"));
-   
-   print "D: $pgzurl\n" if $verbose;
-   
-   # dl to temp file first, otherwise risking connection timout
-   if((!system "curl", "--stderr", "/dev/null", "-o", $tmp, $pgzurl) && open(pfile,"-|",$cat,$tmp)) {
-
-         my $prio;
-      while(<pfile>) {
-         if(/^Priority:\s+(.*)\n/) { $prio=$1; }
-         if(/^Filename: (.*)\n/) {
-            my $path=$1;
-            s!.*/!!g;
-            my ($file, $name) = (/^(([^\/_]+).*)\n/);
-            if($file && defined($prios)) {
-               if(!-e $file && $prios=~/$prio/) {
-                  print "D: $acurl/$path\n" if $verbose;
-                  system $curl, "-o", "/dev/null", "$acurl/$path";
-               }
-            }
-            elsif($pkgs{$name}) {
-               if(!-e $file) {
-                  $pcount++;
-                  print "D: $acurl/$path\n" if $verbose;
-                  system $curl, "-o", "/dev/null", "$acurl/$path";
-               }
-            }
-         }
-      }
-   }
-}
-
-unlink $tmp;
-
-print "Downloaded: $pcount packages.\n" if $verbose;
diff -r 9ce9101b3e6b binary-overlay.xenrt/usr/local/share/apt-cacher/lib/install.pl
--- a/binary-overlay.xenrt/usr/local/share/apt-cacher/lib/install.pl	Wed Feb 27 12:23:56 2008 +0000
+++ /dev/null	Thu Jan 01 00:00:00 1970 +0000
@@ -1,209 +0,0 @@
-#!/usr/bin/perl -w
-#	@(#) setup.pl -- Setup script for apt-cacher.pl
-#	$ Revision: $
-#	$ Source: $
-#	$ Date: $
-#
-#	Safe to run multiple times; later versions of this script will
-#	remove obsolete directories or files and not touch required
-#	directories or files.
-#
-
-umask 0022;
-
-#############################################################################
-### configuration ###########################################################
-# Include the library for the config file parser
-require '/usr/local/share/apt-cacher/lib/apt-cacher-lib.pl';
-
-# Read in the config file and set the necessary variables
-my $configfile = '/usr/local/share/apt-cacher/etc/apt-cacher.conf';
-
-my $configref;
-eval {
-        $configref = read_config($configfile);
-};
-my %config = %$configref;
-
-# not sure what to do if we can't read the config file...
-die "Could not read config file: $@" if $@;
-
-# Now set some things from the config file
-# $logfile used to be set in the config file: now we derive it from $logdir
-$config{logfile} = "$config{logdir}/access.log";
-
-# $errorfile used to be set in the config file: now we derive it from $logdir
-$config{errorfile} = "$config{logdir}/error.log";
-
-my $private_dir = "$config{cache_dir}/private";
-
-################################################
-# Check that the cache_dir has been set and continue on (note: this should never happen
-# because cache_dir is preset to a default value prior to loading the config file)
-die "Warning: config file could not be parsed ($configfile)/ (cache_dir is not set)\n" if ($config{cache_dir} eq '');
-
-
-@info=getpwnam("www-data");
-my @permcmd;
-if(-e $config{cache_dir}) {
-   @permcmd = ("chown", "--reference", $config{cache_dir});
-}
-elsif(@info) {
-   print "Assuming www-data is the user ID used to run apt-cacher\n";
-   @permcmd = ("chown", "$info[2]:$info[3]");
-}
-else {
-   @permcmd = ("/bin/echo", "User account for apt-cacher/http daemon unknown, plese set ownership for the following files manually:");
-}
-
-for ("README", "README.txt") {
-   my $file=$config{cache_dir}."/$_";
-   if (-f $file) {
-      print "Found obsolete file $file - removing.\n";
-      unlink($file);
-   }
-}
-
-foreach my $dir ($config{cache_dir}, $config{logdir}, "$config{cache_dir}/private", "$config{cache_dir}/tmp", "$config{cache_dir}/import", "$config{cache_dir}/packages", "$config{cache_dir}/headers") {
-	if (!-d $dir) {
-		print "Doing mkdir($dir, 0755)\n";
-		mkdir($dir, 0755);
-    system (@permcmd, $dir);
-	}
-	if (!-w $dir) {
-		die "Warning, $dir exists but is not is not writeable for apt-cacher!\n";
-	}
-}
-
-# Remove these directories if they exist (obsolete)
-# later rmdir $cache_dir/tmp, just not now as I may want it in future
-foreach my $rmdir ("$config{cache_dir}/head") {
-	if (-d $rmdir) {
-		print "Doing 'rm -rf $rmdir' (obsolete)\n";
-		system("rm -rf $rmdir");
-	}
-}
-
-# At the moment we need to create empty access and error logs so apt-cacher
-# doesn't barf the first time it's run. Probably should change apt-cacher
-# so it can handle missing logs, and create them itself if required.
-for $file ($config{logfile}, $config{errorfile}) {
-   if(!-e $file) {
-      open(my $tmp, ">$file");
-      close($tmp);
-      system @permcmd, $file;
-   }
-}
-
-# These ownership changes are a cludge: need to make them check httpd.conf for the Apache
-# user and set ownership to that, and do it with Perl instead of shell
-# EB: fsck that, this may simply overwritte changes by the admin
-# `chown -R www-data.www-data $config{cache_dir}`;
-
-# We used to tack a line onto the end of apache.conf. Now we just symlink into conf.d
-if(-d "/etc/apache/conf.d" ){
-	symlink("/etc/apt-cacher/apache.conf","/etc/apache/conf.d/apt-cacher");
-}
-
-if(-d "/etc/apache-ssl/conf.d" ){
-	symlink("/etc/apt-cacher/apache.conf","/etc/apache-ssl/conf.d/apt-cacher");
-}
-
-if(-d "/etc/apache2/conf.d" ){
-	rename("/etc/apache2/conf.d/apt-cacher", "/etc/apache2/conf.d/apt-cacher.conf") || symlink("/etc/apt-cacher/apache.conf","/etc/apache2/conf.d/apt-cacher.conf");
-}
-
-# Apache2 needs the cgi module installed, which it isn't by default.
-if(-d "/etc/apache2/mods-enabled"){
-	symlink("/etc/apache2/mods-available/cgi.load","/etc/apache2/mods-enabled/cgi.load");
-}
-
-
-#vvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvv
-# Just for now we still have to try nuking old entries in httpd.conf,
-# because they may have been left behind previously. After a couple
-# more releases this should be removed from here and remove.pl
-
-# Remove the include lines from Apache's httpd.conf
-my $httpdconf = "/etc/apache/httpd.conf";
-if (-f $httpdconf) {
-	$old = $httpdconf;
-	$new = "$httpdconf.tmp.$$";
-	$bak = "$httpdconf.bak";
-	
-	open(OLD, "< $old")         or die "can't open $old: $!";
-	open(NEW, "> $new")         or die "can't open $new: $!";
-	
-	while (<OLD>) {
-		s/# This line has been appended by the Apt\-cacher install script/ /;
-		s/Include \/etc\/apt\-cacher\/apache.conf/ /;
-		(print NEW $_)          or die "can't write to $new: $!";
-	}
-	
-	close(OLD)                  or die "can't close $old: $!";
-	close(NEW)                  or die "can't close $new: $!";
-	
-	rename($old, $bak)          or die "can't rename $old to $bak: $!";
-	rename($new, $old)          or die "can't rename $new to $old: $!";
-	if (-f "/etc/init.d/apache")
-	{
-		`/etc/init.d/apache restart`;
-	}
-}
-
-# Remove the include lines from Apache-SSL's httpd.conf
-$httpdconf = "/etc/apache-ssl/httpd.conf";
-if (-f $httpdconf) {
-	$old = $httpdconf;
-	$new = "$httpdconf.tmp.$$";
-	$bak = "$httpdconf.bak";
-	
-	open(OLD, "< $old")         or die "can't open $old: $!";
-	open(NEW, "> $new")         or die "can't open $new: $!";
-	
-	while (<OLD>) {
-		s/# This line has been appended by the Apt\-cacher install script/ /;
-		s/Include \/etc\/apt\-cacher\/apache.conf/ /;
-		(print NEW $_)          or die "can't write to $new: $!";
-	}
-	
-	close(OLD)                  or die "can't close $old: $!";
-	close(NEW)                  or die "can't close $new: $!";
-	
-	rename($old, $bak)          or die "can't rename $old to $bak: $!";
-	rename($new, $old)          or die "can't rename $new to $old: $!";
-	if (-f "/etc/init.d/apache-ssl")
-	{
-		`/etc/init.d/apache-ssl restart`;
-	}
-}
-
-# Remove the include lines from Apache2's apache2.conf
-$httpdconf = "/etc/apache2/apache2.conf";
-if (-f $httpdconf) {
-        $old = $httpdconf;
-        $new = "$httpdconf.tmp.$$";
-        $bak = "$httpdconf.bak";
-
-        open(OLD, "< $old")         or die "can't open $old: $!";
-        open(NEW, "> $new")         or die "can't open $new: $!";
-
-        while (<OLD>) {
-                s/# This line has been appended by the Apt\-cacher install script/ /;
-                s/Include \/etc\/apt\-cacher\/apache.conf/ /;
-                (print NEW $_)          or die "can't write to $new: $!";
-        }
-
-        close(OLD)                  or die "can't close $old: $!";
-        close(NEW)                  or die "can't close $new: $!";
-
-        rename($old, $bak)          or die "can't rename $old to $bak: $!";
-        rename($new, $old)          or die "can't rename $new to $old: $!";
-	if (-f "/etc/init.d/apache2")
-	{
-		`/etc/init.d/apache2 restart`;
-	}
-}
-#^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
-
-exit(0);
diff -r 9ce9101b3e6b binary-overlay.xenrt/usr/local/share/apt-cacher/lib/remove.pl
--- a/binary-overlay.xenrt/usr/local/share/apt-cacher/lib/remove.pl	Wed Feb 27 12:23:56 2008 +0000
+++ /dev/null	Thu Jan 01 00:00:00 1970 +0000
@@ -1,142 +0,0 @@
-#!/usr/bin/perl -w
-#	@(#) remove.pl -- Remove script for apt-cacher
-#	$ Revision: $
-#	$ Source: $
-#	$ Date: $
-#
-
-my $path = $ENV{PATH_INFO};
-#############################################################################
-### configuration ###########################################################
-# Include the library for the config file parser
-require '/usr/share/apt-cacher/apt-cacher-lib.pl';
-
-# Read in the config file and set the necessary variables
-my $configfile = '/etc/apt-cacher/apt-cacher.conf';
-
-my $configref;
-eval {
-        $configref = read_config($configfile);
-};
-my %config = %$configref;
-
-# not sure what to do if we can't read the config file...
-die "Could not read config file: $@" if $@;
-
-# Now set some things from the config file
-# $logfile used to be set in the config file: now we derive it from $logdir
-$config{logfile} = "$config{logdir}/access.log";
-
-# $errorfile used to be set in the config file: now we derive it from $logdir
-$config{errorfile} = "$config{logdir}/error.log";
-
-my $private_dir = "$config{cache_dir}/private";
-
-################################################
-
-# Now set some things from the config file
-$config{reportfile} = "$config{logdir}/report.html";
-
-
-
-# Remove the include lines from Apache's httpd.conf
-# Thankfully this is a lot easier now we're just symlinking our config file!
-if(-d "/etc/apache/conf.d/" ){
-	unlink("/etc/apache/conf.d/apt-cacher");
-}
-
-if(-d "/etc/apache-ssl/conf.d/" ){
-	unlink("/etc/apache-ssl/conf.d/apt-cacher");
-}
-
-if(-d "/etc/apache2/conf.d/" ){
-	unlink("/etc/apache2/conf.d/apt-cacher");
-	unlink("/etc/apache2/conf.d/apt-cacher.conf");
-}
-
-
-# Delete the cache directory and everything in it
-system("rm", "-rf", $config{cache_dir});
-
-# Delete the two log files (leaving the directory behind for now)
-unlink($config{logfile});
-unlink($config{errorfile});
-unlink($config{reportfile});
-
-#vvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvv
-# Just for now we still have to try nuking old entries in httpd.conf,
-# because they may have been left behind previously. After a couple
-# more releases this should be removed from here and install.pl
-
-# Remove the include lines from Apache's httpd.conf
-my $httpdconf = "/etc/apache/httpd.conf";
-if (-f $httpdconf) {
-	$old = $httpdconf;
-	$new = "$httpdconf.tmp.$$";
-	$bak = "$httpdconf.bak";
-	
-	open(OLD, "< $old")         or die "can't open $old: $!";
-	open(NEW, "> $new")         or die "can't open $new: $!";
-	
-	while (<OLD>) {
-		s/# This line has been appended by the Apt\-cacher install script/ /;
-		s/Include \/etc\/apt\-cacher\/apache.conf/ /;
-		(print NEW $_)          or die "can't write to $new: $!";
-	}
-	
-	close(OLD)                  or die "can't close $old: $!";
-	close(NEW)                  or die "can't close $new: $!";
-	
-	rename($old, $bak)          or die "can't rename $old to $bak: $!";
-	rename($new, $old)          or die "can't rename $new to $old: $!";
-}
-
-# Remove the include lines from Apache-SSL's httpd.conf
-$httpdconf = "/etc/apache-ssl/httpd.conf";
-if (-f $httpdconf) {
-	$old = $httpdconf;
-	$new = "$httpdconf.tmp.$$";
-	$bak = "$httpdconf.bak";
-	
-	open(OLD, "< $old")         or die "can't open $old: $!";
-	open(NEW, "> $new")         or die "can't open $new: $!";
-	
-	while (<OLD>) {
-		s/# This line has been appended by the Apt\-cacher install script/ /;
-		s/Include \/etc\/apt\-cacher\/apache.conf/ /;
-		(print NEW $_)          or die "can't write to $new: $!";
-	}
-	
-	close(OLD)                  or die "can't close $old: $!";
-	close(NEW)                  or die "can't close $new: $!";
-	
-	rename($old, $bak)          or die "can't rename $old to $bak: $!";
-	rename($new, $old)          or die "can't rename $new to $old: $!";
-}
-
-# Remove the include lines from Apache2's apache2.conf
-$httpdconf = "/etc/apache2/apache2.conf";
-if (-f $httpdconf) {
-        $old = $httpdconf;
-        $new = "$httpdconf.tmp.$$";
-        $bak = "$httpdconf.bak";
-
-        open(OLD, "< $old")         or die "can't open $old: $!";
-        open(NEW, "> $new")         or die "can't open $new: $!";
-
-        while (<OLD>) {
-                s/# This line has been appended by the Apt\-cacher install script/ /;
-                s/Include \/etc\/apt\-cacher\/apache.conf/ /;
-                (print NEW $_)          or die "can't write to $new: $!";
-        }
-
-        close(OLD)                  or die "can't close $old: $!";
-        close(NEW)                  or die "can't close $new: $!";
-
-        rename($old, $bak)          or die "can't rename $old to $bak: $!";
-        rename($new, $old)          or die "can't rename $new to $old: $!";
-}
-#^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
-
-
-exit(0);
diff -r 9ce9101b3e6b binary-overlay.xenrt/usr/local/share/apt-cacher/lib/upgrade.pl
--- a/binary-overlay.xenrt/usr/local/share/apt-cacher/lib/upgrade.pl	Wed Feb 27 12:23:56 2008 +0000
+++ /dev/null	Thu Jan 01 00:00:00 1970 +0000
@@ -1,124 +0,0 @@
-#!/usr/bin/perl -w
-#	@(#) remove.pl -- Upgrade script for apt-cacher
-#	$ Revision: $
-#	$ Source: $
-#	$ Date: $
-# This script is actually almost identical to the remove script, except that
-# on upgrade we don't want to nuke the cache contents so that part is commented
-# out. We also don't want to restart Apache twice (it already gets done by the
-# install script that gets run at the end of the upgrade, and even that's not
-# necessary).
-
-my $path = $ENV{PATH_INFO};
-#############################################################################
-### configuration ###########################################################
-# Include the library for the config file parser
-require '/usr/share/apt-cacher/apt-cacher-lib.pl';
-
-# Read in the config file and set the necessary variables
-my $configfile = '/etc/apt-cacher/apt-cacher.conf';
-
-my $configref;
-eval {
-        $configref = read_config($configfile);
-};
-my %config = %$configref;
-
-# not sure what to do if we can't read the config file...
-die "Could not read config file: $@" if $@;
-
-# Now set some things from the config file
-# $logfile used to be set in the config file: now we derive it from $logdir
-$config{logfile} = "$config{logdir}/access.log";
-
-# $errorfile used to be set in the config file: now we derive it from $logdir
-$config{errorfile} = "$config{logdir}/error.log";
-
-my $private_dir = "$config{cache_dir}/private";
-
-################################################
-
-# Now set some things from the config file
-$config{reportfile} = "$config{logdir}/report.html";
-
-
-
-
-# Remove the include lines from Apache's httpd.conf
-# This should really be turned into a function so I don't have to
-# copy the whole lot for Apache-SSL!
-my $httpdconf = "/etc/apache/httpd.conf";
-if (-f $httpdconf) {
-	$old = $httpdconf;
-	$new = "$httpdconf.tmp.$$";
-	$bak = "$httpdconf.bak";
-	
-	open(OLD, "< $old")         or die "can't open $old: $!";
-	open(NEW, "> $new")         or die "can't open $new: $!";
-	
-	while (<OLD>) {
-		s/# This line has been appended by the Apt\-cacher install script/ /;
-		s/Include \/etc\/apt\-cacher\/apache.conf/ /;
-		(print NEW $_)          or die "can't write to $new: $!";
-	}
-	
-	close(OLD)                  or die "can't close $old: $!";
-	close(NEW)                  or die "can't close $new: $!";
-	
-	rename($old, $bak)          or die "can't rename $old to $bak: $!";
-	rename($new, $old)          or die "can't rename $new to $old: $!";
-	
-	## Restart Apache
-	#if ( -f "/etc/init.d/apache" ) {
-	#	print "Restarting Apache (if you have an SSL cert password, enter it now):";
-	#	`/etc/init.d/apache restart`;
-	#	print "... done.\n";
-	#} else {
-	#	print "Apache startup script was not found. Please restart Apache manually.\n";
-	#}
-}
-
-# Remove the include lines from Apache-SSL's httpd.conf
-# This should really be turned into a function so I don't have to
-# copy the whole lot for Apache-SSL!
-$httpdconf = "/etc/apache-ssl/httpd.conf";
-if (-f $httpdconf) {
-	$old = $httpdconf;
-	$new = "$httpdconf.tmp.$$";
-	$bak = "$httpdconf.bak";
-	
-	open(OLD, "< $old")         or die "can't open $old: $!";
-	open(NEW, "> $new")         or die "can't open $new: $!";
-	
-	while (<OLD>) {
-		s/# This line has been appended by the Apt\-cacher install script/ /;
-		s/Include \/etc\/apt\-cacher\/apache.conf/ /;
-		(print NEW $_)          or die "can't write to $new: $!";
-	}
-	
-	close(OLD)                  or die "can't close $old: $!";
-	close(NEW)                  or die "can't close $new: $!";
-	
-	rename($old, $bak)          or die "can't rename $old to $bak: $!";
-	rename($new, $old)          or die "can't rename $new to $old: $!";
-	
-	## Restart Apache-SSL
-	#if ( -f "/etc/init.d/apache-ssl" ) {
-	#	print "Restarting Apache-SSL (if you have an SSL cert password, enter it now):";
-	#	`/etc/init.d/apache-ssl restart`;
-	#	print "... done.\n";
-	#} else {
-	#	print "Apache-SSL startup script was not found. Please restart Apache-SSL manually.\n";
-	#}
-}
-
-
-## Delete the cache directory and everything in it
-#system("rm -rf $config{cache_dir}");
-#
-## Delete the two log files (leaving the directory behind for now)
-#unlink($config{logfile});
-#unlink($config{errorfile});
-#unlink($config{reportfile});
-
-exit(0);
