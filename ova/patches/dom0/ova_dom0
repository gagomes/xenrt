# HG changeset patch
# Parent cc18a01046362ee08ce9d0fa08de0633582376e9
Cumulative XenRT OVA dom0.hg patches.

diff -r cc18a0104636 Makefile
--- a/Makefile	Mon Sep 13 14:21:38 2010 +0100
+++ b/Makefile	Tue Sep 28 13:04:52 2010 +0100
@@ -82,6 +82,11 @@
 OVA_STAGING = $(ISO_STAGING)/$(COMPONENT)
 OVA_IMAGE = $(MY_OBJ_DIR)/ova.ext3
 
+XENRT_SWAP_IMAGE = $(MY_OBJ_DIR)/swap
+XENRT_SWAP_G = 2
+XENRT_SWAP_DEVICE = sdb
+XENRT_DATA_DEVICE = sdc
+
 iso-cookie = $(MY_OBJ_DIR)/.$(1).iso.cookie
 ISO_COOKIE = $(call iso-cookie,$(COMPONENT))
 
@@ -92,14 +97,17 @@
 SUPP_PACK_FILES_SRC = $(addprefix $(STAGING)/usr/local/bin/,$(SUPP_PACK_FILES))
 
 # In 1,000,000,000 bytes not 1,073,741,824 (i.e. GB not GiB)
-OVA_DISK_G = 2
+OVA_DISK_G ?= 2
 # In 1,048,576 bytes not 1,000,000 (i.e. MiB not MB)
-OVA_MEM_MB = 512
-OVA_ROOT_DEVICE = xvda
+OVA_MEM_MB ?= 512
+OVA_ROOT_DEVICE = sda
 
 OVA_BRANDING = sed -e "s/@OVA_ROOT_DEVICE@/$(OVA_ROOT_DEVICE)/g" \
                    -e "s/@OVA_DISK@/$$(( $(OVA_DISK_G)*1000*1000*1000 ))/g" \
-                   -e "s/@OVA_MEM@/$$(( $(OVA_MEM_MB)*1024*1024 ))/g"
+                   -e "s/@OVA_MEM@/$$(( $(OVA_MEM_MB)*1024*1024 ))/g" \
+                   -e "s/@XENRT_SWAP_DEVICE@/$(XENRT_SWAP_DEVICE)/g" \
+                   -e "s/@XENRT_DISK_SWAP@/$$(( $(XENRT_SWAP_G)*1000*1000*1000 ))/g" \
+                   -e "s/@XENRT_DATA_DEVICE@/$(XENRT_DATA_DEVICE)/g"
 
 include $(PROJECT_OUTPUTDIR)/kernel-dom0/kernel.inc
 
@@ -107,8 +115,9 @@
 build-dom0: $(DOM0_PACKAGE) $(CDFILES_INSTALLED_COOKIE) $(MY_SOURCES)/MANIFEST
 	@ :
 
-.PHONY: build-ddk
+.PHONY: build-ddk build-xenrt
 build-ddk: $(ISO) $(SUPP_PACK_TARBALL) $(MY_SOURCES)/MANIFEST
+build-xenrt: $(ISO) $(MY_SOURCES)/MANIFEST
 	@:
 
 .PHONY: build-sdk
@@ -448,6 +457,72 @@
 
 	@touch $@
 
+$(MY_OBJ_DIR)/xrt_binaries/.stamp: $(CARBON_DISTFILES)/isolinux/syslinux-3.31.tar.bz2 $(CARBON_DISTFILES)/dnsmasq-2.40.tar.gz
+	$(call mkdir_clean,$(MY_OBJ_DIR)/xrt_binaries)
+	cd $(MY_OBJ_DIR)/xrt_binaries && tar -xjf $(CARBON_DISTFILES)/isolinux/syslinux-3.31.tar.bz2
+	cd $(MY_OBJ_DIR)/xrt_binaries && tar -xzf $(CARBON_DISTFILES)/dnsmasq-2.40.tar.gz
+	@touch $@
+
+$(call post-cookie,xenrt): $(COMMON_POST_COOKIE) $(MY_OBJ_DIR)/xrt_binaries/.stamp
+	$(CHROOT) depmod -a $(KERNEL_VERSION)
+	$(CHROOT) mkinitrd -f /boot/initrd-$(KERNEL_VERSION).img $(KERNEL_VERSION)
+	ln -fs menu.lst $(STAGING)/boot/grub/grub.conf
+	$(CHROOT) rm -f /etc/localtime
+	$(CHROOT) cp /usr/share/zoneinfo/UTC /etc/localtime
+	$(CHROOT) /sbin/chkconfig iptables off || true
+	$(CHROOT) /sbin/chkconfig httpd on || true
+	$(CHROOT) /sbin/chkconfig ntpd on || true
+	$(CHROOT) /sbin/chkconfig postgresql on || true
+	$(CHROOT) /sbin/chkconfig nfs on || true
+	$(CHROOT) /sbin/chkconfig dhcpd on || true
+	$(CHROOT) /sbin/chkconfig rootpassword on
+	$(CHROOT) /sbin/chkconfig unplug-vcpus off || true
+	$(CHROOT) chmod 755 /etc/init.d/ipsetup
+	$(CHROOT) chmod 755 /etc/ipsetup
+	$(CHROOT) /sbin/chkconfig ipsetup on
+	echo "root:xensource" | $(CHROOT) chpasswd
+	$(CHROOT) /usr/sbin/useradd -p xensource xenrtd
+	echo "xenrtd:xensource" | $(CHROOT) chpasswd
+	$(CHROOT) mkdir -p /local
+	$(CHROOT) mkdir -p /var/www/html
+	$(CHROOT) mkdir -p /usr/share/xenrt
+	$(CHROOT) mkdir -p /etc/xenrt
+	cp $(MY_OBJ_DIR)/xrt_binaries/syslinux-3.31/pxelinux.0 $(STAGING)/tftpboot/
+	cp $(MY_OBJ_DIR)/xrt_binaries/syslinux-3.31/com32/modules/mboot.c32 $(STAGING)/tftpboot/
+	cp -R $(MY_OBJ_DIR)/xrt_binaries/dnsmasq-2.40 $(STAGING)/root/
+	$(CHROOT) make -C /root/dnsmasq-2.40 install
+	$(CHROOT) chown -R xenrtd /tftpboot /local /usr/share/xenrt /etc/xenrt
+	$(CHROOT) ln -s /usr/share/xenrt /var/www/html/share
+	$(CHROOT) ln -s /local/scratch/www /var/www/html/export
+	$(CHROOT) ln -s /local/inputs/linux /var/www/html/linux
+	$(CHROOT) ln -s /usr/share/xenrt/control/style.css /var/www/html/style.css
+	$(CHROOT) ln -s /usr/share/xenrt/control/xenrt /usr/bin/xenrt
+	$(CHROOT) ln -s /usr/share/xenrt/exec/main.py /usr/bin/xrt
+	cd $(STAGING)/home/xenrtd ; hg clone http://hg.uk.xensource.com/xenrt.hg
+	$(CHROOT) chown -R xenrtd /home/xenrtd/xenrt.hg
+	# Pull in tests data
+	$(CHROOT) mkdir /home/xenrtd/tests
+	$(CHROOT) chown xenrtd /home/xenrtd/tests
+	$(STAGING)/home/xenrtd/xenrt.hg/scripts/ova/copytests \
+	    $(STAGING)/home/xenrtd/xenrt.hg/tests $(XENRT_DISTMASTER) \
+	    $(STAGING)/home/xenrtd/tests
+	# Remove Mercurial stuff
+	$(CHROOT) rm -rf /home/xenrtd/xenrt.hg/.hg
+	$(CHROOT) rm -rf /home/xenrtd/xenrt.hg/.hgtags
+	$(CHROOT) rm -rf /home/xenrtd/xenrt.hg/.hgignore
+	# Set up swap file
+	bash mkfs.swap $(XENRT_SWAP_IMAGE) $(XENRT_SWAP_G)
+	$(CHROOT) chmod -R a+x /usr/share/apt-cacher
+	$(CHROOT) chmod a+x /sbin/update-issue
+	# Bring in cleanroot images etc
+	cp -R $(XENRT_DISTMASTER)/clean $(STAGING)/tftpboot/
+	# Install any extra RPMs (XRT-4150)
+	$(CHROOT) mkdir -p /tmp/rpms
+	cp -R $(XENRT_DISTMASTER)/rpms $(STAGING)/tmp/rpms/
+	$(CHROOT) rpm -i /tmp/rpms/*.rpm || true
+
+	@touch $@
+
 # assemble output package from staging directory
 $(DOM0_PACKAGE): $(POST_COOKIE) $(MY_MAIN_PACKAGES)/.dirstamp
 	tar --directory $(STAGING) --exclude 'boot/grub' --exclude 'boot/message*' -cjf $@ .
@@ -487,9 +562,20 @@
 $(call iso-cookie,ddk): $(OVA_STAGING)/ova.xml
 	@touch $@
 
+$(call iso-cookie,xenrt): $(OVA_STAGING)/ova.xml
+	mkdir -p $(OVA_STAGING)/$(XENRT_SWAP_DEVICE)
+
+	set -ex ; for chunk in $$(seq -f "%09.f" 0 $$(($(XENRT_SWAP_G)-1))) ; do \
+		O=$(OVA_STAGING)/$(XENRT_SWAP_DEVICE)/chunk-$$chunk.gz ; \
+		dd if=$(XENRT_SWAP_IMAGE) bs=1MB count=1000 skip=$${chunk}000 | gzip -v9 > $${O} ; \
+	done
+
+	@touch $@
+
 # Build ISO
 $(MY_OUTPUT_DIR)/sdk.iso: LABEL := SDK
 $(MY_OUTPUT_DIR)/ddk.iso: LABEL := DDK
+$(MY_OUTPUT_DIR)/xenrt.iso: LABEL := XENRT
 $(ISO): $(ISO_COOKIE) $(MY_OUTPUT_DIR)/.dirstamp
 	mkisofs -joliet -joliet-long -r \
 		-V "$(PRODUCT_BRAND)-$(PRODUCT_VERSION) $(LABEL)" \
diff -r cc18a0104636 binary-overlay.xenrt/etc/apt-cacher/apache.conf
--- /dev/null	Thu Jan 01 00:00:00 1970 +0000
+++ b/binary-overlay.xenrt/etc/apt-cacher/apache.conf	Tue Sep 28 13:04:52 2010 +0100
@@ -0,0 +1,10 @@
+Alias /apt-cacher /usr/share/apt-cacher/apt-cacher.pl
+
+<DirectoryMatch /usr/share/apt-cacher/>
+	Options ExecCGI
+	AddHandler cgi-script .pl
+	AllowOverride None
+	order allow,deny
+	allow from all
+</DirectoryMatch>
+
diff -r cc18a0104636 binary-overlay.xenrt/etc/apt-cacher/apt-cacher.conf
--- /dev/null	Thu Jan 01 00:00:00 1970 +0000
+++ b/binary-overlay.xenrt/etc/apt-cacher/apt-cacher.conf	Tue Sep 28 13:04:52 2010 +0100
@@ -0,0 +1,140 @@
+#################################################################
+# This is the config file for apt-cacher. On most Debian systems
+# you can safely leave the defaults alone.
+#################################################################
+
+# cache_dir is used to set the location of the local cache. This can
+# become quite large, so make sure it is somewhere with plenty of space.
+cache_dir=/local/apt-cache
+
+# The email address of the administrator is displayed in the info page
+# and traffic reports.
+admin_email=root@localhost
+
+# For the daemon startup settings please edit the file /etc/default/apt-cacher.
+
+# Daemon port setting, only useful in stand-alone mode. You need to run the
+# daemon as root to use privileged ports (<1024).
+daemon_port=3142
+
+# optional settings, user and group to run the daemon as. Make sure they have
+# sufficient permissions on the cache and log directories. Comment the settings
+# to run apt-cacher as the native user.
+group=xenrtd
+user=xenrtd
+
+# optional setting, binds the listening daemon to one specified IP. Use IP
+# ranges for more advanced configuration, see below.
+# daemon_addr=localhost
+
+# If your apt-cacher machine is directly exposed to the Internet and you are
+# worried about unauthorised machines fetching packages through it, you can
+# specify a list of IPv4 addresses which are allowed to use it and another
+# list of IPv4 addresses which aren't.
+# Localhost (127.0.0.1) is always allowed. Other addresses must be matched
+# by allowed_hosts and not by denied_hosts to be permitted to use the cache.
+# Setting allowed_hosts to "*" means "allow all".
+# Otherwise the format is a comma-separated list containing addresses,
+# optionally with masks (like 10.0.0.0/22), or ranges of addresses (two
+# addresses separated by a hyphen, no masks, like '192.168.0.3-192.168.0.56').
+allowed_hosts=*
+denied_hosts=
+
+# And similiarly for IPv6 with allowed_hosts_6 and denied_hosts_6.
+# Note that IPv4-mapped IPv6 addresses (::ffff:w.x.y.z) are truncated to
+# w.x.y.z and are handled as IPv4.
+allowed_hosts_6=fec0::/16
+denied_hosts_6=
+
+# This thing can be done by Apache but is much simplier here - limit access to
+# Debian mirrors based on server names in the URLs
+#allowed_locations=ftp.uni-kl.de,ftp.nerim.net,debian.tu-bs.de
+
+# Apt-cacher can generate usage reports every 24 hours if you set this
+# directive to 1. You can view the reports in a web browser by pointing
+# to your cache machine with '/apt-cacher/report' on the end, like this:
+#      http://yourcache.example.com/apt-cacher/report
+# Generating reports is very fast even with many thousands of logfile
+# lines, so you can safely turn this on without creating much 
+# additional system load.
+generate_reports=0
+
+# Apt-cacher can clean up its cache directory every 24 hours if you set
+# this directive to 1. Cleaning the cache can take some time to run
+# (generally in the order of a few minutes) and removes all package
+# files that are not mentioned in any existing 'Packages' lists. This
+# has the effect of deleting packages that have been superseded by an
+# updated 'Packages' list.
+clean_cache=0
+
+# The directory to use for apt-cacher access and error logs.
+# The access log records every request in the format:
+# date-time|client ip address|HIT/MISS/EXPIRED|object size|object name
+# The error log is slightly more free-form, and is also used for debug
+# messages if debug mode is turned on.
+# Note that the old 'logfile' and 'errorfile' directives are
+# deprecated: if you set them explicitly they will be honoured, but it's
+# better to just get rid of them from old config files.
+logdir=/var/log/httpd/apt-cache
+
+# apt-cacher can use different methods to decide whether package lists need to
+# be updated,
+# A) looking at the age of the cached files
+# B) getting HTTP header from server and comparing that with cached data. This
+# method is more reliable and avoids desynchronisation of data and index files
+# but needs to transfer few bytes from the server every time somebody requests
+# the files ("apt-get update")
+# Set the following value to the maximum age (in hours) for method A or to 0
+# for method B
+expire_hours=0
+
+# Apt-cacher can pass all its requests to an external http proxy like
+# Squid, which could be very useful if you are using an ISP that blocks
+# port 80 and requires all web traffic to go through its proxy. The
+# format is 'hostname:port', eg: 'proxy.example.com:8080'.
+http_proxy=proxy.example.com:8080
+
+# Use of an external proxy can be turned on or off with this flag.
+# Value should be either 0 (off) or 1 (on).
+use_proxy=0
+
+# External http proxy sometimes need authentication to get full access. The
+# format is 'username:password'.
+http_proxy_auth=proxyuser:proxypass
+
+# Use of external proxy authentication can be turned on or off with this flag.
+# Value should be either 0 (off) or 1 (on).
+use_proxy_auth=0
+
+# Rate limiting sets the maximum bandwidth in bytes per second to use
+# for fetching packages. Syntax is fully defined in 'man wget'.
+# Use 'k' or 'm' to use kilobits or megabits / second: eg, 'limit=25k'.
+# Use 0 or a negative value for no rate limiting.
+limit=0
+
+# Debug mode makes apt-cacher spew a lot of extra debug junk to the
+# error log (whose location is defined with the 'logdir' directive).
+# Leave this off unless you need it, or your error log will get very
+# big. Acceptable values are 0 or 1.
+debug=0
+
+# Adapt the line in the usage info web page to match your server configuration
+# example_sources_line=deb&nbsp;http://<b>my.cacher.server:3142/</b>ftp.au.debian.org/debian&nbsp;unstable&nbsp;main&nbsp;contrib&nbsp;non-free
+
+# Print a 410 (Gone) HTTP message with the specified text when accessed via
+# CGI. Useful to tell users to adapt their sources.list files when the
+# apt-cacher server is beeing relocated (via apt-get's error messages while
+# running "update")
+#cgi_advise_to_use = Please use http://cacheserver:3142/ as apt-cacher access URL
+#cgi_advise_to_use = Server relocated. To change sources.list, run perl -pe "s,/apt-cacher\??,:3142," -i /etc/apt/sources.list
+
+# Server mapping - this allows to hide real server names behind virtual paths
+# that appear in the access URL. This method is known from apt-proxy. This is
+# also the only method to use FTP access to the target hosts. The syntax is simple, the part of the beginning to replace, followed by a list of mirror urls, all space separated. Multiple profile are separated by semicolons
+# path_map = debian ftp.uni-kl.de/pub/linux/debian ftp2.de.debian.org/debian ; ubuntu archive.ubuntu.com/ubuntu ; security security.debian.org/debian-security ftp2.de.debian.org/debian-security
+# Note that you need to specify all target servers in the allowed_locations
+# options if you make use of it. Also note that the paths should not overlap
+# each other. FTP access method not supported yet, maybe in the future.
+
+# Use offline mode by default
+offline_mode=1
diff -r cc18a0104636 binary-overlay.xenrt/etc/apt-cacher/checksumming.conf
--- /dev/null	Thu Jan 01 00:00:00 1970 +0000
+++ b/binary-overlay.xenrt/etc/apt-cacher/checksumming.conf	Tue Sep 28 13:04:52 2010 +0100
@@ -0,0 +1,8 @@
+# To enable data checksumming, install libdbd-sqlite3-perl and uncomment the
+# line below. Then wait untill the Packages/Sources files have been refreshed
+# once (and so the database has been built up). You can also nuke them in the
+# cache to trigger the update.
+# require '/usr/share/apt-cacher/apt-cacher-lib-cs.pl';
+
+# don't touch the following line
+1;
diff -r cc18a0104636 binary-overlay.xenrt/etc/httpd/conf.d/apt-cacher.conf
--- /dev/null	Thu Jan 01 00:00:00 1970 +0000
+++ b/binary-overlay.xenrt/etc/httpd/conf.d/apt-cacher.conf	Tue Sep 28 13:04:52 2010 +0100
@@ -0,0 +1,16 @@
+Alias /apt-cacher /usr/share/apt-cacher/apt-cacher.pl
+
+<DirectoryMatch /usr/share/apt-cacher/>
+	Options ExecCGI
+	AddHandler cgi-script .pl
+	AllowOverride None
+	order allow,deny
+	allow from all
+</DirectoryMatch>
+
+RewriteEngine on
+RewriteRule ^/debian-security/(.*) /apt-cacher/security.debian.org/$1 [PT]
+RewriteRule ^/debian-amd64/(.*) /apt-cacher/amd64.debian.net/debian-amd64/$1 [PT]
+RewriteRule ^/debian/(.*) /apt-cacher/ftp.us.debian.org/debian/$1 [PT]
+RewriteRule ^/debian-backports/(.*) /apt-cacher/www.backports.org/debian/$1 [PT]
+RewriteRule ^/XenServer/([^/]+)/debian/(.*) /apt-cacher/updates.xensource.com/XenServer/$1/debian/$2 [PT]
diff -r cc18a0104636 binary-overlay.xenrt/usr/sbin/apt-cacher
--- /dev/null	Thu Jan 01 00:00:00 1970 +0000
+++ b/binary-overlay.xenrt/usr/sbin/apt-cacher	Tue Sep 28 13:04:52 2010 +0100
@@ -0,0 +1,1648 @@
+#!/usr/bin/perl
+
+=head1 NAME
+
+ apt-cacher2 - WWW proxy optimized for use with APT
+
+ Copyright (C) 2005 Eduard Bloch <blade@debian.org>
+ Distributed under the terms of the GNU Public Licence (GPL).
+
+=head1 SYNOPSIS
+
+ ./setup.pl /home/me/cache
+ edit /etc/apt/sources.list (use sources like deb http://proxy:3142/archiveserver/debian ...)
+ apt-get update
+ apt-get -u upgrade
+
+=head1 DESCRIPTION
+
+If you have two or more Debian GNU/Linux machines on a fast local
+network and you wish to upgrade packages from the Internet, you
+don't want to download every package several times.
+
+apt-cacher2 is a tiny HTTP proxy that keeps a cache on disk of Debian
+binary/source packages and meta files which have been received from Debian
+distribution servers on the Internet. When an apt-get client issues
+a request for a file to apt-cacher2, if the file is already on disk
+it is served to the client immediately, otherwise it is fetched from the
+Internet and served to the client while a copy is beeing stored on the disk.
+This means that several Debian machines can be upgraded but each package needs
+to be downloaded only once.
+
+apt-cacher2 is a rewrite of the original apt-cacher.pl CGI script, keeping
+compatibility in mind. The cached data can be shared by the both
+implementations, while apt-cacher2 providers better performance and less server
+load.
+
+=head1 INSTALLATION
+
+Assuming your cache server is called B<www.myserver.com>
+and your cache directory is called B</home/me/cache>, then:
+
+1. Edit apt-cacher.conf to customize your settings
+
+2. Run apt-cacher2
+
+=cut
+# ----------------------------------------------------------------------------
+
+use strict;
+#use warnings;
+
+use Fcntl ':flock';
+use POSIX;
+
+use LWP::UserAgent;
+use IO::Socket::INET;
+use HTTP::Response;
+
+use Time::HiRes qw( sleep gettimeofday tv_interval );
+
+
+my @index_files = (
+    'Index',
+	'Packages.gz',
+	'Packages.bz2',
+	'Release',
+	'Release.gpg',
+	'Sources.gz',
+	'Sources.bz2',
+	'Contents-.+\.gz',
+    'pkglist.*\.bz2',
+    'release$',
+    'release\..*',
+    'srclist.*\.bz2'
+);
+my $index_files_regexp = '(' . join('|', @index_files) . ')$';
+
+
+# Include the library for the config file parser
+require '/usr/share/apt-cacher/apt-cacher-lib.pl';
+require '/etc/apt-cacher/checksumming.conf';
+
+
+# Set some defaults
+my $version='0.1'; # this will be auto-replaced when the Debian package is beeing built
+my $configfile_default = '/etc/apt-cacher/apt-cacher.conf';
+my $daemon_port_default=3142;
+my $client="local";
+
+# Read in the config file and set the necessary variables
+my $configfile = $configfile_default;
+
+my $direct_mode; # defines using STDIN/STDOUT
+my $inetd_mode; # no security checks
+my $cgi_mode;
+my $cgi_path;
+
+my $cfg;
+
+my $pidfile;
+my @extraconfig;
+
+my $chroot;
+my $retnum;
+my $do_fork_away;
+
+# this script needs to be executed trough a CGI wrapper setting a flag variable
+if($ENV{CGI_MODE})
+{
+    # yahoo, back to the roots, assume beeing in CGI mode
+    $cgi_mode=1;
+    $direct_mode=1;
+    # pick up the URL
+    $cgi_path=$ENV{PATH_INFO} if ! $cgi_path;
+    $cgi_path=$ENV{QUERY_STRING} if ! $cgi_path;
+    $cgi_path="/" if ! $cgi_path; # set an invalid path to display infos below
+}
+else {
+    while(scalar @ARGV) {
+
+        my $arg=shift(@ARGV);
+
+        if($arg eq "-c") {
+            $configfile=shift(@ARGV);
+            die "$configfile unreadable" if ! -r $configfile;
+        }
+        elsif($arg eq "-r") {
+            $chroot=shift(@ARGV);
+            die "No such directory: $chroot\n" if ! -d $chroot;
+        }
+        elsif($arg eq "-R") {
+            $retnum=shift(@ARGV);
+        }
+        elsif($arg eq "-i") {
+            $inetd_mode=1;
+            $direct_mode=1;
+        }
+        elsif($arg eq "-d") {
+            $do_fork_away=1;
+        }
+        elsif($arg eq "-p") {
+            $pidfile=shift(@ARGV);
+        }
+        elsif($arg=~/(\S+)=(\S+)/) {
+            push(@extraconfig, $1, $2);
+        }
+        elsif($arg eq "-h" || $arg eq "--help") {
+            print <<EOM;
+USAGE: $0 <options> <override(s)>
+Options:
+
+-c configfile   Custom config file (default: $configfile_default)
+-i              Inetd mode, STDIN and STDOUT are used for service
+(default: standalone server mode)
+-d              become a background daemon
+
+Advanced options (root only):
+-r directory    (experimental option) 
+                path to chroot to after reading the config and opening the log
+                files. cache directory setting must be relative to the new root.
+                WARNING: log files should be created before and be owned by tne
+                effective user/group if -g or -u are used
+-p pidfile      write the server process ID into this file
+
+Overrides:     override config variables (see config file), eg. daemon_port=9999
+
+EOM
+            exit(0);
+        }
+        else {
+            die "Unknown parameter $arg\n";
+        }
+    }
+}
+
+eval {
+        $cfg = read_config($configfile);
+};
+
+# not sure what to do if we can't read the config file...
+die "Could not read config file: $@" if $@;
+
+# Now set some things from the config file
+# $logfile used to be set in the config file: now we derive it from $logdir
+$$cfg{logfile} = "$$cfg{logdir}/access.log";
+
+# $errorfile used to be set in the config file: now we derive it from $logdir
+$$cfg{errorfile} = "$$cfg{logdir}/error.log";
+
+$$cfg{fetch_timeout}=300; # five minutes from now
+
+my $private_dir = "$$cfg{cache_dir}/private";
+define_global_lockfile("$private_dir/exlock");
+
+# override config values with the user-specified parameters
+while(@extraconfig) { 
+    my $k=shift(@extraconfig);
+    my $v=shift(@extraconfig); 
+    $$cfg{$k}=$v;
+}
+
+
+my ($aclog_fh, $erlog_fh);
+#FIXME: genauer die Scopes betrachten
+my ($path, $filename, $new_filename, $con, $source);
+
+my %pathmap;
+
+if($$cfg{path_map}) {
+    for(split(/\s*;\s*/, $$cfg{path_map})) {
+        my @tmp = split(/\s+/, $_);
+        # must have at least one path and target
+        next if ($#tmp < 1);
+        my $key=shift(@tmp);
+        $pathmap{$key}=[@tmp];
+    }
+}
+
+
+# Output data as soon as we print it
+$| = 1;
+
+# Function prototypes
+sub ipv4_addr_in_list ($$);
+sub ipv6_addr_in_list ($$);
+sub get_abort_time ();
+
+# ----------------------------------------------------------------------------
+# Die if we have not been configured correctly
+die "$0: No cache_dir directory!\n" if (!-d $$cfg{cache_dir});
+die "$0: No cache_dir/private directory!\n" if (!-d $private_dir);
+
+# ----------------------------------------------------------------------------
+# Data shared between functions
+
+my $cached_file;
+my $cached_head;
+my $complete_file;
+my $notify_file;
+
+my $do_import=0;
+my $concloseflag;
+my $is_index_file;
+
+my $ua;
+my $daemon;
+my $server_pid;
+my $fetcher_pid;
+my %childPids;
+my $terminating;
+
+sub term_handler {
+    $terminating=1;
+
+    # close all connections or shutdown the server if parent and kill 
+    debug_message("received SIGTERM, terminating");
+    $con->close if defined($con);
+
+    
+    if($server_pid && $server_pid == $$) {
+        $daemon->shutdown(2);
+    }
+
+    # stop all children
+    #{ doesn't work, signal comes delayed. Why?!
+    #    local $SIG{"TERM"} = 'IGNORE';          
+    #    kill("TERM", -$$);
+    #}
+    for(keys %childPids) { 
+        &debug_message("killing subprocess: $_"); 
+        kill 15, $_;
+    };
+    exit 0;
+};
+
+sub reload_config {
+    debug_message("Got SIGHUP, reloading config");
+    $cfg = read_config($configfile);
+};
+
+# broken, kills unrelated processes. Not using for now.
+# perlipc(1)
+# also remove them from the to-be-killed list
+#sub reap_children {
+#    my $child;
+#    while (($child = waitpid(-1,WNOHANG)) > 0) {
+#        delete $childPids{$child};
+#    }
+#    $SIG{CHLD} = \&reap_children;  # still loathe sysV
+#
+#}
+#$SIG{CHLD} = \&reap_children;
+$SIG{CHLD} = 'IGNORE';
+$SIG{'TERM'} = \&term_handler;
+$SIG{'HUP'} = \&reload_config;
+
+my $getBufLen=10000;
+my $maxspeed;
+
+my ($chfd, $pkfd);
+
+# for rate limit support
+if($$cfg{limit}>0) {
+    $maxspeed = $$cfg{limit}*1024;
+    $getBufLen = $maxspeed/20; # 20 portions per second should be enough
+}
+
+sub setup_agent {
+
+   return if(defined($ua));
+
+   $ua=LWP::UserAgent->new('keep_alive' => 1);
+
+   # Check whether a proxy is to be used, and set the appropriate environment variable
+   my $proxystring;
+   if ( $$cfg{use_proxy} eq 1 && $$cfg{http_proxy}) {
+       $proxystring="http://";
+       if ( $$cfg{use_proxy_auth} eq 1) {
+           $proxystring.=$$cfg{http_proxy_auth}.'@';
+       }
+       $proxystring.=$$cfg{http_proxy};
+   }
+   $ua->proxy("http", $proxystring) if $proxystring;
+}
+
+
+
+
+
+# BEGINN MAIN PART
+
+if($cgi_mode && defined($$cfg{cgi_advise_to_use}) && $$cfg{cgi_advise_to_use}) {
+    print "Status: 410 $$cfg{cgi_advise_to_use}\r\n\r\n";
+    exit 0;
+}
+
+if($direct_mode) {
+    &setup_ownership;
+    &open_log_files;
+#optional checksumming support
+    db_init("$$cfg{cache_dir}/md5sums.sl3");
+    $client = "INETD" if $inetd_mode;
+
+    # get the string if available even in inetd / direct mode so local calles can
+    # identify themselves in the logs.
+    $client=$ENV{REMOTE_ADDR} if exists $ENV{REMOTE_ADDR};
+
+    &handle_connection;
+    exit 0;
+}
+
+my %daemonopts = (LocalPort => $$cfg{daemon_port}, Proto => 'tcp', Listen => 1, ReuseAddr => 1);
+$daemonopts{LocalAddr}=$$cfg{daemon_addr} if(defined($$cfg{daemon_addr}));
+
+while(1) {
+    $daemon = IO::Socket::INET->new(%daemonopts);
+    last if $daemon;
+    $retnum--;
+    last if($retnum<=0);
+    print STDERR "Unable to bind socket (port $$cfg{daemon_port}), trying again in 5 seconds.\n";
+    sleep 5;
+}
+die "Unable to bind socket (port $$cfg{daemon_port}), $0 not started.\n" if ! $daemon;
+
+$server_pid=$$;
+
+if($do_fork_away) {
+    my $pid = fork();
+    if ($pid < 0) {
+        barf("fork() failed");
+    }
+    if ($pid > 0) {
+        # parent
+        exit 0;
+    }
+}
+
+# STATE: Port open, still beeing root. Create pidfiles, logfiles, then su
+# 
+if($pidfile) {
+    open(my $fh, ">$pidfile");
+    print $fh $$;
+    close($fh);
+}
+
+
+&setup_ownership;
+&open_log_files;
+#optional checksumming support
+db_init("$$cfg{cache_dir}/md5sums.sl3");
+
+# State: READY
+# That is the working condition (daemon mode)
+
+debug_message("Apt-Cacher started with Debug output enabled, accepting connections...");
+
+while (1)
+{
+    my $newcon = $daemon->accept;
+    # we don't stop, only by term_handler since the accept method is unreliable
+    next if(!$newcon);
+    last if $terminating;
+
+    $client = $newcon->peerhost;
+    debug_message("Connection from $client");
+
+    my $pid = fork();
+    if ($pid < 0) {
+        barf("fork() failed");
+    }
+
+    if ($pid > 0) {
+        # parent
+        debug_message("registred child process: $pid");
+        $childPids{$pid}=1;
+        next;
+    }
+    # child
+    undef %childPids;
+
+    &handle_connection($newcon);
+    exit (0);
+
+}
+exit 0;
+# exit from the daemon loop
+
+
+
+sub handle_connection {
+    # now begin connection's personal stuff
+    debug_message("New HTTP connection open");
+    
+    if($direct_mode) {
+        # beeing in forced mode, ie. manual call
+        $source=*STDIN;
+        $con = *STDOUT;
+    }
+    else {
+
+        # serving a network client
+        
+        $con = shift;
+        $source = $con;
+    }
+    
+
+    if(!$inetd_mode) {
+        # ----------------------------------------------------------------------------
+        # Let's do some security checking. We only want to respond to clients within an
+        # authorised address range (127.0.0.1 and ::1 are always allowed).
+
+        my $ip_pass = 1;
+        my $ip_fail = 0;
+        my $clientaddr;
+
+        # allowed_hosts == '*' means allow all ('' means deny all)
+        # denied_hosts == '' means don't explicitly deny any
+        # localhost is always accepted
+        # otherwise host must be in allowed list and not in denied list to be accepted
+
+        if ($client =~ /:/) # IPv6?
+        {
+            defined ($clientaddr = ipv6_normalise ($client)) or goto badaddr;
+            if (substr ($clientaddr, 0, 12) eq "\0\0\0\0\0\0\0\0\0\0\xFF\xFF")
+            {
+                $clientaddr = substr ($clientaddr, 12);
+                goto is_ipv4;
+            }
+            elsif ($clientaddr eq "\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\1")
+            {
+                debug_message("client is localhost");
+            }
+            else
+            {
+                $ip_pass = ($$cfg{allowed_hosts_6} =~ /^\*?$/) ||
+                ipv6_addr_in_list ($clientaddr, 'allowed_hosts_6');
+                $ip_fail = ipv6_addr_in_list ($clientaddr, 'denied_hosts_6');
+            }
+        }
+        elsif (defined ($clientaddr = ipv4_normalise ($client))) # IPv4?
+        {
+            is_ipv4:
+            if ($clientaddr eq "\x7F\0\0\1")
+            {
+                debug_message("client is localhost");
+            }
+            else
+            {
+                $ip_pass = ($$cfg{allowed_hosts} =~ /^\*?$/) ||
+                ipv4_addr_in_list ($clientaddr, 'allowed_hosts');
+                $ip_fail = ipv4_addr_in_list ($clientaddr, 'denied_hosts');
+            }
+        }
+        else
+        {
+            goto badaddr;
+        }
+
+        # Now check if the client address falls within this range
+        if ($ip_pass && !$ip_fail)
+        {
+            # Everything's cool, client is in allowed range
+            debug_message("Client $client passed access control rules");
+        }
+#        elsif($client eq "local")
+#        {
+#            # Everything's cool, client is in allowed range
+#            debug_message("Client $client passed access control rules");
+#        }
+        else
+        {
+            # Bzzzt, client is outside allowed range. Send 'em a 403 and bail.
+            badaddr:
+            debug_message("Alert: client $client disallowed by access control");
+
+            &sendrsp(403, "Access to cache prohibited");
+            exit(4);
+        }
+
+    }
+
+    REQUEST:
+    while(!$concloseflag) {
+
+        my $testpath; # temporary, to be set by GET lines, undef on GO
+        my $ifmosince;# to be undef by new GET lines
+        my $send_head_only=0; # to be undef by new GET lines
+        my $tolerated_empty_lines=20;
+        my $rangereq;
+
+        # reading input line by line, trough the secure input method
+        CLIENTLINE: while(1) {
+
+            debug_message("Processing a new request line");
+
+            $_=&getRequestLine;
+            debug_message("got: $_");
+
+            exit if !defined($_);
+
+            if(/^$/) {
+                if(defined($testpath)) {
+                    # done reading request
+                    $path=$testpath;
+                    last CLIENTLINE;
+                }
+                elsif(!$tolerated_empty_lines)   {
+                    &sendrsp(403, "Go away");
+                    exit(4);
+                }
+                else {
+                    $tolerated_empty_lines--;
+                }
+            }
+            else {
+                if(/^(GET|HEAD)\s+(\S+)/) {
+                    if(defined($testpath)) {
+                        &sendrsp(403, "Confusing request");
+                        exit(4);
+                    }
+                    $testpath=$2;
+                    # also support pure HEAD calls
+                    if($1 eq 'HEAD') {
+                        $send_head_only=1;
+                    }
+                }
+                elsif(/^Connection: close/i) {
+                    $concloseflag=1;
+                }
+                elsif(/^Connection: .*TE/) {
+                    $concloseflag=1;
+                }
+                elsif(/^Range/i) {
+                    $rangereq=1;
+                }
+                elsif(/^If-Modified-Since:\s+(.*)/i) {
+                    $ifmosince=$1;
+                }
+                elsif(/^\S+: [^:]*/) {
+                    # whatever, but valid
+                }
+                else {
+                    &sendrsp(403, "Could not understand $_");
+                    exit(4);
+                }
+            }
+        }
+
+        # always resend the file if a part was requested since we don't support ranges
+        $ifmosince=0 if !$rangereq;
+
+        # tolerate CGI specific junk and two slashes in the beginning
+        $path =~ s!^/apt-cacher\??/!/!;
+        $path =~ s!^//!/!;
+        $path =~ s!^http://!!; # allow proxy style
+
+        # Now parse the path
+        if ($path =~ /^\/?report/) {
+            usage_report();
+            exit(0);
+        }
+
+        if ($path !~ m(^/?.+/.+)) {
+            usage_error();
+        }
+
+        REPARSE:
+        
+        my($host,$uri) = ($path =~ m#^/?([^/]+)(/.+)#);
+        
+        if ( !$host || !$uri ) {
+            usage_error();
+        }
+
+        ($filename) = ($uri =~ /\/?([^\/]+)$/);
+
+        if($$cfg{allowed_locations}) {
+            #         debug_message("Doing location check for ".$$cfg{allowed_locations} );
+            my $mess;
+            my $cleanuri=$uri;
+            $cleanuri=~s!/[^/]+/[\.]{2}/!/!g;
+            if ($host eq ".." ) {
+                $mess = "'..' contained in the hostname";
+            }
+            elsif ($cleanuri =~/\/\.\./) {
+                $mess = "File outside of the allowed path";
+            }
+            else {
+                for( split(/\s*,\s*/,$$cfg{allowed_locations}) ) {
+                    debug_message("Testing URI: $host$cleanuri on $_");
+                    goto location_allowed if ("$host$cleanuri" =~ /^$_/);
+                }
+                $mess = "Host '$host' is not configured in the allowed_locations directive";
+            }
+            badguy:
+            debug_message("$mess; access denied");
+            &sendrsp(403, "Access to cache prohibited, $mess");
+            exit(4);
+        }
+        location_allowed:
+
+        $do_import=0;
+        $is_index_file=0;
+
+        if ($filename =~ /(\.deb|\.rpm|\.dsc|\.tar\.gz|\.diff\.gz|\.udeb)$/) {
+            # We must be fetching a .deb or a .rpm, so let's cache it.
+            # Place the file in the cache with just its basename
+            $new_filename = $filename;
+            debug_message("new filename with just basename: $new_filename");
+        } 
+        elsif ($filename =~ /2\d\d\d-\d\d-\d\d.*\.gz$/) {
+            # a patch file. Needs a unique filename but no freshness checks
+            $new_filename = "$host$uri";
+            $new_filename =~ s/\//_/g;
+            debug_message("new long filename: $new_filename");
+        }
+        elsif ($filename =~ /$index_files_regexp/) {
+            $is_index_file=1;
+            # It's a Packages.gz or related file: make a long filename so we can cache these files without
+            # the names colliding
+            $new_filename = "$host$uri";
+            $new_filename =~ s/\//_/g;
+            debug_message("new long filename: $new_filename");
+            # optional checksumming support
+            if ($filename =~ /(Packages|Sources)/) {
+                # warning, an attacker could poison the checksum cache easily
+                $do_import=1;
+            }
+        } else {
+            # Maybe someone's trying to use us as a general purpose proxy / relay.
+            # Let's stomp on that now.
+            debug_message("Sorry, not allowed to fetch that type of file: $filename");
+            &sendrsp(403, "Sorry, not allowed to fetch that type of file: $filename");
+            exit(4);
+        }
+
+        $cached_file = "$$cfg{cache_dir}/packages/$new_filename";
+        $cached_head = "$$cfg{cache_dir}/headers/$new_filename";
+        $complete_file = "$private_dir/$new_filename.complete";
+        $notify_file = "$private_dir/$new_filename.notify";
+
+        my $force_download=0;
+
+        my $cache_status;
+
+        debug_message("looking for $cached_file");
+
+        if ($is_index_file) {
+            debug_message("known as index file: $filename");
+            # in offline mode, deliver it as-is, otherwise check freshness
+            if (-f $cached_file && -f $cached_head && !$$cfg{offline_mode}) {
+                if($$cfg{expire_hours} > 0) {
+                    my $now = time();
+                    my @stat = stat($cached_file);
+                    if (@stat && int(($now - $stat[9])/3600) > $$cfg{expire_hours}) {
+                        debug_message("unlinking $new_filename because it is too old");
+                        # Set the status to EXPIRED so the log file can show it was downloaded again
+                        $cache_status = "EXPIRED";
+                        debug_message("$cache_status");
+                        $force_download=1;
+                    }
+                }
+                else {
+                    # use HTTP timestamping
+                    my ($oldhead, $testfile, $newhead);
+                    my $response = &ua_act(1, $host, $uri);
+                    #my $response = $ua->head("http://$host$uri");
+                    $newhead = $response->header("Last-Modified");
+                    if($newhead && open($testfile, $cached_head)) {
+                        
+                        $newhead =~ s/\n|\r//g;
+
+                        for(<$testfile>){
+                            if(/^.*Last-Modified:\s(.*)(\r|\n)/) {
+                                $oldhead = $1;
+                                last
+                            }
+                        }
+                        close($testfile);
+                    }
+                    if($oldhead && ($oldhead eq $newhead) ) {
+                        # that's ok
+                        debug_message("remote file not changed, $oldhead vs. $newhead");
+                    }
+                    else {
+                        debug_message("unlinking $new_filename because it differs from server's version");
+                        $cache_status = "EXPIRED";
+                        debug_message("$cache_status");
+                        $force_download=1;
+                    }
+                }
+            }
+        }
+
+        # handle if-modified-since in a better way (check the equality of
+        # the time stamps). Do only if download not forced above.
+
+        if($ifmosince && !$force_download) {
+            $ifmosince=~s/\n|\r//g;
+
+            my $oldhead;
+            if(open(my $testfile, $cached_head)) {
+                LINE: for(<$testfile>){
+                    if(/^.*Last-Modified:\s(.*)(\r|\n)/) {
+                        $oldhead = $1;
+                        last LINE;
+                    }
+                }
+                close($testfile);
+            }
+
+            if($oldhead && $ifmosince eq $oldhead) {
+                &sendrsp(304, "Not Modified");
+                debug_message("File not changed: $ifmosince");
+                next REQUEST;
+            }
+        }
+
+        &set_global_lock(": file download decission"); # file state decissions, lock that area
+
+        my $fromfile; # handle for the reader
+
+        # download or not decission. Also releases the global lock
+        dl_check:
+        if( !$force_download && -e $cached_head && -e $cached_file) {
+            if (-f $complete_file) {
+                # not much to do if complete
+                $cache_status = "HIT";
+                debug_message("$cache_status");
+            }
+            else {
+                # a fetcher was either not successfull or is still running
+                # look for activity...
+                sysopen($fromfile, $cached_file, O_RDONLY) || undef $fromfile;
+                if (flock($fromfile, LOCK_EX|LOCK_NB)) {
+                    flock($fromfile, LOCK_UN);
+                    # bad, no fetcher working on this package. Redownload it.
+                    close($fromfile); undef $fromfile;
+                    debug_message("no fetcher running, forcing download");
+                    $force_download=1;
+                    goto dl_check;
+                }
+            }
+
+            &release_global_lock;
+        }
+        else {
+            # bypass for offline mode, no forking, just report the "problem"
+            if($$cfg{offline_mode})
+            {
+                &sendrsp(503, "Apt-Cacher in Offline Mode");
+                next REQUEST;
+            }
+
+            # (re) download them
+            unlink($cached_file, $cached_head, $complete_file, $notify_file);
+            debug_message("file does not exist or so, creating it");
+            # Set the status to MISS so the log file can show it had to be downloaded
+            if(!defined($cache_status)) { # except on special presets from index file checks above
+                $cache_status = "MISS"; 
+                debug_message("$cache_status");
+            }
+
+            # the writer releases the global lock after opening the target file
+            my $pid = fork();
+            if ($pid < 0) {
+                barf("fork() failed");
+            }
+            if ($pid == 0) {
+                # child, the fetcher thread
+                undef %childPids;
+                sysopen($pkfd, $cached_file, O_RDWR|O_CREAT|O_EXCL, 0644) || barf("Unable to store files");
+                open ( $chfd, ">$cached_head");
+
+                if (flock($pkfd, LOCK_EX)) {
+                    # jump from the global lock to a lock on the target file
+                    &release_global_lock;
+
+                    &fetch_store ($host, $uri); 
+
+                    exit 0;
+                }
+                else {
+                    barf("Problem locking the target file!");
+                }
+                # child exiting above, so or so
+            }
+            # parent continues
+            $childPids{$pid}=1;
+            debug_message("registred child process: $pid");
+            # &release_global_lock; to be release by downloader thread, not here
+        }
+
+        debug_message("checks done, can return now");
+        my $ret = &return_file (\$fromfile, $send_head_only);
+        goto dl_check if $ret==2; # retry code
+        debug_message("Package sent");
+
+        # Write all the stuff to the log file
+        writeaccesslog("$cache_status", "$new_filename");
+        if(!$is_index_file && !check_sum($new_filename)) {
+            writeerrorlog("   ALARM!    Faulty package in local cache detected! Removing, to be replaced with the next download.");
+            unlink $cached_file;
+            exit(5);
+        }
+        
+    }
+
+}
+
+
+sub return_file {
+    # At this point the file is open, and it's either complete or somebody
+    # is fetching its contents
+
+    our ($ffref, $send_head_only) =@_;
+    my $fromfile=$$ffref;
+
+    my $header_printed=0;
+
+    data_init();
+    
+    my $abort_time = get_abort_time();
+
+    my $buf;
+
+    my $geslen=0;
+    my $curlen=0;
+    my $explen;
+
+    my $complete_found;
+
+    # needs to print the header first
+    CHUNK: while (1) {
+
+        #debug_message("Send loop iteration:");
+
+        if (time() > $abort_time) {
+            debug_message("abort (timeout)");
+            exit(4);
+        }
+
+        if(! $header_printed) {
+
+            # add this reader to the notification list before printing anything useful to the client
+            if(! -f $complete_file) { # there is no point if the package is already downloaded
+                open(my $nf, ">>$notify_file");
+                flock($nf, LOCK_EX);
+                print $nf "$$\n";
+                flock($nf, LOCK_UN);
+                close($nf);
+            }
+
+            my $headstring;
+            if(-s $cached_head) {
+                # header file seen, protect the reading 
+                &set_global_lock(": reading the header file");
+                if(! -f $cached_head) {
+                    # file removed while waiting for lock - download failure?!
+                    # start over, maybe spawning an own fetcher
+                    &release_global_lock;
+                    return 2;
+                    #goto dl_check;
+                }
+
+                open(my $in, $cached_head);
+                my $code=200;
+                my $msg='';
+                my $headstring='';
+
+                $headstring=<$in>; # read exactly one status line
+
+                ($code, $msg) = ($headstring=~/^HTTP\S+\s+(\d+)\s(.*)/);
+                # alternative for critical errors
+                if(!defined($code)) {
+                    ($code, $msg) = ($headstring=~/^(5\d\d)\s(.*)/);
+                }
+
+                if(!defined($code)) {
+                    writeerrorlog("Faulty header file detected: $cached_head, first line was: $headstring");
+                    unlink $cached_head;
+                    exit 3;
+                }
+
+                # in CGI mode, use alternative status line. Don't print one
+                # for normal data output (apache does not like that) but on
+                # anormal codes, and then exit immediately
+                if($cgi_mode) {
+                    # don't print the head line but a Status on errors instead
+                    $headstring=~s/^HTTP\S+/Status:/;
+                    if($code == 200) {
+                        $headstring=''; # kick headline by default
+                    }
+                    else {
+                        print $con $headstring."\n\n";
+                        exit 1;
+                    }
+                }
+
+                # keep alive or not? Just follow the client
+                $headstring .= "Connection: ".($concloseflag?"Close":"Keep-Alive")."\r\n";
+
+                # keep only parts interesting for apt
+                if($code==200) {
+                    for(<$in>) {
+                        if(/^Last-Modified|Content|Accept/) {
+                            $headstring.=$_;
+                            if(/^Content-Length:\ *(\d+)/) {
+                                $explen=$1;
+                            }
+                        }
+                    }
+                }
+                close($in);
+                &release_global_lock;
+
+                print $con $headstring."\r\n";
+
+                $header_printed=1;
+                debug_message("Header sent: $headstring");
+
+                # Stop after sending the header with errors
+                return if($code != 200); 
+
+            }
+            else {
+                sleep(0.5);
+                next CHUNK;
+            }
+
+            # pure HEAD request, we are done
+            return if $send_head_only;
+            debug_message("ready to send contents of $cached_file");
+        }
+
+        if(! $fromfile) # is the data file open already? open in this iteration if needed
+        {
+            debug_message("opening file first: $cached_file");
+            if( ! -f $cached_file) {
+                sleep(1);
+                next CHUNK;
+            }
+
+            sysopen($fromfile, $cached_file, O_RDONLY); #FIXME, checken
+            next CHUNK;
+        }
+        else
+        {
+            my $n=0;
+            $n = sysread($fromfile, $buf, 65536);
+            debug_message("read $n bytes");
+
+            if(!defined($n)) {
+                debug_message("Error detected, closing connection");
+                exit(4);
+            }
+            
+            if($n==0) {
+                
+                if($complete_found) { # comlete file was found in the previous iteration
+                    # this is the loop exit condition
+                    # 
+                    # some extra error cases
+                    #if($explen && $curlen != $explen) {
+                    #    writeerrorlog("  ALARM!   $cached_file file is smaller than expected ($explen). Renaming to $cached_file.corrupted for further investigation, check your filesystem!");
+                    #    unlink "$cached_file.corrupted";
+                    #    rename($cached_file, "$cached_file.corrupted");
+                    #    exit(5);
+                    #}
+                    last CHUNK;
+                }
+
+                if (-f $complete_file) {
+                    # do another iteration, may need to read remaining data
+                    debug_message("complete file found");
+                    $complete_found=1;
+                    next CHUNK;
+                }
+
+                #debug_message("waiting for new data");
+                # wait for fresh data
+                sleep(0.5);
+                next CHUNK;
+
+            }
+            else {
+                $curlen+=$n;
+                if($explen && $curlen > $explen) {
+                    writeerrorlog("  ALARM!   $cached_file file is larger than expected ($explen). Renaming to $cached_file.corrupted for further investigation, check your filesystem!");
+                    unlink "$cached_file.corrupted";
+                    rename($cached_file, "$cached_file.corrupted");
+                    exit(5);
+                }
+                #debug_message("write $n / $curlen bytes");
+                # send data and update watchdog
+                print $con $buf;
+                debug_message("wrote $n (sum: $curlen) bytes");
+                $abort_time = get_abort_time();
+                data_feed(\$buf);
+            }
+        }
+    }
+}
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+sub barf {
+	my $errs = shift;
+
+	die "--- $0: Fatal: $errs\n";
+}
+
+sub usage_error {
+    &open_log_files;
+	writeerrorlog("--- $0: Usage error");
+
+    if(! defined($$cfg{example_sources_line})) {
+        $$cfg{example_sources_line}="deb&nbsp;http://<b>yourcache.example.com:$$cfg{daemon_port}/</b>ftp.au.debian.org/debian&nbsp;unstable&nbsp;main&nbsp;contrib&nbsp;non-free";
+    }
+
+    &sendrsp(200, "OK", "Content-Type", "text/html", "Expires", 0);
+	print $con <<EOF;
+
+<html>
+<title>Apt-cacher version $version
+</title><style type="text/css"><!--
+a { text-decoration: none; }
+a:hover { text-decoration: underline; }
+h1 { font-family: arial, helvetica, sans-serif; font-size: 18pt; font-weight: bold;}
+h2 { font-family: arial, helvetica, sans-serif; font-size: 14pt; font-weight: bold;}
+body, td { font-family: arial, helvetica, sans-serif; font-size: 10pt; }
+th { font-family: arial, helvetica, sans-serif; font-size: 11pt; font-weight: bold; }
+//--></style>
+</head>
+<body>
+<p>
+<table border=0 cellpadding=8 cellspacing=1 bgcolor="#000000" align="center" width="600">
+<tr bgcolor="#9999cc"><td> <h1>Apt-cacher version $version</h1> </td></tr>
+<tr bgcolor="#cccccc"><td>
+Usage: edit your /etc/apt/sources.list so all your HTTP sources are prepended 
+with the address of your apt-cacher machine and the port, like this:
+<blockquote>deb&nbsp;http://ftp.au.debian.org/debian&nbsp;unstable&nbsp;main&nbsp;contrib&nbsp;non-free</blockquote>
+becomes
+<blockquote>$$cfg{example_sources_line}</blockquote>
+</td></tr>
+</table>
+
+<h2 align="center">config values</h2>
+<table border=0 cellpadding=3 cellspacing=1 bgcolor="#000000" align="center">
+<tr bgcolor="#9999cc"><th> Directive </th><th> Value </th></tr>
+<tr bgcolor="#cccccc"><td bgcolor="#ccccff"> configfile </td><td> $configfile </td></tr>
+<tr bgcolor="#cccccc"><td bgcolor="#ccccff"> admin_email </td><td> <a href="mailto:$$cfg{admin_email}">$$cfg{admin_email}</a> </td></tr>
+<tr bgcolor="#cccccc"><td bgcolor="#ccccff"> generate_reports </td><td> $$cfg{generate_reports} </td></tr>
+<tr bgcolor="#cccccc"><td bgcolor="#ccccff"> cache_dir </td><td> $$cfg{cache_dir} </td></tr>
+<tr bgcolor="#cccccc"><td bgcolor="#ccccff"> logfile </td><td> $$cfg{logfile} </td></tr>
+<tr bgcolor="#cccccc"><td bgcolor="#ccccff"> errorfile </td><td> $$cfg{errorfile} </td></tr>
+<tr bgcolor="#cccccc"><td bgcolor="#ccccff"> expire_hours </td><td> $$cfg{expire_hours} </td></tr>
+<tr bgcolor="#cccccc"><td bgcolor="#ccccff"> http_proxy </td><td> $$cfg{http_proxy} </td></tr>
+<tr bgcolor="#cccccc"><td bgcolor="#ccccff"> use_proxy </td><td> $$cfg{use_proxy} </td></tr>
+<tr bgcolor="#cccccc"><td bgcolor="#ccccff"> use_proxy_auth </td><td> $$cfg{use_proxy_auth} </td></tr>
+<tr bgcolor="#cccccc"><td bgcolor="#ccccff"> debug </td><td> $$cfg{debug} </td></tr>
+</table>
+
+<p>
+<h2 align="center">license</h2>
+<table border=0 cellpadding=8 cellspacing=1 bgcolor="#000000" align="center" width="600">
+<tr bgcolor="#cccccc"><td>
+<p>Apt-cacher is free software; you can redistribute it and/or modify it under the terms of the GNU General 
+Public License as published by the Free Software Foundation; either version 2 of the License, or (at your 
+option) any later version.
+
+<p>Apt-cacher is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the 
+implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public 
+License for more details.
+
+<p>A copy of the GNU General Public License is available as /usr/share/common-licenses/GPL in the Debian 
+GNU/Linux distribution or on the World Wide Web at http://www.gnu.org/copyleft/gpl.html. You can also 
+obtain it by writing to the Free Software Foundation, Inc., 59 Temple Place - Suite 330, Boston, MA 
+02111-1307, USA.
+</td></tr>
+</table>
+</body>
+</html>
+EOF
+
+    exit 1;
+
+}
+
+
+# Jon's extra stuff to write the event to a log file.
+sub writeaccesslog {
+    my $cache_status = shift;
+    my $new_filename = shift;
+
+    # The format is 'time|cache status (HIT, MISS or EXPIRED)|client IP address|file size|name of requested file'
+    my $time = localtime;
+    my ($dev,$ino,$mode,$nlink,$uid,$gid,$rdev,$size,$atime,$mtime,$ctime,$blksize,$blocks) = stat($cached_file);
+    my $file_length = 0;
+    $file_length+=$size if defined($size);
+
+    flock($aclog_fh, LOCK_EX);
+    print $aclog_fh "$time|$client|$cache_status|$file_length|$new_filename\n";
+    flock($aclog_fh, LOCK_UN);
+}
+
+# Jon's extra stuff to write errors to a log file.
+sub writeerrorlog {
+	my $message = shift;
+	
+	my $time = localtime;
+
+    flock($erlog_fh, LOCK_EX);
+    # files may need to be reopened sometimes - reason unknown yet, EBADF
+    # results
+	syswrite($erlog_fh,"$time|$client|$message\n") || &open_log_files;
+    flock($erlog_fh, LOCK_UN);
+}
+
+# Stuff to append debug messages to the error log.
+sub debug_message {
+    if ($$cfg{debug} eq 1) {
+        my $message = shift;
+        &writeerrorlog("debug [$$]: $message");
+    }
+}
+
+sub open_log_files {
+	if(!$erlog_fh)
+    {
+        open($erlog_fh,">>$$cfg{errorfile}") or barf("Unable to open $$cfg{errorfile}");
+    }
+    if(!$aclog_fh) {
+        open($aclog_fh,">>$$cfg{logfile}") or barf("Unable to open $$cfg{logfile}");
+    }
+}
+ 
+sub get_abort_time () {
+  return time () + $$cfg{fetch_timeout}; # five minutes from now
+}
+
+my $header_stored=0;
+
+my $tstart;
+my $geslen;
+
+sub get_callback {
+    my $errors=0;
+
+    my ($data, $response, $proto) = @_;
+#    debug_message("Callback got data\n");
+    if(!$header_stored) {
+        $header_stored=1;
+        my $headstring = $response->as_string;
+
+        # print $con $headstring;
+        
+        &set_global_lock(": Callback, storing the header"); # set the lock before writting the first byte to that file, and release it after the file is closed
+        (scalar print $chfd $headstring ) || $errors++;
+        close($chfd);
+        &release_global_lock;
+
+        if($maxspeed) {
+            $geslen=-$getBufLen; # will be re-added below
+            $tstart = [gettimeofday];
+        }
+
+    }
+    (scalar print $pkfd $data ) || $errors++;
+    #print $con $data;
+
+    data_feed(\$data);
+
+    # delay for rate limiting
+    if($maxspeed) {
+        $geslen+=$getBufLen;
+        my $delta= $geslen/$maxspeed - ( scalar tv_interval ( $tstart ));
+        sleep($delta) if ($delta > 0);
+    }
+
+    if($errors) {
+        writeerrorlog("Write error. Disk full?");
+        # don't just exit here, fetcher needs to handle that
+        die();
+    }
+}
+
+sub fetch_store {
+
+    my ($host, $uri) = @_;
+
+    my $url = "http://$host$uri";
+    debug_message("fetcher: try to fetch $url");
+
+    # for checksumming
+    data_init();
+
+    my $response = &ua_act(0, $host, $uri);
+    #my $response = $ua->get($url, ':content_cb' => \&get_callback, ':read_size_hint' => $getBufLen);
+    #$geslen=0;
+
+    debug_message("Get is back");
+
+    if ($response->is_success && !defined($response->header("X-Died")) )
+    {
+
+        close($pkfd) if $pkfd;
+        undef $pkfd;
+
+        debug_message("stored $url as $cached_file");
+
+        # check missmatch or fetcher failure, could not connect the server
+        if( !$is_index_file && !check_sum($new_filename)) {
+            &set_global_lock(": file corruption report");
+            writeerrorlog("Do00h, checksum mismatch on $new_filename");
+            unlink $cached_file, $cached_head;
+            open(MF, ">$cached_head");
+            print MF "HTTP/1.1 502 Data corruption";
+            close(MF);
+            &kill_readers;
+            &release_global_lock;
+        }
+
+        # assuming here that the filesystem really closes the file and writes
+        # it out to disk before creating the complete flag file
+        
+        debug_message("setting complete flag for $new_filename");
+        # Now create the file to show the pickup is complete, also store the original URL there
+        open(MF, ">$private_dir/$new_filename.complete");
+        print MF $path;
+        close(MF); 
+
+        # index file seen? Get checksums
+        import_sums($cached_file) if $do_import;
+        
+        # store the sum, it may be not available yet but better this one than
+        # nothing. 
+        # disabled for now store_sum($new_filename);
+        # The sum may change on index files but that case is handled
+        # separately, the stored sum is allowed to differ from the data
+        # contents.
+
+    }
+    else
+    {
+        if(defined($response->header("X-Died"))) {
+            $response->code(502);
+            $response->message("Apt-Cacher: Transfer terminated");
+        }
+
+        debug_message("Reporting error: ".$response->code);
+        &set_global_lock(": HTTP error report");
+        open(my $ch, $cached_head);
+        my $headstring = $response->as_string;
+        if($headstring=~/^5\d\d/) { 
+            # work around LWP bug, incorrect status line with internal messages
+            $headstring = "HTTP/1.1 $headstring";
+        }
+        print $chfd $headstring;
+        close($chfd);
+        &release_global_lock;
+        if(defined($response->header("X-Died"))) { # was critical, most likely frozen now
+            &kill_readers;
+        }
+    }
+
+    debug_message("fetcher exiting");
+    unlink $notify_file;
+
+    # reset the shared vars
+    $header_stored=0; # FIXME, really needed? fetcher thread runs only once
+
+    _exit(0);
+}
+
+# FIXME: that sucks. Still needed?!
+sub kill_readers {
+    my $nf;
+    if(open($nf, $notify_file)) {
+        while(<$nf>) {
+            chomp;
+        debug_message("Stopping reader: $_");
+               kill 9, $_; # hard, bypassing the handler
+        }
+        close($nf);
+    }
+    # should be okay to unlink the file after all readers are "notified"
+    unlink $cached_file;
+}
+
+
+# Check if there has been a usage report generated and display it
+sub usage_report {
+	my $usage_file = "$$cfg{logdir}/report.html";
+    &sendrsp(200, "OK", "Content-Type", "text/html", "Expires", 0);
+	if (!-f $usage_file) {
+		print $con <<EOF;
+
+<html>
+<title>Apt-cacher traffic report</title><style type="text/css"><!--
+a { text-decoration: none; }
+a:hover { text-decoration: underline; }
+h1 { font-family: arial, helvetica, sans-serif; font-size: 18pt; font-weight: bold;}
+h2 { font-family: arial, helvetica, sans-serif; font-size: 14pt; font-weight: bold;}
+body, td { font-family: arial, helvetica, sans-serif; font-size: 10pt; }
+th { font-family: arial, helvetica, sans-serif; font-size: 11pt; font-weight: bold; }
+//--></style>
+</head>
+<body>
+<table border=0 cellpadding=8 cellspacing=1 bgcolor="#000000" align="center" width="600">
+<tr bgcolor="#9999cc"><td> <h1>Apt-cacher traffic report</h1> </td></tr>
+</td></tr>
+</table>
+		
+<p><table border=0 cellpadding=3 cellspacing=1 bgcolor="#000000" align="center" width="600">
+<tr bgcolor="#9999cc"><th bgcolor="#9999cc"> An Apt-cacher usage report has not yet been generated </th></tr>
+<tr bgcolor="#cccccc"><td bgcolor="#ccccff"> Reports are generated every 24 hours. If you want reports to be generated, make sure you set '<b>generate_reports=1</b>' in <b>$configfile</b>.</td></tr>
+</table>
+		</body>
+		</html>
+EOF
+
+	}
+	else
+	{
+        open(my $usefile, $usage_file);
+        my @usedata = <$usefile>;
+        close($usefile);
+        print $con @usedata;
+	}
+}
+
+# IP address filtering.
+sub ipv4_addr_in_list ($$)
+{
+	return 0 if $_[0] eq '';
+	debug_message ("testing $_[1]");
+	return 0 unless $$cfg{$_[1]};
+
+	my ($client, $cfitem) = @_;
+	my @allowed_hosts = split(/,\s*/, $$cfg{$cfitem});
+	for my $ahp (@allowed_hosts)
+	{
+		goto unknown if $ahp !~ /^[-\/,.[:digit:]]+$/;
+
+		# single host
+		if ($ahp =~ /^([^-\/]*)$/)
+		{
+			my $ip = $1;
+			debug_message("checking against $ip");
+			defined ($ip = ipv4_normalise($ip)) or goto unknown;
+			return 1 if $ip eq $client;
+		}
+		# range of hosts (netmask)
+		elsif ($ahp =~ /^([^-\/]*)\/([^-\/]*)$/)
+		{
+			my ($base, $mask) = ($1, $2);
+			debug_message("checking against $ahp");
+			defined ($base = ipv4_normalise($base)) or goto unknown;
+			$mask = ($mask =~ /^\d+$/) ? make_mask ($mask, 32)
+																 : ipv4_normalise ($mask);
+			goto unknown unless defined $mask;
+			return 1 if ($client & $mask) eq ($base & $mask);
+		}
+		# range of hosts (start & end)
+		elsif ($ahp =~ /^([^-\/]*)-([^-\/]*)$/)
+		{
+			my ($start, $end) = ($1, $2);
+			debug_message("checking against $start to $end");
+			defined ($start = ipv4_normalise($start)) or goto unknown;
+			defined ($end = ipv4_normalise($end)) or goto unknown;
+			return 1 if $client ge $start && $client le $end;
+		}
+		# unknown
+		else
+		{
+			unknown:
+			debug_message("Alert: $cfitem ($ahp) is bad");
+			&sendrsp(500, "Configuration error");
+			exit(4);
+		}
+	}
+	return 0; # failed
+}
+
+sub ipv6_addr_in_list ($$)
+{
+	return 0 if $_[0] eq '';
+	debug_message ("testing $_[1]");
+	return 0 unless $$cfg{$_[1]};
+
+	my ($client, $cfitem) = @_;
+	my @allowed_hosts = split(/,\s*/, $$cfg{$cfitem});
+	for my $ahp (@allowed_hosts)
+	{
+		goto unknown if $ahp !~ /^[-\/,:[:xdigit:]]+$/;
+
+		# single host
+		if ($ahp =~ /^([^-\/]*)$/)
+		{
+			my $ip = $1;
+			debug_message("checking against $ip");
+			$ip = ipv6_normalise($ip);
+			goto unknown if $ip eq '';
+			return 1 if $ip eq $client;
+		}
+		# range of hosts (netmask)
+		elsif ($ahp =~ /^([^-\/]*)\/([^-\/]*)$/)
+		{
+			my ($base, $mask) = ($1, $2);
+			debug_message("checking against $ahp");
+			$base = ipv6_normalise($base);
+			goto unknown if $base eq '';
+			goto unknown if $mask !~ /^\d+$/ || $mask < 0 || $mask > 128;
+			my $m = ("\xFF" x ($mask / 8));
+			$m .= chr ((-1 << (8 - $mask % 8)) & 255) if $mask % 8;
+			$mask = $m . ("\0" x (16 - length ($m)));
+			return 1 if ($client & $mask) eq ($base & $mask);
+		}
+		# range of hosts (start & end)
+		elsif ($ahp =~ /^([^-\/]*)-([^-\/]*)$/)
+		{
+			my ($start, $end) = ($1, $2);
+			debug_message("checking against $start to $end");
+			$start = ipv6_normalise($start);
+			$end = ipv6_normalise($end);
+			goto unknown if $start eq '' || $end eq '';
+			return 1 if $client ge $start && $client le $end;
+		}
+		# unknown
+		else
+		{
+			unknown:
+			debug_message("Alert: $cfitem ($ahp) is bad");
+            &sendrsp(500, "Configuration error");
+			exit(4);
+		}
+	}
+	return 0; # failed
+}
+
+sub sendrsp {
+    my $code=shift;
+    my $msg=shift;
+    $msg="" if !defined($msg);
+    
+    my $initmsg=
+    $cgi_mode ? 
+    "Status: $code $msg\r\n" :
+    "HTTP/1.1 $code $msg\r\n";
+    
+    $initmsg.="Connection: Keep-Alive\r\nAccept-Ranges: bytes\r\nKeep-Alive: timeout=15, max=100\r\n" if ($code ne 403);
+
+    #debug_message("Sending Response: $initmsg");
+    print $con $initmsg;
+
+    my $altbit=0;
+    for(@_) {
+        $altbit=!$altbit;
+        if($altbit) {
+            #debug_message("$_: ");
+            print $con $_.": ";
+        }
+        else {
+            #debug_message($_."\r\n);
+            print $con $_."\r\n";
+        }
+    }
+    print $con "\r\n";
+
+}
+
+# DOS attack safe input reader
+my @reqLineBuf;
+my $reqTail;
+sub getRequestLine {
+    if($cgi_path) { 
+        push(@reqLineBuf, "GET $cgi_path", "", undef); # undef stops operation
+        undef $cgi_path; # don't re-add it
+    }
+    if(! @reqLineBuf) {
+        my $buf="";
+
+        # after every read at least one line MUST have been found. Read length
+        # is large enough.
+
+        my $n=sysread($source, $buf, 1024);
+        $buf=$reqTail.$buf if(defined($reqTail));
+        undef $reqTail;
+
+        # pushes the lines found into the buffer. The last one may be incomplete,
+        # extra handling below
+        push(@reqLineBuf, split(/\r\n/, $buf, 1000) );
+
+        # buf did not end in a line terminator so the last line is an incomplete
+        # chunk. Does also work if \r and \n are separated
+        if(substr($buf, -2) ne "\r\n") {
+            $reqTail=pop(@reqLineBuf);
+        }
+    }
+    return shift(@reqLineBuf);
+}
+
+# runs the get or head operations on the user agent
+sub ua_act {
+    my ($only_head, $vhost, $uri) = @_;
+
+    my $url="http://$vhost$uri";
+    
+    &setup_agent;
+
+    my $do_hopping = (exists $pathmap{$vhost});
+
+    my $response;
+    my $hostcand;
+
+    RETRY_ACTION:
+
+    # make the virtual hosts real. The list is reduced which is not so smart,
+    # but since the fetcher process dies anyway it does not matter.
+    if($do_hopping) {
+        $hostcand = shift(@{$pathmap{$vhost}});
+        debug_message("Candidate: $hostcand");
+        $url=($hostcand =~ /^http:/?"" : "http://").$hostcand.$uri;
+        #$url="http://$hostcand$uri";
+        #$url="$hostcand$uri" if not $hostcand =~ /:\/\//;
+    }
+
+    debug_message("download agent: getting $url");
+    
+    if($only_head) {
+        $response = $ua->head($url);
+    }
+    else {
+        $response = $ua->get($url, ':content_cb' => \&get_callback, ':read_size_hint' => $getBufLen);
+    }
+
+    if($do_hopping) {
+        # if okay or the last candidate failes, put it back into the list
+        if($response->is_success || ! @{$pathmap{$vhost}} ) { 
+            unshift(@{$pathmap{$vhost}}, $hostcand);
+        }
+        else {
+            goto RETRY_ACTION;
+        }
+    }
+
+    return $response;
+}
+
+
+sub setup_ownership {
+    my $uid=$$cfg{user};
+    my $gid=$$cfg{group};
+
+    if($chroot) {
+        if($uid || $gid) {
+            # open them now, before it is too late
+            # FIXME: reopening won't work, but the lose of file handles needs to be
+            # made reproducible first
+            &open_log_files;
+        }
+        chroot $chroot || die "Unable to chroot, aborting.\n";
+        chdir $chroot;
+    }
+
+    if($gid) {
+        if($gid=~/^\d+$/) {
+            my $name=getgrgid($gid);
+            die "Unknown group ID: $gid (exiting)\n" if !$name;
+        }
+        else {
+            $gid=getgrnam($gid);
+            die "No such group (exiting)\n" if !defined($gid);
+        }
+        $) = $gid;
+        $( = $gid;
+        $) =~ /^$gid\b/ && $( =~ /^$gid\b/ || barf("Unable to change group id");
+    }
+
+    if($uid) {
+        if($uid=~/^\d+$/) {
+            my $name=getpwuid($uid);
+            die "Unknown user ID: $uid (exiting)\n" if !$name;
+        }
+        else {
+            $uid=getpwnam($uid);
+            die "No such user (exiting)\n" if !defined($uid);
+        }
+        $> = $uid;
+        $< = $uid;
+        $> == $uid && $< == $uid || barf("Unable to change user id");
+    }
+}
diff -r cc18a0104636 binary-overlay.xenrt/usr/share/apt-cacher/apt-cacher
--- /dev/null	Thu Jan 01 00:00:00 1970 +0000
+++ b/binary-overlay.xenrt/usr/share/apt-cacher/apt-cacher	Tue Sep 28 13:04:52 2010 +0100
@@ -0,0 +1,1648 @@
+#!/usr/bin/perl
+
+=head1 NAME
+
+ apt-cacher2 - WWW proxy optimized for use with APT
+
+ Copyright (C) 2005 Eduard Bloch <blade@debian.org>
+ Distributed under the terms of the GNU Public Licence (GPL).
+
+=head1 SYNOPSIS
+
+ ./setup.pl /home/me/cache
+ edit /etc/apt/sources.list (use sources like deb http://proxy:3142/archiveserver/debian ...)
+ apt-get update
+ apt-get -u upgrade
+
+=head1 DESCRIPTION
+
+If you have two or more Debian GNU/Linux machines on a fast local
+network and you wish to upgrade packages from the Internet, you
+don't want to download every package several times.
+
+apt-cacher2 is a tiny HTTP proxy that keeps a cache on disk of Debian
+binary/source packages and meta files which have been received from Debian
+distribution servers on the Internet. When an apt-get client issues
+a request for a file to apt-cacher2, if the file is already on disk
+it is served to the client immediately, otherwise it is fetched from the
+Internet and served to the client while a copy is beeing stored on the disk.
+This means that several Debian machines can be upgraded but each package needs
+to be downloaded only once.
+
+apt-cacher2 is a rewrite of the original apt-cacher.pl CGI script, keeping
+compatibility in mind. The cached data can be shared by the both
+implementations, while apt-cacher2 providers better performance and less server
+load.
+
+=head1 INSTALLATION
+
+Assuming your cache server is called B<www.myserver.com>
+and your cache directory is called B</home/me/cache>, then:
+
+1. Edit apt-cacher.conf to customize your settings
+
+2. Run apt-cacher2
+
+=cut
+# ----------------------------------------------------------------------------
+
+use strict;
+#use warnings;
+
+use Fcntl ':flock';
+use POSIX;
+
+use LWP::UserAgent;
+use IO::Socket::INET;
+use HTTP::Response;
+
+use Time::HiRes qw( sleep gettimeofday tv_interval );
+
+
+my @index_files = (
+    'Index',
+	'Packages.gz',
+	'Packages.bz2',
+	'Release',
+	'Release.gpg',
+	'Sources.gz',
+	'Sources.bz2',
+	'Contents-.+\.gz',
+    'pkglist.*\.bz2',
+    'release$',
+    'release\..*',
+    'srclist.*\.bz2'
+);
+my $index_files_regexp = '(' . join('|', @index_files) . ')$';
+
+
+# Include the library for the config file parser
+require '/usr/share/apt-cacher/apt-cacher-lib.pl';
+require '/etc/apt-cacher/checksumming.conf';
+
+
+# Set some defaults
+my $version='0.1'; # this will be auto-replaced when the Debian package is beeing built
+my $configfile_default = '/etc/apt-cacher/apt-cacher.conf';
+my $daemon_port_default=3142;
+my $client="local";
+
+# Read in the config file and set the necessary variables
+my $configfile = $configfile_default;
+
+my $direct_mode; # defines using STDIN/STDOUT
+my $inetd_mode; # no security checks
+my $cgi_mode;
+my $cgi_path;
+
+my $cfg;
+
+my $pidfile;
+my @extraconfig;
+
+my $chroot;
+my $retnum;
+my $do_fork_away;
+
+# this script needs to be executed trough a CGI wrapper setting a flag variable
+if($ENV{CGI_MODE})
+{
+    # yahoo, back to the roots, assume beeing in CGI mode
+    $cgi_mode=1;
+    $direct_mode=1;
+    # pick up the URL
+    $cgi_path=$ENV{PATH_INFO} if ! $cgi_path;
+    $cgi_path=$ENV{QUERY_STRING} if ! $cgi_path;
+    $cgi_path="/" if ! $cgi_path; # set an invalid path to display infos below
+}
+else {
+    while(scalar @ARGV) {
+
+        my $arg=shift(@ARGV);
+
+        if($arg eq "-c") {
+            $configfile=shift(@ARGV);
+            die "$configfile unreadable" if ! -r $configfile;
+        }
+        elsif($arg eq "-r") {
+            $chroot=shift(@ARGV);
+            die "No such directory: $chroot\n" if ! -d $chroot;
+        }
+        elsif($arg eq "-R") {
+            $retnum=shift(@ARGV);
+        }
+        elsif($arg eq "-i") {
+            $inetd_mode=1;
+            $direct_mode=1;
+        }
+        elsif($arg eq "-d") {
+            $do_fork_away=1;
+        }
+        elsif($arg eq "-p") {
+            $pidfile=shift(@ARGV);
+        }
+        elsif($arg=~/(\S+)=(\S+)/) {
+            push(@extraconfig, $1, $2);
+        }
+        elsif($arg eq "-h" || $arg eq "--help") {
+            print <<EOM;
+USAGE: $0 <options> <override(s)>
+Options:
+
+-c configfile   Custom config file (default: $configfile_default)
+-i              Inetd mode, STDIN and STDOUT are used for service
+(default: standalone server mode)
+-d              become a background daemon
+
+Advanced options (root only):
+-r directory    (experimental option) 
+                path to chroot to after reading the config and opening the log
+                files. cache directory setting must be relative to the new root.
+                WARNING: log files should be created before and be owned by tne
+                effective user/group if -g or -u are used
+-p pidfile      write the server process ID into this file
+
+Overrides:     override config variables (see config file), eg. daemon_port=9999
+
+EOM
+            exit(0);
+        }
+        else {
+            die "Unknown parameter $arg\n";
+        }
+    }
+}
+
+eval {
+        $cfg = read_config($configfile);
+};
+
+# not sure what to do if we can't read the config file...
+die "Could not read config file: $@" if $@;
+
+# Now set some things from the config file
+# $logfile used to be set in the config file: now we derive it from $logdir
+$$cfg{logfile} = "$$cfg{logdir}/access.log";
+
+# $errorfile used to be set in the config file: now we derive it from $logdir
+$$cfg{errorfile} = "$$cfg{logdir}/error.log";
+
+$$cfg{fetch_timeout}=300; # five minutes from now
+
+my $private_dir = "$$cfg{cache_dir}/private";
+define_global_lockfile("$private_dir/exlock");
+
+# override config values with the user-specified parameters
+while(@extraconfig) { 
+    my $k=shift(@extraconfig);
+    my $v=shift(@extraconfig); 
+    $$cfg{$k}=$v;
+}
+
+
+my ($aclog_fh, $erlog_fh);
+#FIXME: genauer die Scopes betrachten
+my ($path, $filename, $new_filename, $con, $source);
+
+my %pathmap;
+
+if($$cfg{path_map}) {
+    for(split(/\s*;\s*/, $$cfg{path_map})) {
+        my @tmp = split(/\s+/, $_);
+        # must have at least one path and target
+        next if ($#tmp < 1);
+        my $key=shift(@tmp);
+        $pathmap{$key}=[@tmp];
+    }
+}
+
+
+# Output data as soon as we print it
+$| = 1;
+
+# Function prototypes
+sub ipv4_addr_in_list ($$);
+sub ipv6_addr_in_list ($$);
+sub get_abort_time ();
+
+# ----------------------------------------------------------------------------
+# Die if we have not been configured correctly
+die "$0: No cache_dir directory!\n" if (!-d $$cfg{cache_dir});
+die "$0: No cache_dir/private directory!\n" if (!-d $private_dir);
+
+# ----------------------------------------------------------------------------
+# Data shared between functions
+
+my $cached_file;
+my $cached_head;
+my $complete_file;
+my $notify_file;
+
+my $do_import=0;
+my $concloseflag;
+my $is_index_file;
+
+my $ua;
+my $daemon;
+my $server_pid;
+my $fetcher_pid;
+my %childPids;
+my $terminating;
+
+sub term_handler {
+    $terminating=1;
+
+    # close all connections or shutdown the server if parent and kill 
+    debug_message("received SIGTERM, terminating");
+    $con->close if defined($con);
+
+    
+    if($server_pid && $server_pid == $$) {
+        $daemon->shutdown(2);
+    }
+
+    # stop all children
+    #{ doesn't work, signal comes delayed. Why?!
+    #    local $SIG{"TERM"} = 'IGNORE';          
+    #    kill("TERM", -$$);
+    #}
+    for(keys %childPids) { 
+        &debug_message("killing subprocess: $_"); 
+        kill 15, $_;
+    };
+    exit 0;
+};
+
+sub reload_config {
+    debug_message("Got SIGHUP, reloading config");
+    $cfg = read_config($configfile);
+};
+
+# broken, kills unrelated processes. Not using for now.
+# perlipc(1)
+# also remove them from the to-be-killed list
+#sub reap_children {
+#    my $child;
+#    while (($child = waitpid(-1,WNOHANG)) > 0) {
+#        delete $childPids{$child};
+#    }
+#    $SIG{CHLD} = \&reap_children;  # still loathe sysV
+#
+#}
+#$SIG{CHLD} = \&reap_children;
+$SIG{CHLD} = 'IGNORE';
+$SIG{'TERM'} = \&term_handler;
+$SIG{'HUP'} = \&reload_config;
+
+my $getBufLen=10000;
+my $maxspeed;
+
+my ($chfd, $pkfd);
+
+# for rate limit support
+if($$cfg{limit}>0) {
+    $maxspeed = $$cfg{limit}*1024;
+    $getBufLen = $maxspeed/20; # 20 portions per second should be enough
+}
+
+sub setup_agent {
+
+   return if(defined($ua));
+
+   $ua=LWP::UserAgent->new('keep_alive' => 1);
+
+   # Check whether a proxy is to be used, and set the appropriate environment variable
+   my $proxystring;
+   if ( $$cfg{use_proxy} eq 1 && $$cfg{http_proxy}) {
+       $proxystring="http://";
+       if ( $$cfg{use_proxy_auth} eq 1) {
+           $proxystring.=$$cfg{http_proxy_auth}.'@';
+       }
+       $proxystring.=$$cfg{http_proxy};
+   }
+   $ua->proxy("http", $proxystring) if $proxystring;
+}
+
+
+
+
+
+# BEGINN MAIN PART
+
+if($cgi_mode && defined($$cfg{cgi_advise_to_use}) && $$cfg{cgi_advise_to_use}) {
+    print "Status: 410 $$cfg{cgi_advise_to_use}\r\n\r\n";
+    exit 0;
+}
+
+if($direct_mode) {
+    &setup_ownership;
+    &open_log_files;
+#optional checksumming support
+    db_init("$$cfg{cache_dir}/md5sums.sl3");
+    $client = "INETD" if $inetd_mode;
+
+    # get the string if available even in inetd / direct mode so local calles can
+    # identify themselves in the logs.
+    $client=$ENV{REMOTE_ADDR} if exists $ENV{REMOTE_ADDR};
+
+    &handle_connection;
+    exit 0;
+}
+
+my %daemonopts = (LocalPort => $$cfg{daemon_port}, Proto => 'tcp', Listen => 1, ReuseAddr => 1);
+$daemonopts{LocalAddr}=$$cfg{daemon_addr} if(defined($$cfg{daemon_addr}));
+
+while(1) {
+    $daemon = IO::Socket::INET->new(%daemonopts);
+    last if $daemon;
+    $retnum--;
+    last if($retnum<=0);
+    print STDERR "Unable to bind socket (port $$cfg{daemon_port}), trying again in 5 seconds.\n";
+    sleep 5;
+}
+die "Unable to bind socket (port $$cfg{daemon_port}), $0 not started.\n" if ! $daemon;
+
+$server_pid=$$;
+
+if($do_fork_away) {
+    my $pid = fork();
+    if ($pid < 0) {
+        barf("fork() failed");
+    }
+    if ($pid > 0) {
+        # parent
+        exit 0;
+    }
+}
+
+# STATE: Port open, still beeing root. Create pidfiles, logfiles, then su
+# 
+if($pidfile) {
+    open(my $fh, ">$pidfile");
+    print $fh $$;
+    close($fh);
+}
+
+
+&setup_ownership;
+&open_log_files;
+#optional checksumming support
+db_init("$$cfg{cache_dir}/md5sums.sl3");
+
+# State: READY
+# That is the working condition (daemon mode)
+
+debug_message("Apt-Cacher started with Debug output enabled, accepting connections...");
+
+while (1)
+{
+    my $newcon = $daemon->accept;
+    # we don't stop, only by term_handler since the accept method is unreliable
+    next if(!$newcon);
+    last if $terminating;
+
+    $client = $newcon->peerhost;
+    debug_message("Connection from $client");
+
+    my $pid = fork();
+    if ($pid < 0) {
+        barf("fork() failed");
+    }
+
+    if ($pid > 0) {
+        # parent
+        debug_message("registred child process: $pid");
+        $childPids{$pid}=1;
+        next;
+    }
+    # child
+    undef %childPids;
+
+    &handle_connection($newcon);
+    exit (0);
+
+}
+exit 0;
+# exit from the daemon loop
+
+
+
+sub handle_connection {
+    # now begin connection's personal stuff
+    debug_message("New HTTP connection open");
+    
+    if($direct_mode) {
+        # beeing in forced mode, ie. manual call
+        $source=*STDIN;
+        $con = *STDOUT;
+    }
+    else {
+
+        # serving a network client
+        
+        $con = shift;
+        $source = $con;
+    }
+    
+
+    if(!$inetd_mode) {
+        # ----------------------------------------------------------------------------
+        # Let's do some security checking. We only want to respond to clients within an
+        # authorised address range (127.0.0.1 and ::1 are always allowed).
+
+        my $ip_pass = 1;
+        my $ip_fail = 0;
+        my $clientaddr;
+
+        # allowed_hosts == '*' means allow all ('' means deny all)
+        # denied_hosts == '' means don't explicitly deny any
+        # localhost is always accepted
+        # otherwise host must be in allowed list and not in denied list to be accepted
+
+        if ($client =~ /:/) # IPv6?
+        {
+            defined ($clientaddr = ipv6_normalise ($client)) or goto badaddr;
+            if (substr ($clientaddr, 0, 12) eq "\0\0\0\0\0\0\0\0\0\0\xFF\xFF")
+            {
+                $clientaddr = substr ($clientaddr, 12);
+                goto is_ipv4;
+            }
+            elsif ($clientaddr eq "\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\1")
+            {
+                debug_message("client is localhost");
+            }
+            else
+            {
+                $ip_pass = ($$cfg{allowed_hosts_6} =~ /^\*?$/) ||
+                ipv6_addr_in_list ($clientaddr, 'allowed_hosts_6');
+                $ip_fail = ipv6_addr_in_list ($clientaddr, 'denied_hosts_6');
+            }
+        }
+        elsif (defined ($clientaddr = ipv4_normalise ($client))) # IPv4?
+        {
+            is_ipv4:
+            if ($clientaddr eq "\x7F\0\0\1")
+            {
+                debug_message("client is localhost");
+            }
+            else
+            {
+                $ip_pass = ($$cfg{allowed_hosts} =~ /^\*?$/) ||
+                ipv4_addr_in_list ($clientaddr, 'allowed_hosts');
+                $ip_fail = ipv4_addr_in_list ($clientaddr, 'denied_hosts');
+            }
+        }
+        else
+        {
+            goto badaddr;
+        }
+
+        # Now check if the client address falls within this range
+        if ($ip_pass && !$ip_fail)
+        {
+            # Everything's cool, client is in allowed range
+            debug_message("Client $client passed access control rules");
+        }
+#        elsif($client eq "local")
+#        {
+#            # Everything's cool, client is in allowed range
+#            debug_message("Client $client passed access control rules");
+#        }
+        else
+        {
+            # Bzzzt, client is outside allowed range. Send 'em a 403 and bail.
+            badaddr:
+            debug_message("Alert: client $client disallowed by access control");
+
+            &sendrsp(403, "Access to cache prohibited");
+            exit(4);
+        }
+
+    }
+
+    REQUEST:
+    while(!$concloseflag) {
+
+        my $testpath; # temporary, to be set by GET lines, undef on GO
+        my $ifmosince;# to be undef by new GET lines
+        my $send_head_only=0; # to be undef by new GET lines
+        my $tolerated_empty_lines=20;
+        my $rangereq;
+
+        # reading input line by line, trough the secure input method
+        CLIENTLINE: while(1) {
+
+            debug_message("Processing a new request line");
+
+            $_=&getRequestLine;
+            debug_message("got: $_");
+
+            exit if !defined($_);
+
+            if(/^$/) {
+                if(defined($testpath)) {
+                    # done reading request
+                    $path=$testpath;
+                    last CLIENTLINE;
+                }
+                elsif(!$tolerated_empty_lines)   {
+                    &sendrsp(403, "Go away");
+                    exit(4);
+                }
+                else {
+                    $tolerated_empty_lines--;
+                }
+            }
+            else {
+                if(/^(GET|HEAD)\s+(\S+)/) {
+                    if(defined($testpath)) {
+                        &sendrsp(403, "Confusing request");
+                        exit(4);
+                    }
+                    $testpath=$2;
+                    # also support pure HEAD calls
+                    if($1 eq 'HEAD') {
+                        $send_head_only=1;
+                    }
+                }
+                elsif(/^Connection: close/i) {
+                    $concloseflag=1;
+                }
+                elsif(/^Connection: .*TE/) {
+                    $concloseflag=1;
+                }
+                elsif(/^Range/i) {
+                    $rangereq=1;
+                }
+                elsif(/^If-Modified-Since:\s+(.*)/i) {
+                    $ifmosince=$1;
+                }
+                elsif(/^\S+: [^:]*/) {
+                    # whatever, but valid
+                }
+                else {
+                    &sendrsp(403, "Could not understand $_");
+                    exit(4);
+                }
+            }
+        }
+
+        # always resend the file if a part was requested since we don't support ranges
+        $ifmosince=0 if !$rangereq;
+
+        # tolerate CGI specific junk and two slashes in the beginning
+        $path =~ s!^/apt-cacher\??/!/!;
+        $path =~ s!^//!/!;
+        $path =~ s!^http://!!; # allow proxy style
+
+        # Now parse the path
+        if ($path =~ /^\/?report/) {
+            usage_report();
+            exit(0);
+        }
+
+        if ($path !~ m(^/?.+/.+)) {
+            usage_error();
+        }
+
+        REPARSE:
+        
+        my($host,$uri) = ($path =~ m#^/?([^/]+)(/.+)#);
+        
+        if ( !$host || !$uri ) {
+            usage_error();
+        }
+
+        ($filename) = ($uri =~ /\/?([^\/]+)$/);
+
+        if($$cfg{allowed_locations}) {
+            #         debug_message("Doing location check for ".$$cfg{allowed_locations} );
+            my $mess;
+            my $cleanuri=$uri;
+            $cleanuri=~s!/[^/]+/[\.]{2}/!/!g;
+            if ($host eq ".." ) {
+                $mess = "'..' contained in the hostname";
+            }
+            elsif ($cleanuri =~/\/\.\./) {
+                $mess = "File outside of the allowed path";
+            }
+            else {
+                for( split(/\s*,\s*/,$$cfg{allowed_locations}) ) {
+                    debug_message("Testing URI: $host$cleanuri on $_");
+                    goto location_allowed if ("$host$cleanuri" =~ /^$_/);
+                }
+                $mess = "Host '$host' is not configured in the allowed_locations directive";
+            }
+            badguy:
+            debug_message("$mess; access denied");
+            &sendrsp(403, "Access to cache prohibited, $mess");
+            exit(4);
+        }
+        location_allowed:
+
+        $do_import=0;
+        $is_index_file=0;
+
+        if ($filename =~ /(\.deb|\.rpm|\.dsc|\.tar\.gz|\.diff\.gz|\.udeb)$/) {
+            # We must be fetching a .deb or a .rpm, so let's cache it.
+            # Place the file in the cache with just its basename
+            $new_filename = $filename;
+            debug_message("new filename with just basename: $new_filename");
+        } 
+        elsif ($filename =~ /2\d\d\d-\d\d-\d\d.*\.gz$/) {
+            # a patch file. Needs a unique filename but no freshness checks
+            $new_filename = "$host$uri";
+            $new_filename =~ s/\//_/g;
+            debug_message("new long filename: $new_filename");
+        }
+        elsif ($filename =~ /$index_files_regexp/) {
+            $is_index_file=1;
+            # It's a Packages.gz or related file: make a long filename so we can cache these files without
+            # the names colliding
+            $new_filename = "$host$uri";
+            $new_filename =~ s/\//_/g;
+            debug_message("new long filename: $new_filename");
+            # optional checksumming support
+            if ($filename =~ /(Packages|Sources)/) {
+                # warning, an attacker could poison the checksum cache easily
+                $do_import=1;
+            }
+        } else {
+            # Maybe someone's trying to use us as a general purpose proxy / relay.
+            # Let's stomp on that now.
+            debug_message("Sorry, not allowed to fetch that type of file: $filename");
+            &sendrsp(403, "Sorry, not allowed to fetch that type of file: $filename");
+            exit(4);
+        }
+
+        $cached_file = "$$cfg{cache_dir}/packages/$new_filename";
+        $cached_head = "$$cfg{cache_dir}/headers/$new_filename";
+        $complete_file = "$private_dir/$new_filename.complete";
+        $notify_file = "$private_dir/$new_filename.notify";
+
+        my $force_download=0;
+
+        my $cache_status;
+
+        debug_message("looking for $cached_file");
+
+        if ($is_index_file) {
+            debug_message("known as index file: $filename");
+            # in offline mode, deliver it as-is, otherwise check freshness
+            if (-f $cached_file && -f $cached_head && !$$cfg{offline_mode}) {
+                if($$cfg{expire_hours} > 0) {
+                    my $now = time();
+                    my @stat = stat($cached_file);
+                    if (@stat && int(($now - $stat[9])/3600) > $$cfg{expire_hours}) {
+                        debug_message("unlinking $new_filename because it is too old");
+                        # Set the status to EXPIRED so the log file can show it was downloaded again
+                        $cache_status = "EXPIRED";
+                        debug_message("$cache_status");
+                        $force_download=1;
+                    }
+                }
+                else {
+                    # use HTTP timestamping
+                    my ($oldhead, $testfile, $newhead);
+                    my $response = &ua_act(1, $host, $uri);
+                    #my $response = $ua->head("http://$host$uri");
+                    $newhead = $response->header("Last-Modified");
+                    if($newhead && open($testfile, $cached_head)) {
+                        
+                        $newhead =~ s/\n|\r//g;
+
+                        for(<$testfile>){
+                            if(/^.*Last-Modified:\s(.*)(\r|\n)/) {
+                                $oldhead = $1;
+                                last
+                            }
+                        }
+                        close($testfile);
+                    }
+                    if($oldhead && ($oldhead eq $newhead) ) {
+                        # that's ok
+                        debug_message("remote file not changed, $oldhead vs. $newhead");
+                    }
+                    else {
+                        debug_message("unlinking $new_filename because it differs from server's version");
+                        $cache_status = "EXPIRED";
+                        debug_message("$cache_status");
+                        $force_download=1;
+                    }
+                }
+            }
+        }
+
+        # handle if-modified-since in a better way (check the equality of
+        # the time stamps). Do only if download not forced above.
+
+        if($ifmosince && !$force_download) {
+            $ifmosince=~s/\n|\r//g;
+
+            my $oldhead;
+            if(open(my $testfile, $cached_head)) {
+                LINE: for(<$testfile>){
+                    if(/^.*Last-Modified:\s(.*)(\r|\n)/) {
+                        $oldhead = $1;
+                        last LINE;
+                    }
+                }
+                close($testfile);
+            }
+
+            if($oldhead && $ifmosince eq $oldhead) {
+                &sendrsp(304, "Not Modified");
+                debug_message("File not changed: $ifmosince");
+                next REQUEST;
+            }
+        }
+
+        &set_global_lock(": file download decission"); # file state decissions, lock that area
+
+        my $fromfile; # handle for the reader
+
+        # download or not decission. Also releases the global lock
+        dl_check:
+        if( !$force_download && -e $cached_head && -e $cached_file) {
+            if (-f $complete_file) {
+                # not much to do if complete
+                $cache_status = "HIT";
+                debug_message("$cache_status");
+            }
+            else {
+                # a fetcher was either not successfull or is still running
+                # look for activity...
+                sysopen($fromfile, $cached_file, O_RDONLY) || undef $fromfile;
+                if (flock($fromfile, LOCK_EX|LOCK_NB)) {
+                    flock($fromfile, LOCK_UN);
+                    # bad, no fetcher working on this package. Redownload it.
+                    close($fromfile); undef $fromfile;
+                    debug_message("no fetcher running, forcing download");
+                    $force_download=1;
+                    goto dl_check;
+                }
+            }
+
+            &release_global_lock;
+        }
+        else {
+            # bypass for offline mode, no forking, just report the "problem"
+            if($$cfg{offline_mode})
+            {
+                &sendrsp(503, "Apt-Cacher in Offline Mode");
+                next REQUEST;
+            }
+
+            # (re) download them
+            unlink($cached_file, $cached_head, $complete_file, $notify_file);
+            debug_message("file does not exist or so, creating it");
+            # Set the status to MISS so the log file can show it had to be downloaded
+            if(!defined($cache_status)) { # except on special presets from index file checks above
+                $cache_status = "MISS"; 
+                debug_message("$cache_status");
+            }
+
+            # the writer releases the global lock after opening the target file
+            my $pid = fork();
+            if ($pid < 0) {
+                barf("fork() failed");
+            }
+            if ($pid == 0) {
+                # child, the fetcher thread
+                undef %childPids;
+                sysopen($pkfd, $cached_file, O_RDWR|O_CREAT|O_EXCL, 0644) || barf("Unable to store files");
+                open ( $chfd, ">$cached_head");
+
+                if (flock($pkfd, LOCK_EX)) {
+                    # jump from the global lock to a lock on the target file
+                    &release_global_lock;
+
+                    &fetch_store ($host, $uri); 
+
+                    exit 0;
+                }
+                else {
+                    barf("Problem locking the target file!");
+                }
+                # child exiting above, so or so
+            }
+            # parent continues
+            $childPids{$pid}=1;
+            debug_message("registred child process: $pid");
+            # &release_global_lock; to be release by downloader thread, not here
+        }
+
+        debug_message("checks done, can return now");
+        my $ret = &return_file (\$fromfile, $send_head_only);
+        goto dl_check if $ret==2; # retry code
+        debug_message("Package sent");
+
+        # Write all the stuff to the log file
+        writeaccesslog("$cache_status", "$new_filename");
+        if(!$is_index_file && !check_sum($new_filename)) {
+            writeerrorlog("   ALARM!    Faulty package in local cache detected! Removing, to be replaced with the next download.");
+            unlink $cached_file;
+            exit(5);
+        }
+        
+    }
+
+}
+
+
+sub return_file {
+    # At this point the file is open, and it's either complete or somebody
+    # is fetching its contents
+
+    our ($ffref, $send_head_only) =@_;
+    my $fromfile=$$ffref;
+
+    my $header_printed=0;
+
+    data_init();
+    
+    my $abort_time = get_abort_time();
+
+    my $buf;
+
+    my $geslen=0;
+    my $curlen=0;
+    my $explen;
+
+    my $complete_found;
+
+    # needs to print the header first
+    CHUNK: while (1) {
+
+        #debug_message("Send loop iteration:");
+
+        if (time() > $abort_time) {
+            debug_message("abort (timeout)");
+            exit(4);
+        }
+
+        if(! $header_printed) {
+
+            # add this reader to the notification list before printing anything useful to the client
+            if(! -f $complete_file) { # there is no point if the package is already downloaded
+                open(my $nf, ">>$notify_file");
+                flock($nf, LOCK_EX);
+                print $nf "$$\n";
+                flock($nf, LOCK_UN);
+                close($nf);
+            }
+
+            my $headstring;
+            if(-s $cached_head) {
+                # header file seen, protect the reading 
+                &set_global_lock(": reading the header file");
+                if(! -f $cached_head) {
+                    # file removed while waiting for lock - download failure?!
+                    # start over, maybe spawning an own fetcher
+                    &release_global_lock;
+                    return 2;
+                    #goto dl_check;
+                }
+
+                open(my $in, $cached_head);
+                my $code=200;
+                my $msg='';
+                my $headstring='';
+
+                $headstring=<$in>; # read exactly one status line
+
+                ($code, $msg) = ($headstring=~/^HTTP\S+\s+(\d+)\s(.*)/);
+                # alternative for critical errors
+                if(!defined($code)) {
+                    ($code, $msg) = ($headstring=~/^(5\d\d)\s(.*)/);
+                }
+
+                if(!defined($code)) {
+                    writeerrorlog("Faulty header file detected: $cached_head, first line was: $headstring");
+                    unlink $cached_head;
+                    exit 3;
+                }
+
+                # in CGI mode, use alternative status line. Don't print one
+                # for normal data output (apache does not like that) but on
+                # anormal codes, and then exit immediately
+                if($cgi_mode) {
+                    # don't print the head line but a Status on errors instead
+                    $headstring=~s/^HTTP\S+/Status:/;
+                    if($code == 200) {
+                        $headstring=''; # kick headline by default
+                    }
+                    else {
+                        print $con $headstring."\n\n";
+                        exit 1;
+                    }
+                }
+
+                # keep alive or not? Just follow the client
+                $headstring .= "Connection: ".($concloseflag?"Close":"Keep-Alive")."\r\n";
+
+                # keep only parts interesting for apt
+                if($code==200) {
+                    for(<$in>) {
+                        if(/^Last-Modified|Content|Accept/) {
+                            $headstring.=$_;
+                            if(/^Content-Length:\ *(\d+)/) {
+                                $explen=$1;
+                            }
+                        }
+                    }
+                }
+                close($in);
+                &release_global_lock;
+
+                print $con $headstring."\r\n";
+
+                $header_printed=1;
+                debug_message("Header sent: $headstring");
+
+                # Stop after sending the header with errors
+                return if($code != 200); 
+
+            }
+            else {
+                sleep(0.5);
+                next CHUNK;
+            }
+
+            # pure HEAD request, we are done
+            return if $send_head_only;
+            debug_message("ready to send contents of $cached_file");
+        }
+
+        if(! $fromfile) # is the data file open already? open in this iteration if needed
+        {
+            debug_message("opening file first: $cached_file");
+            if( ! -f $cached_file) {
+                sleep(1);
+                next CHUNK;
+            }
+
+            sysopen($fromfile, $cached_file, O_RDONLY); #FIXME, checken
+            next CHUNK;
+        }
+        else
+        {
+            my $n=0;
+            $n = sysread($fromfile, $buf, 65536);
+            debug_message("read $n bytes");
+
+            if(!defined($n)) {
+                debug_message("Error detected, closing connection");
+                exit(4);
+            }
+            
+            if($n==0) {
+                
+                if($complete_found) { # comlete file was found in the previous iteration
+                    # this is the loop exit condition
+                    # 
+                    # some extra error cases
+                    #if($explen && $curlen != $explen) {
+                    #    writeerrorlog("  ALARM!   $cached_file file is smaller than expected ($explen). Renaming to $cached_file.corrupted for further investigation, check your filesystem!");
+                    #    unlink "$cached_file.corrupted";
+                    #    rename($cached_file, "$cached_file.corrupted");
+                    #    exit(5);
+                    #}
+                    last CHUNK;
+                }
+
+                if (-f $complete_file) {
+                    # do another iteration, may need to read remaining data
+                    debug_message("complete file found");
+                    $complete_found=1;
+                    next CHUNK;
+                }
+
+                #debug_message("waiting for new data");
+                # wait for fresh data
+                sleep(0.5);
+                next CHUNK;
+
+            }
+            else {
+                $curlen+=$n;
+                if($explen && $curlen > $explen) {
+                    writeerrorlog("  ALARM!   $cached_file file is larger than expected ($explen). Renaming to $cached_file.corrupted for further investigation, check your filesystem!");
+                    unlink "$cached_file.corrupted";
+                    rename($cached_file, "$cached_file.corrupted");
+                    exit(5);
+                }
+                #debug_message("write $n / $curlen bytes");
+                # send data and update watchdog
+                print $con $buf;
+                debug_message("wrote $n (sum: $curlen) bytes");
+                $abort_time = get_abort_time();
+                data_feed(\$buf);
+            }
+        }
+    }
+}
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+sub barf {
+	my $errs = shift;
+
+	die "--- $0: Fatal: $errs\n";
+}
+
+sub usage_error {
+    &open_log_files;
+	writeerrorlog("--- $0: Usage error");
+
+    if(! defined($$cfg{example_sources_line})) {
+        $$cfg{example_sources_line}="deb&nbsp;http://<b>yourcache.example.com:$$cfg{daemon_port}/</b>ftp.au.debian.org/debian&nbsp;unstable&nbsp;main&nbsp;contrib&nbsp;non-free";
+    }
+
+    &sendrsp(200, "OK", "Content-Type", "text/html", "Expires", 0);
+	print $con <<EOF;
+
+<html>
+<title>Apt-cacher version $version
+</title><style type="text/css"><!--
+a { text-decoration: none; }
+a:hover { text-decoration: underline; }
+h1 { font-family: arial, helvetica, sans-serif; font-size: 18pt; font-weight: bold;}
+h2 { font-family: arial, helvetica, sans-serif; font-size: 14pt; font-weight: bold;}
+body, td { font-family: arial, helvetica, sans-serif; font-size: 10pt; }
+th { font-family: arial, helvetica, sans-serif; font-size: 11pt; font-weight: bold; }
+//--></style>
+</head>
+<body>
+<p>
+<table border=0 cellpadding=8 cellspacing=1 bgcolor="#000000" align="center" width="600">
+<tr bgcolor="#9999cc"><td> <h1>Apt-cacher version $version</h1> </td></tr>
+<tr bgcolor="#cccccc"><td>
+Usage: edit your /etc/apt/sources.list so all your HTTP sources are prepended 
+with the address of your apt-cacher machine and the port, like this:
+<blockquote>deb&nbsp;http://ftp.au.debian.org/debian&nbsp;unstable&nbsp;main&nbsp;contrib&nbsp;non-free</blockquote>
+becomes
+<blockquote>$$cfg{example_sources_line}</blockquote>
+</td></tr>
+</table>
+
+<h2 align="center">config values</h2>
+<table border=0 cellpadding=3 cellspacing=1 bgcolor="#000000" align="center">
+<tr bgcolor="#9999cc"><th> Directive </th><th> Value </th></tr>
+<tr bgcolor="#cccccc"><td bgcolor="#ccccff"> configfile </td><td> $configfile </td></tr>
+<tr bgcolor="#cccccc"><td bgcolor="#ccccff"> admin_email </td><td> <a href="mailto:$$cfg{admin_email}">$$cfg{admin_email}</a> </td></tr>
+<tr bgcolor="#cccccc"><td bgcolor="#ccccff"> generate_reports </td><td> $$cfg{generate_reports} </td></tr>
+<tr bgcolor="#cccccc"><td bgcolor="#ccccff"> cache_dir </td><td> $$cfg{cache_dir} </td></tr>
+<tr bgcolor="#cccccc"><td bgcolor="#ccccff"> logfile </td><td> $$cfg{logfile} </td></tr>
+<tr bgcolor="#cccccc"><td bgcolor="#ccccff"> errorfile </td><td> $$cfg{errorfile} </td></tr>
+<tr bgcolor="#cccccc"><td bgcolor="#ccccff"> expire_hours </td><td> $$cfg{expire_hours} </td></tr>
+<tr bgcolor="#cccccc"><td bgcolor="#ccccff"> http_proxy </td><td> $$cfg{http_proxy} </td></tr>
+<tr bgcolor="#cccccc"><td bgcolor="#ccccff"> use_proxy </td><td> $$cfg{use_proxy} </td></tr>
+<tr bgcolor="#cccccc"><td bgcolor="#ccccff"> use_proxy_auth </td><td> $$cfg{use_proxy_auth} </td></tr>
+<tr bgcolor="#cccccc"><td bgcolor="#ccccff"> debug </td><td> $$cfg{debug} </td></tr>
+</table>
+
+<p>
+<h2 align="center">license</h2>
+<table border=0 cellpadding=8 cellspacing=1 bgcolor="#000000" align="center" width="600">
+<tr bgcolor="#cccccc"><td>
+<p>Apt-cacher is free software; you can redistribute it and/or modify it under the terms of the GNU General 
+Public License as published by the Free Software Foundation; either version 2 of the License, or (at your 
+option) any later version.
+
+<p>Apt-cacher is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the 
+implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public 
+License for more details.
+
+<p>A copy of the GNU General Public License is available as /usr/share/common-licenses/GPL in the Debian 
+GNU/Linux distribution or on the World Wide Web at http://www.gnu.org/copyleft/gpl.html. You can also 
+obtain it by writing to the Free Software Foundation, Inc., 59 Temple Place - Suite 330, Boston, MA 
+02111-1307, USA.
+</td></tr>
+</table>
+</body>
+</html>
+EOF
+
+    exit 1;
+
+}
+
+
+# Jon's extra stuff to write the event to a log file.
+sub writeaccesslog {
+    my $cache_status = shift;
+    my $new_filename = shift;
+
+    # The format is 'time|cache status (HIT, MISS or EXPIRED)|client IP address|file size|name of requested file'
+    my $time = localtime;
+    my ($dev,$ino,$mode,$nlink,$uid,$gid,$rdev,$size,$atime,$mtime,$ctime,$blksize,$blocks) = stat($cached_file);
+    my $file_length = 0;
+    $file_length+=$size if defined($size);
+
+    flock($aclog_fh, LOCK_EX);
+    print $aclog_fh "$time|$client|$cache_status|$file_length|$new_filename\n";
+    flock($aclog_fh, LOCK_UN);
+}
+
+# Jon's extra stuff to write errors to a log file.
+sub writeerrorlog {
+	my $message = shift;
+	
+	my $time = localtime;
+
+    flock($erlog_fh, LOCK_EX);
+    # files may need to be reopened sometimes - reason unknown yet, EBADF
+    # results
+	syswrite($erlog_fh,"$time|$client|$message\n") || &open_log_files;
+    flock($erlog_fh, LOCK_UN);
+}
+
+# Stuff to append debug messages to the error log.
+sub debug_message {
+    if ($$cfg{debug} eq 1) {
+        my $message = shift;
+        &writeerrorlog("debug [$$]: $message");
+    }
+}
+
+sub open_log_files {
+	if(!$erlog_fh)
+    {
+        open($erlog_fh,">>$$cfg{errorfile}") or barf("Unable to open $$cfg{errorfile}");
+    }
+    if(!$aclog_fh) {
+        open($aclog_fh,">>$$cfg{logfile}") or barf("Unable to open $$cfg{logfile}");
+    }
+}
+ 
+sub get_abort_time () {
+  return time () + $$cfg{fetch_timeout}; # five minutes from now
+}
+
+my $header_stored=0;
+
+my $tstart;
+my $geslen;
+
+sub get_callback {
+    my $errors=0;
+
+    my ($data, $response, $proto) = @_;
+#    debug_message("Callback got data\n");
+    if(!$header_stored) {
+        $header_stored=1;
+        my $headstring = $response->as_string;
+
+        # print $con $headstring;
+        
+        &set_global_lock(": Callback, storing the header"); # set the lock before writting the first byte to that file, and release it after the file is closed
+        (scalar print $chfd $headstring ) || $errors++;
+        close($chfd);
+        &release_global_lock;
+
+        if($maxspeed) {
+            $geslen=-$getBufLen; # will be re-added below
+            $tstart = [gettimeofday];
+        }
+
+    }
+    (scalar print $pkfd $data ) || $errors++;
+    #print $con $data;
+
+    data_feed(\$data);
+
+    # delay for rate limiting
+    if($maxspeed) {
+        $geslen+=$getBufLen;
+        my $delta= $geslen/$maxspeed - ( scalar tv_interval ( $tstart ));
+        sleep($delta) if ($delta > 0);
+    }
+
+    if($errors) {
+        writeerrorlog("Write error. Disk full?");
+        # don't just exit here, fetcher needs to handle that
+        die();
+    }
+}
+
+sub fetch_store {
+
+    my ($host, $uri) = @_;
+
+    my $url = "http://$host$uri";
+    debug_message("fetcher: try to fetch $url");
+
+    # for checksumming
+    data_init();
+
+    my $response = &ua_act(0, $host, $uri);
+    #my $response = $ua->get($url, ':content_cb' => \&get_callback, ':read_size_hint' => $getBufLen);
+    #$geslen=0;
+
+    debug_message("Get is back");
+
+    if ($response->is_success && !defined($response->header("X-Died")) )
+    {
+
+        close($pkfd) if $pkfd;
+        undef $pkfd;
+
+        debug_message("stored $url as $cached_file");
+
+        # check missmatch or fetcher failure, could not connect the server
+        if( !$is_index_file && !check_sum($new_filename)) {
+            &set_global_lock(": file corruption report");
+            writeerrorlog("Do00h, checksum mismatch on $new_filename");
+            unlink $cached_file, $cached_head;
+            open(MF, ">$cached_head");
+            print MF "HTTP/1.1 502 Data corruption";
+            close(MF);
+            &kill_readers;
+            &release_global_lock;
+        }
+
+        # assuming here that the filesystem really closes the file and writes
+        # it out to disk before creating the complete flag file
+        
+        debug_message("setting complete flag for $new_filename");
+        # Now create the file to show the pickup is complete, also store the original URL there
+        open(MF, ">$private_dir/$new_filename.complete");
+        print MF $path;
+        close(MF); 
+
+        # index file seen? Get checksums
+        import_sums($cached_file) if $do_import;
+        
+        # store the sum, it may be not available yet but better this one than
+        # nothing. 
+        # disabled for now store_sum($new_filename);
+        # The sum may change on index files but that case is handled
+        # separately, the stored sum is allowed to differ from the data
+        # contents.
+
+    }
+    else
+    {
+        if(defined($response->header("X-Died"))) {
+            $response->code(502);
+            $response->message("Apt-Cacher: Transfer terminated");
+        }
+
+        debug_message("Reporting error: ".$response->code);
+        &set_global_lock(": HTTP error report");
+        open(my $ch, $cached_head);
+        my $headstring = $response->as_string;
+        if($headstring=~/^5\d\d/) { 
+            # work around LWP bug, incorrect status line with internal messages
+            $headstring = "HTTP/1.1 $headstring";
+        }
+        print $chfd $headstring;
+        close($chfd);
+        &release_global_lock;
+        if(defined($response->header("X-Died"))) { # was critical, most likely frozen now
+            &kill_readers;
+        }
+    }
+
+    debug_message("fetcher exiting");
+    unlink $notify_file;
+
+    # reset the shared vars
+    $header_stored=0; # FIXME, really needed? fetcher thread runs only once
+
+    _exit(0);
+}
+
+# FIXME: that sucks. Still needed?!
+sub kill_readers {
+    my $nf;
+    if(open($nf, $notify_file)) {
+        while(<$nf>) {
+            chomp;
+        debug_message("Stopping reader: $_");
+               kill 9, $_; # hard, bypassing the handler
+        }
+        close($nf);
+    }
+    # should be okay to unlink the file after all readers are "notified"
+    unlink $cached_file;
+}
+
+
+# Check if there has been a usage report generated and display it
+sub usage_report {
+	my $usage_file = "$$cfg{logdir}/report.html";
+    &sendrsp(200, "OK", "Content-Type", "text/html", "Expires", 0);
+	if (!-f $usage_file) {
+		print $con <<EOF;
+
+<html>
+<title>Apt-cacher traffic report</title><style type="text/css"><!--
+a { text-decoration: none; }
+a:hover { text-decoration: underline; }
+h1 { font-family: arial, helvetica, sans-serif; font-size: 18pt; font-weight: bold;}
+h2 { font-family: arial, helvetica, sans-serif; font-size: 14pt; font-weight: bold;}
+body, td { font-family: arial, helvetica, sans-serif; font-size: 10pt; }
+th { font-family: arial, helvetica, sans-serif; font-size: 11pt; font-weight: bold; }
+//--></style>
+</head>
+<body>
+<table border=0 cellpadding=8 cellspacing=1 bgcolor="#000000" align="center" width="600">
+<tr bgcolor="#9999cc"><td> <h1>Apt-cacher traffic report</h1> </td></tr>
+</td></tr>
+</table>
+		
+<p><table border=0 cellpadding=3 cellspacing=1 bgcolor="#000000" align="center" width="600">
+<tr bgcolor="#9999cc"><th bgcolor="#9999cc"> An Apt-cacher usage report has not yet been generated </th></tr>
+<tr bgcolor="#cccccc"><td bgcolor="#ccccff"> Reports are generated every 24 hours. If you want reports to be generated, make sure you set '<b>generate_reports=1</b>' in <b>$configfile</b>.</td></tr>
+</table>
+		</body>
+		</html>
+EOF
+
+	}
+	else
+	{
+        open(my $usefile, $usage_file);
+        my @usedata = <$usefile>;
+        close($usefile);
+        print $con @usedata;
+	}
+}
+
+# IP address filtering.
+sub ipv4_addr_in_list ($$)
+{
+	return 0 if $_[0] eq '';
+	debug_message ("testing $_[1]");
+	return 0 unless $$cfg{$_[1]};
+
+	my ($client, $cfitem) = @_;
+	my @allowed_hosts = split(/,\s*/, $$cfg{$cfitem});
+	for my $ahp (@allowed_hosts)
+	{
+		goto unknown if $ahp !~ /^[-\/,.[:digit:]]+$/;
+
+		# single host
+		if ($ahp =~ /^([^-\/]*)$/)
+		{
+			my $ip = $1;
+			debug_message("checking against $ip");
+			defined ($ip = ipv4_normalise($ip)) or goto unknown;
+			return 1 if $ip eq $client;
+		}
+		# range of hosts (netmask)
+		elsif ($ahp =~ /^([^-\/]*)\/([^-\/]*)$/)
+		{
+			my ($base, $mask) = ($1, $2);
+			debug_message("checking against $ahp");
+			defined ($base = ipv4_normalise($base)) or goto unknown;
+			$mask = ($mask =~ /^\d+$/) ? make_mask ($mask, 32)
+																 : ipv4_normalise ($mask);
+			goto unknown unless defined $mask;
+			return 1 if ($client & $mask) eq ($base & $mask);
+		}
+		# range of hosts (start & end)
+		elsif ($ahp =~ /^([^-\/]*)-([^-\/]*)$/)
+		{
+			my ($start, $end) = ($1, $2);
+			debug_message("checking against $start to $end");
+			defined ($start = ipv4_normalise($start)) or goto unknown;
+			defined ($end = ipv4_normalise($end)) or goto unknown;
+			return 1 if $client ge $start && $client le $end;
+		}
+		# unknown
+		else
+		{
+			unknown:
+			debug_message("Alert: $cfitem ($ahp) is bad");
+			&sendrsp(500, "Configuration error");
+			exit(4);
+		}
+	}
+	return 0; # failed
+}
+
+sub ipv6_addr_in_list ($$)
+{
+	return 0 if $_[0] eq '';
+	debug_message ("testing $_[1]");
+	return 0 unless $$cfg{$_[1]};
+
+	my ($client, $cfitem) = @_;
+	my @allowed_hosts = split(/,\s*/, $$cfg{$cfitem});
+	for my $ahp (@allowed_hosts)
+	{
+		goto unknown if $ahp !~ /^[-\/,:[:xdigit:]]+$/;
+
+		# single host
+		if ($ahp =~ /^([^-\/]*)$/)
+		{
+			my $ip = $1;
+			debug_message("checking against $ip");
+			$ip = ipv6_normalise($ip);
+			goto unknown if $ip eq '';
+			return 1 if $ip eq $client;
+		}
+		# range of hosts (netmask)
+		elsif ($ahp =~ /^([^-\/]*)\/([^-\/]*)$/)
+		{
+			my ($base, $mask) = ($1, $2);
+			debug_message("checking against $ahp");
+			$base = ipv6_normalise($base);
+			goto unknown if $base eq '';
+			goto unknown if $mask !~ /^\d+$/ || $mask < 0 || $mask > 128;
+			my $m = ("\xFF" x ($mask / 8));
+			$m .= chr ((-1 << (8 - $mask % 8)) & 255) if $mask % 8;
+			$mask = $m . ("\0" x (16 - length ($m)));
+			return 1 if ($client & $mask) eq ($base & $mask);
+		}
+		# range of hosts (start & end)
+		elsif ($ahp =~ /^([^-\/]*)-([^-\/]*)$/)
+		{
+			my ($start, $end) = ($1, $2);
+			debug_message("checking against $start to $end");
+			$start = ipv6_normalise($start);
+			$end = ipv6_normalise($end);
+			goto unknown if $start eq '' || $end eq '';
+			return 1 if $client ge $start && $client le $end;
+		}
+		# unknown
+		else
+		{
+			unknown:
+			debug_message("Alert: $cfitem ($ahp) is bad");
+            &sendrsp(500, "Configuration error");
+			exit(4);
+		}
+	}
+	return 0; # failed
+}
+
+sub sendrsp {
+    my $code=shift;
+    my $msg=shift;
+    $msg="" if !defined($msg);
+    
+    my $initmsg=
+    $cgi_mode ? 
+    "Status: $code $msg\r\n" :
+    "HTTP/1.1 $code $msg\r\n";
+    
+    $initmsg.="Connection: Keep-Alive\r\nAccept-Ranges: bytes\r\nKeep-Alive: timeout=15, max=100\r\n" if ($code ne 403);
+
+    #debug_message("Sending Response: $initmsg");
+    print $con $initmsg;
+
+    my $altbit=0;
+    for(@_) {
+        $altbit=!$altbit;
+        if($altbit) {
+            #debug_message("$_: ");
+            print $con $_.": ";
+        }
+        else {
+            #debug_message($_."\r\n);
+            print $con $_."\r\n";
+        }
+    }
+    print $con "\r\n";
+
+}
+
+# DOS attack safe input reader
+my @reqLineBuf;
+my $reqTail;
+sub getRequestLine {
+    if($cgi_path) { 
+        push(@reqLineBuf, "GET $cgi_path", "", undef); # undef stops operation
+        undef $cgi_path; # don't re-add it
+    }
+    if(! @reqLineBuf) {
+        my $buf="";
+
+        # after every read at least one line MUST have been found. Read length
+        # is large enough.
+
+        my $n=sysread($source, $buf, 1024);
+        $buf=$reqTail.$buf if(defined($reqTail));
+        undef $reqTail;
+
+        # pushes the lines found into the buffer. The last one may be incomplete,
+        # extra handling below
+        push(@reqLineBuf, split(/\r\n/, $buf, 1000) );
+
+        # buf did not end in a line terminator so the last line is an incomplete
+        # chunk. Does also work if \r and \n are separated
+        if(substr($buf, -2) ne "\r\n") {
+            $reqTail=pop(@reqLineBuf);
+        }
+    }
+    return shift(@reqLineBuf);
+}
+
+# runs the get or head operations on the user agent
+sub ua_act {
+    my ($only_head, $vhost, $uri) = @_;
+
+    my $url="http://$vhost$uri";
+    
+    &setup_agent;
+
+    my $do_hopping = (exists $pathmap{$vhost});
+
+    my $response;
+    my $hostcand;
+
+    RETRY_ACTION:
+
+    # make the virtual hosts real. The list is reduced which is not so smart,
+    # but since the fetcher process dies anyway it does not matter.
+    if($do_hopping) {
+        $hostcand = shift(@{$pathmap{$vhost}});
+        debug_message("Candidate: $hostcand");
+        $url=($hostcand =~ /^http:/?"" : "http://").$hostcand.$uri;
+        #$url="http://$hostcand$uri";
+        #$url="$hostcand$uri" if not $hostcand =~ /:\/\//;
+    }
+
+    debug_message("download agent: getting $url");
+    
+    if($only_head) {
+        $response = $ua->head($url);
+    }
+    else {
+        $response = $ua->get($url, ':content_cb' => \&get_callback, ':read_size_hint' => $getBufLen);
+    }
+
+    if($do_hopping) {
+        # if okay or the last candidate failes, put it back into the list
+        if($response->is_success || ! @{$pathmap{$vhost}} ) { 
+            unshift(@{$pathmap{$vhost}}, $hostcand);
+        }
+        else {
+            goto RETRY_ACTION;
+        }
+    }
+
+    return $response;
+}
+
+
+sub setup_ownership {
+    my $uid=$$cfg{user};
+    my $gid=$$cfg{group};
+
+    if($chroot) {
+        if($uid || $gid) {
+            # open them now, before it is too late
+            # FIXME: reopening won't work, but the lose of file handles needs to be
+            # made reproducible first
+            &open_log_files;
+        }
+        chroot $chroot || die "Unable to chroot, aborting.\n";
+        chdir $chroot;
+    }
+
+    if($gid) {
+        if($gid=~/^\d+$/) {
+            my $name=getgrgid($gid);
+            die "Unknown group ID: $gid (exiting)\n" if !$name;
+        }
+        else {
+            $gid=getgrnam($gid);
+            die "No such group (exiting)\n" if !defined($gid);
+        }
+        $) = $gid;
+        $( = $gid;
+        $) =~ /^$gid\b/ && $( =~ /^$gid\b/ || barf("Unable to change group id");
+    }
+
+    if($uid) {
+        if($uid=~/^\d+$/) {
+            my $name=getpwuid($uid);
+            die "Unknown user ID: $uid (exiting)\n" if !$name;
+        }
+        else {
+            $uid=getpwnam($uid);
+            die "No such user (exiting)\n" if !defined($uid);
+        }
+        $> = $uid;
+        $< = $uid;
+        $> == $uid && $< == $uid || barf("Unable to change user id");
+    }
+}
diff -r cc18a0104636 binary-overlay.xenrt/usr/share/apt-cacher/apt-cacher-cleanup.pl
--- /dev/null	Thu Jan 01 00:00:00 1970 +0000
+++ b/binary-overlay.xenrt/usr/share/apt-cacher/apt-cacher-cleanup.pl	Tue Sep 28 13:04:52 2010 +0100
@@ -0,0 +1,247 @@
+#!/usr/bin/perl -w
+
+# apt-cacher-cleanup.pl
+# Script to clean the cache for the Apt-cacher package caching system.
+#
+# Copyright (C) 2005, Eduard Bloch <blade@debian.org>
+# Copyright (C) 2002-03, Jonathan Oxer <jon@debian.org>
+# Portions  (C) 2002, Jacob Lundberg <jacob@chaos2.org>
+# Distributed under the terms of the GNU Public Licence (GPL).
+
+
+# add one argument like 1 to make it verbose
+
+# do locking, not loosing files because someone redownloaded the index files
+# right then
+# use IO::Handle;
+
+use strict;
+use Cwd 'abs_path';
+
+use Fcntl ':flock';
+use IO::Handle;
+use POSIX;
+use Getopt::Long qw(:config no_ignore_case bundling pass_through);
+
+my $configfile = '/etc/apt-cacher/apt-cacher.conf';
+my $nice_mode=0;
+my $verbose=0;
+my $help;
+my $force;
+
+my %options = (
+    "h|help" => \$help,
+    "n|nice-mode=s"     => \$nice_mode,
+    "v|verbose"           => \$verbose,
+    "f|force"           => \$force,
+    "c|config-file=s"        => \$configfile
+);
+
+
+&help unless ( GetOptions(%options));
+&help if ($help);
+
+$configfile=abs_path($configfile);
+
+sub help {
+    die <<EOM
+    Usage: $0 [ -n ] [ -v ] [ -c configfile ]
+    -n : nice mode, refresh index files first, then renice to 20 and continue
+    -v : verbose mode
+    -f : force executing, disable santity checks
+EOM
+    ;
+}
+
+sub printmsg {
+   print @_ if $verbose;
+}
+
+#use strict;
+#############################################################################
+### configuration ###########################################################
+# Include the library for the config file parser
+require '/usr/share/apt-cacher/apt-cacher-lib.pl';
+# Read in the config file and set the necessary variables
+
+my $configref;
+eval {
+        $configref = read_config($configfile);
+};
+my %config = %$configref;
+
+# not sure what to do if we can't read the config file...
+die "Could not read config file: $@" if $@;
+
+my $globlockfile="$config{cache_dir}/private/exlock";
+
+# check whether we're actually meant to clean the cache
+if ( $config{clean_cache} ne 1 ) {
+	exit 0;
+}
+
+#############################################################################
+
+my $refresh=1;
+
+my %valid;
+
+my $tempdir="$config{cache_dir}/temp";
+mkdir $tempdir if !-d $tempdir;
+die "Could not create tempdir $tempdir\n" if !-d $tempdir;
+unlink (<$tempdir/*>);
+
+### Preparation of the package lists ########################################
+
+chdir "$config{cache_dir}/packages" && -w "." || die "Could not enter the cache dir";
+
+if($> == 0 && !$config{user} && !$force) {
+    die "Running $0 as root\nand no effective user has been specified. Aborting.\nPlease set the effective user in $configfile\n";
+}
+
+sub get {
+    my ($path_info, $filename) = @_;
+
+    my $fh;
+    #print "| /usr/share/apt-cacher/apt-cacher.pl -i -c $configfile >/dev/null";
+    open($fh, "| REMOTE_ADDR=CLEANUPREFRESH /usr/share/apt-cacher/apt-cacher -i -c $configfile >/dev/null");
+    printmsg "GET $path_info\n";
+    #printmsg("REMOTE_ADDR=CLEANUPREFRESH /usr/share/apt-cacher/apt-cacher -i -c $configfile >/dev/null\n");
+    print $fh "GET $path_info\r\nConnection: Close\r\n\r\n";
+    close($fh);
+    if($? && ! $force) {
+        die "Unable to update $path_info . Network problems?\nRun $0 with -v to get more details.\nCleanup aborted since cached data may be damaged.\n";
+    }
+}
+
+
+
+# file state decissions, lock that area
+open(my $lck, $globlockfile);
+flock($lck, LOCK_EX);
+my @ifiles=(<*es.gz>, <*es.bz2>, <*es>, <*_Index>);
+flock($lck, LOCK_UN);
+close($lck);
+
+for (@ifiles) {
+
+   # preserve the index files
+   $valid{$_}=1;
+
+   # now refresh them, unless disabled by the setting above
+   if($refresh) {
+       printmsg "D: $_\n";
+      # if the path is stored there, better use that
+      if(-s "../private/$_.complete") {
+         open(my $tmp, "../private/$_.complete");
+         my $url=<$tmp>;
+         &get($url);
+         close $tmp;
+      }
+      else {
+         my $tmp=$_;
+         $tmp=~s/^/\//;
+         $tmp=~s/_/\//g;
+         &get($tmp);
+      }
+   }
+}
+
+setpriority 0, 0, 20 if $nice_mode;
+
+# use the list of config files we already know
+for my $file (@ifiles) { 
+    printmsg "R: $file\n";
+
+    # get both locks and create a temp. copy
+    my $tmpfile= "$tempdir/$file";
+    open(my $glck, $globlockfile);
+    flock($glck, LOCK_EX);
+    open(my $lck, $file);
+    flock($lck, LOCK_EX);
+    link($file, $tmpfile);
+    flock($lck, LOCK_UN);
+    close($lck);
+    flock($glck, LOCK_UN);
+    close($glck);
+
+    if(-e $tmpfile && ! -s $tmpfile && $tmpfile=~/bz2$/) {
+        # moo, junk, empty file, most likely leftovers from previous versions
+        # of apt-cacher-cleanup where the junk was "protected" from beeing
+        # deleted. Purge later by not having in %valid.
+        # delete $valid{$file}; <- will be recreated RSN either way
+        print "Ignoring empty index file $file, apparently undownloadable\n" if $verbose;
+    }
+    else {
+        extract_sums($tmpfile, \%valid) || die("Error processing $file in $config{cache_dir}/packages, cleanup stopped.\nRemove the file if the repository is no longer interesting and the packages pulled from it are to be removed.\n");
+    }
+}
+
+printmsg "Found ".scalar (keys %valid)." valid file entries\n";
+#print join("\n",keys %valid);
+
+for(<*.deb>, <*.udeb>, <*.bz2>, <*.gz>, <*.dsc>) {
+    # should affect source packages but not index files which are added to the
+    # valid list above
+    if(! defined($valid{$_})) {
+        unlink $_, "../headers/$_", "../private/$_.complete";
+        printmsg "Removing source: $_ and company...\n";
+    }
+}
+
+# similar thing for possibly remaining cruft
+chdir "$config{cache_dir}/headers" && -w "." || die "Could not enter the cache dir";
+
+# headers for previosly expired files
+for(<*.deb>, <*.bz2>, <*.gz>, <*.dsc>) {
+   if(! defined($valid{$_})) {
+      unlink $_, "../private/$_.complete";
+      printmsg "Removing expired headers: $_ and company...\n";
+   }
+}
+
+# also remove void .complete files, created by broken versions of apt-cacher in rare conditions
+chdir "$config{cache_dir}/private" && -w "." || die "Could not enter the cache dir";
+for(<*.deb.complete>, <*.bz2.complete>, <*.gz.complete>, <*.dsc.complete>) {
+   s/.complete$//;
+   if(! (defined($valid{$_}) && -e "../packages/$_" && -e "../headers/$_") ) {
+      printmsg "Removing: $_.complete\n";
+      unlink "$_.complete";
+   }
+}
+
+# last step, kill some zombies
+
+my $now = time();
+for(<*.notify>) {
+    my @info = stat($_);
+    # even the largest package should be downloadable in two days or so
+    if(int(($now - $info[9])/3600) > 48) {
+        printmsg "Removing orphaned notify file: $_\n";
+        unlink $_;
+    }
+}
+
+#define_global_lockfile("$config{cache_dir}/exlock");
+#&set_global_lock(": cleanup zombies");
+
+chdir "$config{cache_dir}/packages";
+
+for(<*>) {
+    # must be empty and not complete and beeing downloaded right now
+    if(!-s $_) {
+        my $fromfile;
+        if(open($fromfile, $_) && flock($fromfile, LOCK_EX|LOCK_NB)) {
+            # double-check, may have changed while locking
+            if(!-s $_) {
+                printmsg "Removing zombie files: $_ and company...\n";
+                unlink $_, "../headers/$_", "../private/$_.complete";
+                flock($fromfile, LOCK_UN);
+                close($fromfile);
+            }
+        }
+    }
+}
+
+unlink (<$tempdir/*>);
+
diff -r cc18a0104636 binary-overlay.xenrt/usr/share/apt-cacher/apt-cacher-format-transition.pl
--- /dev/null	Thu Jan 01 00:00:00 1970 +0000
+++ b/binary-overlay.xenrt/usr/share/apt-cacher/apt-cacher-format-transition.pl	Tue Sep 28 13:04:52 2010 +0100
@@ -0,0 +1,36 @@
+#!/usr/bin/perl
+die "Please specify the cache directory!\n" if !$ARGV[0];
+
+chdir $ARGV[0] || die "Could not enter the cache directory!";
+
+@info = stat("private");
+
+mkdir "packages";
+mkdir "headers";
+chown $info[4], $info[5], "packages", "headers";
+
+for $fname (<*.deb>, <*pgp>, <*gz>, <*bz2>, <*Release>) {
+   my $data=0;
+   my $size=0;
+   open(in, $fname);
+   open(daten, ">packages/$fname");
+   open(header, ">headers/$fname");
+   while(<in>) {
+      if($data) { print daten $_; next; };
+      print header $_;
+      $size=$1 if /^Content-Length: (\d+)/;
+      $data=1 if /^$/;
+   }
+   close(daten);
+   close(header);
+   @statinfo = stat("packages/$fname");
+   if($size == $statinfo[7]) {
+      chown $info[4], $info[5], "packages/$fname", "headers/$fname";
+      utime $statinfo[9], $statinfo[9], "packages/$fname", "headers/$fname";
+      unlink $fname;
+   }
+   else {
+      unlink "packages/$fname";
+      unlink "headers/$fname";
+   }
+}
diff -r cc18a0104636 binary-overlay.xenrt/usr/share/apt-cacher/apt-cacher-import.pl
--- /dev/null	Thu Jan 01 00:00:00 1970 +0000
+++ b/binary-overlay.xenrt/usr/share/apt-cacher/apt-cacher-import.pl	Tue Sep 28 13:04:52 2010 +0100
@@ -0,0 +1,187 @@
+#!/usr/bin/perl
+
+# apt-cacher-import.pl
+# Script to import .deb packages into the Apt-cacher package caching system.
+# This script does not need to be run when setting up Apt-cacher for the first
+# time: its purpose is to initialise .deb packages that have been copied in
+# from some other source, such as a local mirror. Apt-cacher doesn't store
+# it's cached .debs in plain format, it prepends HTTP headers to them to send
+# out to clients when a package is requested. It also keeps track of which
+# packages are fully downloaded by touching a '.complete' file in the 'private'
+# directory in the cache. If .debs are just copied straight into the cache
+# dir Apt-cacher won't use them because it thinks they are both corrupt (no
+# headers) and incomplete (no .complete file). This script allows you to
+# copy a bunch of .debs into an import dir, then run this script to prepend
+# the HTTP headers and touch the .complete file after moving them to the cache
+# dir.
+#
+# Usage:
+# 1. Place your plain debs into /var/cache/apt-cacher/import (or where-ever
+#    you set the cache dir to be)
+# 2. Run this script: /usr/share/apt-cacher-import.pl
+#
+# Copyright (C) 2004, Jonathan Oxer <jon@debian.org>
+# Copyright (C) 2005, Eduard Bloch <blade@debian.org>
+
+# Distributed under the terms of the GNU Public Licence (GPL).
+
+#use strict;
+#############################################################################
+### configuration ###########################################################
+# Include the library for the config file parser
+require '/usr/share/apt-cacher/apt-cacher-lib.pl';
+
+use Getopt::Long qw(:config no_ignore_case bundling pass_through);
+use File::Basename;
+use File::Copy;
+use Cwd 'abs_path';
+use HTTP::Date;
+
+use strict;
+use warnings;
+
+my $configfile = '/etc/apt-cacher/apt-cacher.conf';
+my $help;
+my $quiet; # both not used yet
+my $noact;
+my $recmode;
+my $ro_mode;
+my $symlink_mode;
+
+my %options = (
+    "h|help" => \$help,
+    "q|quiet"           => \$quiet,
+    "n|no-act"          => \$noact,
+    "R|recursive"       => \$recmode,
+    "r|readonly"       => \$ro_mode,
+    "s|symlinks"       => \$symlink_mode,
+    "c|cfgfile=s"        => \$configfile
+);
+
+&help unless ( GetOptions(%options));
+&help if ($help);
+
+#$configfile=abs_path($configfile);
+
+my $cfg;
+eval {
+        $cfg = read_config($configfile);
+};
+
+# not sure what to do if we can't read the config file...
+die "Could not read config file: $@" if $@;
+
+my $private_dir = "$$cfg{cache_dir}/private";
+my $import_dir = "$$cfg{cache_dir}/import";
+my $target_dir = "$$cfg{cache_dir}/packages";
+my $header_dir = "$$cfg{cache_dir}/headers";
+
+my $packagesimported = 0;
+
+#############################################################################
+
+if(!$ARGV[0]) {
+   syswrite(STDOUT, "No import directory specified as the first argument, using $import_dir\n") if !$quiet;
+   sleep 2;
+}
+else {
+   $import_dir=$ARGV[0];
+}
+
+die "Cannot write to $target_dir - permission denied?\n" if !-w $target_dir;
+die "Cannot write to $header_dir - permission denied?\n" if !-w $header_dir;
+
+# common for all files
+my @info = stat($private_dir);
+my $headerdate = time2str();
+
+sub importrec {
+    my $import_dir=shift;
+    chdir($import_dir) || die "apt-cacher-import.pl: can't open the import directory ($import_dir)";
+    #print "Entering: $import_dir\n";
+
+    if($recmode) {
+        my $cwd=Cwd::getcwd();
+        for(<*>) {
+            if(-d $_ && ! -l $_) {
+                importrec($_) if -d $_;
+                chdir $cwd;
+                #print "Back in $cwd\n";
+            }
+        }
+    }
+
+    ### Loop through all the .debs in the import dir
+    foreach my $packagefile ( <*.deb>, <*.udeb>, <*.dsc>, <*.diff.gz>, <*_*tar.gz>, <*diff.bz2>, <*_*.tar.bz2> ) {
+
+        # Get some things we need to insert into the header
+        my $headerlength = (stat($packagefile))[7];
+        my $headeretag = int(rand(100000))."-".int(rand(1000))."-".int(rand(100000000));
+        $headeretag =~ s/^\s*(.*?)\s*$/$1/;
+        my $frompackagefile=$packagefile; # backup of the original name
+        $packagefile=~s/_\d+%3a/_/;
+
+	# Generate a header
+	my $httpheader = "HTTP/1.1 200 OK
+Date: ".$headerdate."
+Server: Apache \(Unix\) apt-cacher
+Last-Modified: ".$headerdate."
+ETag: \"".$headeretag."\"
+Accept-Ranges: bytes
+Content-Length: ".$headerlength."
+Keep-Alive: timeout=10, max=128
+Connection: Keep-Alive
+Content-Type: application/x-debian-package
+
+"
+; # there are TWO new lines
+
+        # Then cat the header to a temp file
+        print "Importing: $packagefile\n" if !$quiet;
+        unlink "$header_dir/$packagefile", "$target_dir/$packagefile",  "$private_dir/$packagefile.complete"; # just to be sure
+        if($symlink_mode) {
+            symlink(abs_path($frompackagefile), "$target_dir/$packagefile") ||
+            (unlink("$target_dir/$packagefile") && symlink(abs_path($frompackagefile), "$target_dir/$packagefile")) ||
+            die "Failed to create the symlink $target_dir/$packagefile";
+        }
+        elsif($ro_mode) {
+            link($frompackagefile, "$target_dir/$packagefile") || copy($frompackagefile, "$target_dir/$packagefile") || die "Failed to copy $frompackagefile";
+        }
+        else {
+            rename($frompackagefile, "$target_dir/$packagefile");
+        }
+
+        open(my $headfile, ">$header_dir/$packagefile");
+        print $headfile $httpheader;
+        close $headfile;
+
+        my $completefile = "$private_dir/$packagefile.complete";
+        open(MF, ">$completefile");
+        close(MF);
+        # copy the ownership of the private directory
+        chown $info[4], $info[5], "$header_dir/$packagefile", "$target_dir/$packagefile",  "$private_dir/$packagefile.complete";
+
+        $packagesimported++;
+    }
+}
+
+importrec($import_dir);
+
+print "Done.\n" if !$quiet;
+print "Packages imported: $packagesimported\n" if !$quiet;
+
+# Woohoo, all done!
+exit 0;
+
+sub help {
+    die "Usage: $0 [ -c apt-cacher.conf ] [ -q | --quiet ] [ -R | --recursive ] [ -r | --readonly ] [ -s | --symlinks ] [ package-source-dir ]
+
+If -c is omited, '-c /etc/apt-cacher/apt-cacher.conf' is assumed.
+If package-source-dir is omited, the filename from apt-cacher.conf is used.
+-R means descending into subdirectories while discovering pacakge files.
+-r tells to not move the source files. Instead, hardlinks or real copies are
+   created.
+-s tells to create symlinks to the source files and not move them. If the
+   target symlink exists, it will be removed.
+";
+}
diff -r cc18a0104636 binary-overlay.xenrt/usr/share/apt-cacher/apt-cacher-lib-cs.pl
--- /dev/null	Thu Jan 01 00:00:00 1970 +0000
+++ b/binary-overlay.xenrt/usr/share/apt-cacher/apt-cacher-lib-cs.pl	Tue Sep 28 13:04:52 2010 +0100
@@ -0,0 +1,91 @@
+#! /usr/bin/perl
+
+# this are hook methods overload the hooks in apt-cacher-lib.pl and implement
+# data checksumming methods
+
+use DBI;
+use Fcntl ':flock';
+use IO::Handle;
+use POSIX;
+use Digest::MD5 qw(md5_hex);
+
+
+my $ctx;
+my $dbfile;
+my $dbh;
+my $dblck;
+
+sub dbauf {
+   open($dblck, $dbfile);
+   flock($dblck, LOCK_EX);
+   $dbh = DBI->connect("dbi:SQLite:dbname=$dbfile","", "",
+   { RaiseError => 1, AutoCommit => 0 } );
+}
+
+sub dbzu {
+   $dbh->disconnect;
+   flock($dblck, LOCK_UN);
+   close($dblck);
+}
+
+# arg: filename
+sub store_sum {
+    dbauf();
+    $dbh->do('REPLACE INTO sums VALUES(?,?);', undef, shift, $ctx->hexdigest);
+    $dbh->commit;
+    dbzu();
+}
+
+# arg: file to be scanned and added to DB
+sub import_sums {
+   my %sumhash;
+   extract_sums(shift, \%sumhash);
+   dbauf();
+   for(keys %sumhash) {
+      $dbh->do("replace into sums values(?,?);",undef,$_,$sumhash{$_});
+   }
+   $dbh->commit;
+   dbzu();
+}
+
+sub db_init {
+   $dbfile=shift;
+   if(!-s $dbfile) { 
+      open $db, ">$dbfile"; close $db; # touch it
+      dbauf();
+      $dbh->do("CREATE TABLE sums (file varchar PRIMARY KEY, sum varchar(32) NOT NULL);");
+      $dbh->commit;
+      dbzu();
+   }
+}
+
+# purpose: create hasher object
+sub data_init {
+   $ctx = Digest::MD5->new;
+   return 1;
+}
+
+# purpose: append data to be scanned
+sub data_feed {
+   $ref=shift;
+   $ctx->add($$ref);
+}
+
+# arg: filename
+sub check_sum {
+   my $digest = $ctx->hexdigest;
+   dbauf();
+   my @sqlar = $dbh->selectrow_array("select sum from sums where file=?", undef, shift);
+   dbzu();
+   if(defined($sqlar[0]) && $sqlar[0] ne '') {
+       # FIXME: do not check SHA1 summs, not supported yet
+       return 1 if(length($sqlar[0]) == 40);
+
+      # now find the faulty deb
+      return ($sqlar[0] eq $digest);
+   }
+   return 1;
+}
+
+
+1;
diff -r cc18a0104636 binary-overlay.xenrt/usr/share/apt-cacher/apt-cacher-lib.pl
--- /dev/null	Thu Jan 01 00:00:00 1970 +0000
+++ b/binary-overlay.xenrt/usr/share/apt-cacher/apt-cacher-lib.pl	Tue Sep 28 13:04:52 2010 +0100
@@ -0,0 +1,226 @@
+#! /usr/bin/perl
+# This is a library file for Apt-cacher to allow code
+# common to Apt-cacher itself plus its supporting scripts
+# (apt-cacher-report.pl and apt-cacher-cleanup.pl) to be
+# maintained in one location.
+
+# This function reads the given config file into the
+# given hash ref. The key and value are separated by
+# a '=' and will have all the leading and trailing 
+# spaces removed.
+sub read_config
+{
+	# set the default config variables
+	my %config = (
+			cache_dir => '/var/log/cache/apt-cacher',
+			logdir => '/var/log/apt-cacher',
+			admin_email => 'root@localhost',
+			generate_reports => 0,
+			expire_hours => 0,
+			http_proxy => 'proxy.example.com:8080',
+			use_proxy => 0,
+			http_proxy_auth => 'proxyuser:proxypass',
+			use_proxy_auth => 0,
+			debug => 0,
+			clean_cache => 0,
+            allowed_hosts_6 => '*',
+            allowed_hosts => '*',
+            limit => 0,
+            daemon_port => 3142
+        );
+
+	($config_file) = @_;
+
+	open CONFIG, $config_file or die $!;
+
+    read(CONFIG, $buf, 50000);
+    $buf=~s/\\\n#/\n#/mg; # fix broken multilines
+    $buf=~s/\\\n//mg; # merge multilines
+
+    for(split(/\n/, $buf))
+	{
+        next if(/^#/); # weed out whole comment lines immediately
+
+        s/#.*//;   # kill off comments
+        s/^\s+//;	# kill off leading spaces
+        s/\s+$//;	# kill off trailing spaces
+
+		if ($_)
+		{
+			my ($key, $value) = split(/\s*=\s*/);	# split into key and value pair
+			$value = 0 unless ($value);
+            #print "key: $key, value: $value\n";
+			$config{$key} = $value;
+            #print "$config{$key}\n";
+		}
+	}
+
+	close CONFIG;
+
+	return \%config;
+}
+
+# Convert a human-readable IPv4 address to raw form (4-byte string)
+# Returns undef if the address is invalid
+sub ipv4_normalise ($)
+{
+	return undef if $_[0] =~ /:/;
+	my @in = split (/\./, $_[0]);
+	return '' if $#in != 3;
+	my $out = '';
+	foreach my $num (@in)
+	{
+		return undef if $num !~ /^[[:digit:]]{1,3}$/o;
+		$out .= pack ("C", $num);
+	}
+	return $out;
+}
+
+# Convert a human-readable IPv6 address to raw form (16-byte string)
+# Returns undef if the address is invalid
+sub ipv6_normalise ($)
+{
+	return "\0" x 16 if $_[0] eq '::';
+	return undef if $_[0] =~ /^:[^:]/  || $_[0] =~ /[^:]:$/ || $_[0] =~ /::.*::/;
+	my @in = split (/:/, $_[0]);
+	return undef if $#in > 7;
+	shift @in if $#in >= 1 && $in[0] eq '' && $in[1] eq ''; # handle ::1 etc.
+	my $num;
+	my $out = '';
+	my $tail = '';
+	while (defined ($num = shift @in) && $num ne '')
+	{
+		return undef if $num !~ /^[[:xdigit:]]{1,4}$/o;
+		$out .= pack ("n", hex $num);
+	}
+	foreach $num (@in)
+	{
+		return undef if $num !~ /^[[:xdigit:]]{1,4}$/o;
+		$tail .= pack ("n", hex $num);
+	}
+	my $l = length ($out.$tail);
+	return $out.("\0" x (16 - $l)).$tail if $l < 16;
+	return $out.$tail if $l == 16;
+	return undef;
+}
+
+# Make a netmask from a CIDR network-part length and the IP address length
+sub make_mask ($$)
+{
+	my ($mask, $bits) = @_;
+	return undef if $mask < 0 || $mask > $bits;
+	my $m = ("\xFF" x ($mask / 8));
+	$m .= chr ((-1 << (8 - $mask % 8)) & 255) if $mask % 8;
+	return $m . ("\0" x ($bits / 8 - length ($m)));
+}
+
+sub extract_sums {
+   my ($name, $hashref) = @_;
+   my ($cat, $listpipe, $indexbase);
+
+   $cat = ($name=~/bz2$/ ? "bzcat" : ($name=~/gz$/ ? "zcat" : "cat"));
+
+   if($name=~/^(.*_)Index$/) {
+       $indexbase=$1;
+       $indexbase=~s!.*/!!g;
+   }
+
+   open($listpipe, "-|", $cat, $name);
+   my $file;
+   while(<$listpipe>) {
+      if(/^\s(\w{40})\s+\d+\s(\S+)\n/) {
+         $sum=$1;
+         # Index format similar to Sources but filenames need to be corrected
+         # FIXME: this is sha1, not md5. Different format, can be detected by
+         # the length (40), though
+         $file=$indexbase.$2.".gz";
+     }
+     elsif(/^\s(\w{32})\s\d+\s(\S+)\n/) {
+         $sum=$1;
+         $file=$2;
+      }
+      elsif(/^MD5sum:\s+(.*)$/) {
+         $sum=$1;
+      }
+      elsif(/^Filename:\s+(.*)$/) {
+         $file=$1;
+         $file=~s/.*\///;
+      }
+      if(defined($file) && defined($sum)) {
+         $$hashref{$file}=$sum;
+         undef $file;
+         undef $sum;
+      }
+   };
+   close($listpipe);
+   my $ret = ! ($? >> 8);
+   return $ret;
+}
+
+
+my $exlock;
+my $exlockfile;
+
+sub define_global_lockfile {
+    $exlockfile=shift;
+}
+
+sub set_global_lock {
+
+    die ("Global lock file unknown") if !defined($exlockfile);
+
+    my $msg=shift;
+    $msg="" if !defined($msg);
+
+    debug_message("Entering critical section $msg");
+
+    #may need to create it if the file got lost
+    my $createstr = (-f $exlockfile) ? "" : '>';
+
+    open($exlock, $createstr.$exlockfile);
+    if ( !$exlock || !flock($exlock, LOCK_EX)) {
+        debug_message("unable to achieve a lock on $exlockfile: $!");
+        die "Unable to achieve lock on $exlockfile: $!";
+    }
+}
+
+sub release_global_lock {
+                    debug_message("Exiting critical section");
+   flock($exlock, LOCK_UN);
+}
+
+
+######### HOOKS ###########
+#
+# arg: file to be scanned and added to DB
+sub import_sums {
+   return 1;
+}
+
+# purpose: ?create?, lock the DB file and establish DB connection
+sub db_init {
+   return 1;
+}
+
+# purpose: create hasher object
+sub data_init {
+   return 1;
+}
+
+# purpose: append data to be scanned
+sub data_feed {
+   return 1;
+}
+
+# args: filename only or filename and sum
+sub check_sum {
+   return 1;
+}
+
+# args: filename and sum
+sub store_sum {
+}
+
+
+
+1;
diff -r cc18a0104636 binary-overlay.xenrt/usr/share/apt-cacher/apt-cacher-precache.pl
--- /dev/null	Thu Jan 01 00:00:00 1970 +0000
+++ b/binary-overlay.xenrt/usr/share/apt-cacher/apt-cacher-precache.pl	Tue Sep 28 13:04:52 2010 +0100
@@ -0,0 +1,189 @@
+#!/usr/bin/perl
+
+##
+# apt-cacher-precache.pl
+# Script for pre-fetching of package data that may be used by users RSN
+#
+# Copyright (C) 2005, Eduard Bloch <blade@debian.org>
+# Distributed under the terms of the GNU Public Licence (GPLv2).
+
+use Getopt::Long qw(:config no_ignore_case bundling pass_through);
+#use File::Basename;
+use Cwd 'abs_path';
+
+use strict;
+
+my $distfilter='testing|etch';
+my $quiet=0;
+my $priofilter='';
+#my $expireafter=0;
+my $help;
+my $noact=0;
+my $uselists=0;
+my $configfile = '/etc/apt-cacher/apt-cacher.conf';
+
+my %options = (
+    "h|help" => \$help,
+    "d|dist-filter=s"     => \$distfilter,
+    "q|quiet"           => \$quiet,
+    "p|by-priority=s"     => \$priofilter,
+    "n|no-act"          => \$noact,
+    "c|cfgfile=s"        => \$configfile,
+    "l|list-dir=s"        => \$uselists
+);
+ 
+
+&help unless ( GetOptions(%options));
+&help if ($help);
+
+# Include the library for the config file parser
+require '/usr/share/apt-cacher/apt-cacher-lib.pl';
+my $cfgref;
+eval {
+        $cfgref = read_config($configfile);
+};
+# not sure what to do if we can't read the config file...
+die "Could not read config file: $@" if $@;
+
+$configfile=abs_path($configfile);
+
+# now pick up what we need
+my $cachedir=$$cfgref{cache_dir};
+
+sub help {
+print "
+USAGE: $0 [ options ]
+Options:
+ -d, --dist-filter=RE  Perl regular experession, applied to the URL of Packages
+                       files to select only special versions. Example:
+                       'sid|unstable|experimental'
+                       (default: 'testing|etch')
+ -q, --quiet           suppress verbose output
+ -l, --list-dir=DIR    also use pure/compressed files from the specified dir
+                       (eg. /var/log/apt-cacher) to get the package names from.
+                       Words before | are ignored (in apt-cacher logs). To
+                       create a such list from clients, see below.
+ -p, --by-priority=RE  Perl regular expression for priorities to be looked for
+                       when selecting packages. Implies threating all packages
+                       with this priority as installation candidates.
+                       (default: scanning the cache for candidates without
+                       looking at priority)
+
+NOTE: the options may change in the future.
+You can feed existing package lists or old apt-cacher logs into the selection
+algorithm by using the -l option above. If the version is omited (eg. for lists
+created with \"dpkg --get-selections\" then the packages may be redownloaded).
+To avoid this, use following one-liner to fake a list with version infos:
+
+dpkg -l | perl -ne 'if(/^(i.|.i)\\s+(\\S+)\\s+(\\S+)/) { print \"\$2_\$3_i386.deb\\n\$2_\$3_all.deb\\n\"}'
+
+"; exit 1;};
+
+syswrite(STDOUT,
+"This is an experimental script. You have been warned.
+Run before apt-cacher-cleanup.pl, otherwise it cannot track old downloads.
+") if !$quiet;
+
+my $pcount=0;
+
+chdir "$cachedir/packages" || die "cannot enter $cachedir/packages" ;
+
+my %having; # remember seen packages, just for debugging/noact, emulate what -f would do for us otherwise
+
+sub get() {
+   my ($path_info, $filename) = @_;
+   if(!defined $having{$filename}) {
+      print "I: downloading $path_info\n" if !$quiet;
+      $pcount++;
+   }
+
+   $having{$filename}=1;
+
+   if(!$noact) {
+      open(fh, "| REMOTE_ADDR=PRECACHING /usr/share/apt-cacher/apt-cacher -i -c $configfile >/dev/null");
+      print fh "GET /$path_info\r\nConnection: Close\r\n\r\n";
+      close(fh);
+   }
+}
+
+my %pkgs;
+for (<*>) { 
+   s/_.*//g;
+   $pkgs{$_}=1;
+}
+
+if($uselists) {
+   for(<$uselists/*>) {
+      my $cat = (/bz2$/ ? "bzcat" : (/gz$/ ? "zcat" : "cat"));
+      #open(catlists, "/bin/cat $$cfg{logdir}/access.log $$cfg{logdir}/access.log.1 2>/dev/null ; zcat $$cfg{logdir}/access.log.*.gz 2>/dev/null |");
+      if(open(catlists,"-|",$cat,$_)) {
+         while(<catlists>){
+            chomp;
+            s/.*\|//g;
+            s/\s.*//g;
+            $having{$_}=1; # filter the packages we already have installed
+            s/_.*//g;
+            $pkgs{$_}=1;
+         }
+      }
+   }
+}
+
+
+PKGITER: for my $pgz (<*Packages*>) {
+
+    # ignore broken files
+    next PKGITER if(!-f "../private/$pgz.complete");
+
+   if(length($distfilter)) {
+      if($pgz =~ /$distfilter/) {
+         print "I: distfilter passed, $pgz\n" if !$quiet;
+      }
+      else {
+         next PKGITER;
+      }
+   }
+   
+   my $pgz_path_info=$pgz;
+   $pgz_path_info =~ s!_!/!g;
+   my $root_path_info = $pgz_path_info;
+   $root_path_info =~ s!/dists/.*!!g; # that sucks, pure guessing
+   $root_path_info =~ s!/project/experimental/.*!!g; # that sucks, pure guessing
+
+   my ($cat, $listpipe);
+   $_=$pgz;
+   $cat = (/bz2$/ ? "bzcat" : (/gz$/ ? "zcat" : "cat"));
+   
+   &get($pgz_path_info, $_);
+
+   print "I: processing $_\n" if !$quiet;
+   if(open(pfile,"-|",$cat,$pgz)) {
+
+      my $prio;
+      while(<pfile>) {
+         chomp;
+         if(/^Priority:\s+(.*)/) { $prio=$1; }
+         if(s/^Filename:.//) {
+            my $deb_path_info="$root_path_info/$_";
+            # purify the name
+            s!.*/!!g;
+            my $filename=$_;
+            s!_.*!!g;
+            my $pkgname=$_;
+            
+            if(length($priofilter)) {
+               if(!-e $filename && $prio=~/$priofilter/ ) {
+                  &get($deb_path_info, $filename);
+               }
+            }
+            elsif($pkgs{$pkgname}) {
+               if(!-e $filename) {
+                  &get($deb_path_info, $filename);
+               }
+            }
+         }
+      }
+   }
+}
+
+print "Downloaded: $pcount files.\n" if !$quiet;
diff -r cc18a0104636 binary-overlay.xenrt/usr/share/apt-cacher/apt-cacher-report.pl
--- /dev/null	Thu Jan 01 00:00:00 1970 +0000
+++ b/binary-overlay.xenrt/usr/share/apt-cacher/apt-cacher-report.pl	Tue Sep 28 13:04:52 2010 +0100
@@ -0,0 +1,234 @@
+#!/usr/bin/perl -w
+
+# apt-cacher-report.pl
+# Script to generate usage reports for the Apt-cacher package caching system.
+#
+# Copyright (C) 2002,2004 Jonathan Oxer <jon@debian.org>
+# Distributed under the terms of the GNU Public Licence (GPL).
+
+#use strict;
+#############################################################################
+### configuration ###########################################################
+# Include the library for the config file parser
+require '/usr/share/apt-cacher/apt-cacher-lib.pl';
+use POSIX qw(strftime);
+
+
+# Read in the config file and set the necessary variables
+my $configfile = '/etc/apt-cacher/apt-cacher.conf';
+
+my $configref;
+eval {
+        $configref = read_config($configfile);
+};
+my %config = %$configref;
+
+# not sure what to do if we can't read the config file...
+die "Could not read config file: $@" if $@;
+
+# check whether we're actually meant to generate a report
+if ( $config{generate_reports} ne 1 ){
+	exit 0;
+}
+
+# Now set some things from the config file
+# $logfile used to be set in the config file: now we derive it from $logdir
+my $logfile = "$config{logdir}/access.log";
+
+
+###################################################
+# Read in the logfiles if they exist, from oldest to newest
+
+# First we look for rolled and compressed logfiles, from
+# /var/log/apt-cacher/access.log.12.gz to access.log.2.gz
+$logcount = 12;
+while ($logcount > 1)
+{
+	if (-f "${logfile}.$logcount.gz") {
+		$logdataraw = `zcat ${logfile}.$logcount.gz`;
+		push (@logdata, split("\n", $logdataraw));
+	}
+	$logcount--;
+}
+
+# Then the immediately rolled (but uncompressed) log
+if (-f "${logfile}.1") {
+	open(LOGFILE, "<${logfile}.1");
+	#@logdata = <LOGFILE>;
+	push(@logdata, <LOGFILE>);
+	close(LOGFILE);
+}
+
+# Then finally the current working log
+if (-f "${logfile}") {
+	open(LOGFILE, "<$logfile");
+	push(@logdata, <LOGFILE>);
+	close(LOGFILE);
+}
+
+#read current time
+#($second,$minute,$hour,$day,$month,$year,$null,$null,$null)=localtime(time);
+my $datetime = strftime("%Y-%m-%d %H:%M:%S", localtime());
+
+#$year = $year + 1900;
+#$month=$month + 1;
+
+my $hit_count = 0;
+my $hit_bytes = 0;
+my $miss_count = 0;
+my $miss_bytes = 0;
+
+#parse logfile:
+foreach $logfile_line (@logdata)
+{
+	#$logfile_line =~ s/ /\+/g;
+	@line = split /\|/, $logfile_line;
+	$req_date = $line[0];
+#	$req_ip   = $line[1];
+	$req_result = $line[2];
+	$req_bytes  = $line[3];
+#	$req_object = $line[4];
+
+	$lastrecord = $req_date;
+	if(!$firstrecord) {
+		$firstrecord = $req_date;
+	}
+	if ( $req_result eq "HIT" )
+	{
+		$hit_count++;
+		$hit_bytes += $req_bytes;
+	}
+	else
+	{
+		$miss_count++;
+		$miss_bytes += $req_bytes;
+	}
+
+}
+
+my $total_count = $hit_count + $miss_count;
+
+if($total_count eq 0)
+{
+	$hit_count_percent = 0;
+	$miss_count_percent = 0;
+} else {
+	$hit_count_percent = (int(($hit_count / $total_count) * 10000)) / 100;
+	$miss_count_percent = (int(($miss_count / $total_count) * 10000)) / 100;
+}
+
+$total_bytes = $hit_bytes + $miss_bytes;
+
+##################################################
+# At this point we have hit/miss/total counts, and hit/miss/total traffic
+# So now we need to decide what units to use for each one, and set a
+# human-readable string. Displays as MB unless > 2000MB, in which case it
+# displays as GB.
+# Yes, I know this really should be a subroutine. Sigh. One day. Maybe.
+
+if($total_bytes > 2097152000)
+{
+	$tx = (int(($total_bytes/1073741824) * 1000)) / 1000;
+	$total_trafficstring = "$tx GB";
+} else {
+	$tx = (int(($total_bytes/1048576) * 1000)) / 1000;
+	$total_trafficstring = "$tx MB";
+}
+
+if($hit_bytes > 2097152000)
+{
+        $tx = (int(($hit_bytes/1073741824) * 1000)) / 1000;
+        $hit_trafficstring = "$tx GB";
+} else {
+        $tx = (int(($hit_bytes/1048576) * 1000)) / 1000;
+        $hit_trafficstring = "$tx MB";
+}
+
+if($miss_bytes > 2097152000)
+{
+        $tx = (int(($miss_bytes/1073741824) * 1000)) / 1000;
+        $miss_trafficstring = "$tx GB";
+} else {
+        $tx = (int(($miss_bytes/1048576) * 1000)) / 1000;
+        $miss_trafficstring = "$tx MB";
+}
+
+
+##################################################
+# Set percentages to 0 if no records, otherwise calculate
+if($total_bytes eq 0)
+{
+	$hit_data_percent = 0;
+	$miss_data_percent = 0;
+} else {
+	$hit_data_percent = (int(($hit_bytes / $total_bytes) * 10000)) / 100;
+	$miss_data_percent = (int(($miss_bytes / $total_bytes) * 10000)) / 100;
+}
+
+##################################################
+# If there weren't actually any logfiles processed these will be null, so we'll
+# set them to strings
+if(!$firstrecord)
+{
+	$firstrecord = "unknown";
+}
+if(!$lastrecord)
+{
+	$lastrecord = "unknown";
+}
+
+##################################################
+# spit out the report
+$output = "
+<html>
+<title>Apt-cacher traffic report</title><style type=\"text/css\"><!--
+a { text-decoration: none; }
+a:hover { text-decoration: underline; }
+h1 { font-family: arial, helvetica, sans-serif; font-size: 18pt; font-weight: bold;}
+h2 { font-family: arial, helvetica, sans-serif; font-size: 14pt; font-weight: bold;}
+body, td { font-family: arial, helvetica, sans-serif; font-size: 10pt; }
+th { font-family: arial, helvetica, sans-serif; font-size: 11pt; font-weight: bold; }
+//--></style>
+</head>
+<body>";
+
+#	print "<html><head><title>Apt-cacher traffic report</title></head>\n";
+#	print "<body bgcolor=\"#ffffff\">\n";
+
+$output .= "<p>
+<table border=0 cellpadding=8 cellspacing=1 bgcolor=\"#000000\" align=\"center\" width=\"600\">
+<tr bgcolor=\"#9999cc\"><td> <h1>Apt-cacher traffic report</h1> </td></tr>
+<tr bgcolor=\"#cccccc\"><td>For more information on apt-cacher visit <a href=\"http://packages.debian.org/apt-cacher\">http://packages.debian.org/apt-cacher</a>.
+</td></tr>
+</table>";
+
+$output .= "<h2 align=\"center\">summary</h2>
+<table border=0 cellpadding=3 cellspacing=1 bgcolor=\"#000000\" align=\"center\" width=\"600\">
+<tr bgcolor=\"#9999cc\"><th bgcolor=\"#9999cc\"> Item </th><th> Value </th></tr>
+<tr bgcolor=\"#cccccc\"><td bgcolor=\"#ccccff\"> Report generated </td><td> $datetime </td></tr>
+<tr bgcolor=\"#cccccc\"><td bgcolor=\"#ccccff\"> Administrator </td><td> <a href=\"mailto:$config{admin_email}\">$config{admin_email}</a> </td></tr>";
+$output .= "<tr bgcolor=\"#cccccc\"><td bgcolor=\"#ccccff\"> First request </td><td> $firstrecord </td></tr>";
+$output .= "<tr bgcolor=\"#cccccc\"><td bgcolor=\"#ccccff\"> Last request </td><td> $lastrecord </td></tr>";
+$output .= "<tr bgcolor=\"#cccccc\"><td bgcolor=\"#ccccff\"> Total requests </td><td> $total_count </td></tr>";
+$output .= "<tr bgcolor=\"#cccccc\"><td bgcolor=\"#ccccff\"> Total traffic </td><td> $total_trafficstring </td></tr>";
+$output .= "</table>";
+
+$output .= "<h2 align=\"center\">cache efficiency</h2>
+<table border=0 cellpadding=3 cellspacing=1 bgcolor=\"#000000\" align=\"center\" width=\"600\">
+<tr bgcolor=\"#9999cc\"><th></th><th>Cache hits</th><th>Cache misses</th><th>Total</th></tr>\n
+<tr bgcolor=\"#cccccc\"><td bgcolor=\"#ccccff\"> Requests </td><td>$hit_count ($hit_count_percent%)</td><td>$miss_count ($miss_count_percent%)</td><td>$total_count</td></tr>\n
+<tr bgcolor=\"#cccccc\"><td bgcolor=\"#ccccff\"> Transfers </td><td>$hit_trafficstring ($hit_data_percent%)</td><td>$miss_trafficstring ($miss_data_percent%)</td><td>$total_trafficstring</td></tr>\n
+</table>";
+	
+$output .= "</body></html>\n";
+
+#print $output;
+my $report_file = "$config{logdir}/report.html";
+`touch $report_file`;
+open(REPORT,">$report_file") or die;
+print REPORT "$output\n";
+close REPORT;
+
+
+exit 0;
+
diff -r cc18a0104636 binary-overlay.xenrt/usr/share/apt-cacher/apt-cacher.pl
--- /dev/null	Thu Jan 01 00:00:00 1970 +0000
+++ b/binary-overlay.xenrt/usr/share/apt-cacher/apt-cacher.pl	Tue Sep 28 13:04:52 2010 +0100
@@ -0,0 +1,9 @@
+#!/usr/bin/perl
+# apt-cacher.pl - CGI to provide a local cache for debian packages and
+# release files and .deb files. Actually just a wrapper to set CGI mode flag
+# for the real script.
+
+$ENV{CGI_MODE}=1;
+
+# identify as CGI and run the actuall script
+require "/usr/share/apt-cacher/apt-cacher";
diff -r cc18a0104636 binary-overlay.xenrt/usr/share/apt-cacher/apt-proxy-to-apt-cacher
--- /dev/null	Thu Jan 01 00:00:00 1970 +0000
+++ b/binary-overlay.xenrt/usr/share/apt-cacher/apt-proxy-to-apt-cacher	Tue Sep 28 13:04:52 2010 +0100
@@ -0,0 +1,167 @@
+#!/usr/bin/perl
+
+use strict;
+
+use Getopt::Long qw(:config no_ignore_case bundling pass_through);
+use Cwd 'abs_path';
+
+my $help;
+my $configfile = '/etc/apt-cacher/apt-cacher.conf';
+my $apconfigfile = '/etc/apt-proxy/apt-proxy-v2.conf';
+
+my %options = (
+    "h|help" => \$help,
+    "c|cfgfile=s"        => \$configfile,
+    "C|apconfigfile=s"        => \$apconfigfile,
+);
+
+&help unless ( GetOptions(%options));
+&help if ($help);
+
+sub help {
+die "
+USAGE: $0 [ options ]
+Transforms configuration and cached data from apt-proxy v2 to apt-cacher 1.x
+
+Options:
+ -c     apt-cacher's config file
+ -C     apt-proxy's  config file
+";
+}
+
+print "Reading apt-proxy's configuration from $apconfigfile\n";
+
+open(my $apc, $apconfigfile) || die "Could not open $apconfigfile. Use the -C option\n";
+
+my %config;
+
+print "Adopting options:\n";
+my $cache_dir;
+
+my $prevkey;
+LINE: while (<$apc>)
+{
+    chomp;
+    if ( /^\t(.*)$/ && defined $prevkey ) {
+        $config{$prevkey}.= " $1 ";
+        next LINE;
+    }
+
+    s/^;.*$//;   # kill off comments
+    s/^\s+//;	# kill off leading spaces
+    s/\s+$//;	# kill off trailing spaces
+
+    next if /^\[DEFAULT/;
+    
+    if(/^\[(.*)\]/) {
+        $config{path_map} .=" ; " if $config{path_map};
+        $config{path_map} .= " $1 ";
+    }
+
+    if ($_)
+    {
+        my ($key, $value) = split(/\s*=\s*/);	# split into key and value pair
+        #print "key: $key, value: $value\n";
+        $prevkey=$key;
+        if($key eq "port") {
+            $config{daemon_port} = $value;
+            print "Port: $value\n";
+        }
+        if($key eq "address") {
+            $config{daemon_addr} = $value;
+            print "Address: $value\n";
+        }
+        if($key eq "http_proxy") {
+            $config{http_proxy} = $value;
+            $config{use_proxy} = 1;
+            print "Proxy: $value\n";
+        }
+        if($key eq "backends") {
+            $prevkey = "path_map";
+            $config{path_map} .= " $value ";
+        }
+        if($key eq "cache_dir") {
+            $cache_dir=$value;
+        }
+    }
+}
+
+my @map = split(/\s+/, $config{path_map});
+for(@map) {
+    # just try to use http on ftp servers and drop rsync versions
+    # s#^ftp:#http:#;
+    # s#^rsync.*##;
+    s#^.*://##;
+}
+$config{path_map} = join(" ", @map);
+
+#for(keys %config) {
+#    print "hm, $_: $config{$_}\n";
+#}
+
+print "Reading apt-cacher's configuration from $configfile\n";
+
+open(CONFIG, $configfile) || die "Unable to open the apt-cacher config file template\n";
+
+my $buf;
+read(CONFIG, $buf, 50000);
+close(CONFIG);
+$buf=~s/\\\n#/\n#/mg; # fix broken multilines
+$buf=~s/\\\n//mg; # merge multilines
+
+my @out = ("# This file has been modified by $0\n# Some lines may have been appended at the bottom of this file\n");
+
+for(split(/\n/, $buf))
+{
+    my $orig=$_;
+
+    s/#.*//;   # kill off comments
+    s/^\s+//;	# kill off leading spaces
+    s/\s+$//;	# kill off trailing spaces
+
+    if ($_)
+    {
+        my ($key, $value) = split(/\s*=\s*/);	# split into key and value pair
+        if(exists $config{$key}) {
+            push @out, "$key = $config{$key}\n";
+            delete $config{$key};
+        }
+        else {
+            push @out, "$orig\n";
+        }
+    }
+    else {
+        push @out, "$orig\n";
+    }
+}
+
+# append the remaining settings
+for(keys %config) {
+    push @out, "\n# extra setting from apt-proxy configuration\n$_ = $config{$_}\n";
+}
+
+print "\n$0 will now modify the apt-cacher.conf file\nand import the data from apt-proxy's cache. Do you wish to continue? [y/n] ";
+my $answer= <STDIN>;
+if($answer eq "y\n") {
+
+    open(CONFIG, ">$configfile") || die "Unable to write apt-cacher config file\n";
+    print CONFIG @out;
+    close(CONFIG);
+    #print join(" ", "Running: ", "/usr/share/apt-cacher/apt-cacher-import.pl", "-c", $configfile, "-r", "-R" , $cache_dir, "\n");
+
+    system("/usr/share/apt-cacher/apt-cacher-import.pl", "-c", $configfile, "-r", "-R" , $cache_dir);
+}
+    
+print "\nStop apt-proxy and start apt-cacher now? [y/n] ";
+$answer= <STDIN>;
+if($answer eq "y\n") {
+    system "/etc/init.d/apt-proxy stop";
+    system "echo AUTOSTART=1 >> /etc/default/apt-cacher";
+    system "/etc/init.d/apt-cacher restart";
+}
+    
+print "\nDisable the apt-proxy in the init configuration (update-rc.d remove)? [y/n] ";
+$answer= <STDIN>;
+if($answer eq "y\n") {
+    system "update-rc.d -f apt-proxy remove";
+}
diff -r cc18a0104636 binary-overlay.xenrt/usr/share/apt-cacher/install.pl
--- /dev/null	Thu Jan 01 00:00:00 1970 +0000
+++ b/binary-overlay.xenrt/usr/share/apt-cacher/install.pl	Tue Sep 28 13:04:52 2010 +0100
@@ -0,0 +1,209 @@
+#!/usr/bin/perl -w
+#	@(#) setup.pl -- Setup script for apt-cacher.pl
+#	$ Revision: $
+#	$ Source: $
+#	$ Date: $
+#
+#	Safe to run multiple times; later versions of this script will
+#	remove obsolete directories or files and not touch required
+#	directories or files.
+#
+
+umask 0022;
+
+#############################################################################
+### configuration ###########################################################
+# Include the library for the config file parser
+require '/usr/share/apt-cacher/apt-cacher-lib.pl';
+
+# Read in the config file and set the necessary variables
+my $configfile = '/etc/apt-cacher/apt-cacher.conf';
+
+my $configref;
+eval {
+        $configref = read_config($configfile);
+};
+my %config = %$configref;
+
+# not sure what to do if we can't read the config file...
+die "Could not read config file: $@" if $@;
+
+# Now set some things from the config file
+# $logfile used to be set in the config file: now we derive it from $logdir
+$config{logfile} = "$config{logdir}/access.log";
+
+# $errorfile used to be set in the config file: now we derive it from $logdir
+$config{errorfile} = "$config{logdir}/error.log";
+
+my $private_dir = "$config{cache_dir}/private";
+
+################################################
+# Check that the cache_dir has been set and continue on (note: this should never happen
+# because cache_dir is preset to a default value prior to loading the config file)
+die "Warning: config file could not be parsed ($configfile)/ (cache_dir is not set)\n" if ($config{cache_dir} eq '');
+
+
+@info=getpwnam("www-data");
+my @permcmd;
+if(-e $config{cache_dir}) {
+   @permcmd = ("chown", "--reference", $config{cache_dir});
+}
+elsif(@info) {
+   print "Assuming www-data is the user ID used to run apt-cacher\n";
+   @permcmd = ("chown", "$info[2]:$info[3]");
+}
+else {
+   @permcmd = ("/bin/echo", "User account for apt-cacher/http daemon unknown, plese set ownership for the following files manually:");
+}
+
+for ("README", "README.txt") {
+   my $file=$config{cache_dir}."/$_";
+   if (-f $file) {
+      print "Found obsolete file $file - removing.\n";
+      unlink($file);
+   }
+}
+
+foreach my $dir ($config{cache_dir}, $config{logdir}, "$config{cache_dir}/private", "$config{cache_dir}/import",
+    "$config{cache_dir}/packages", "$config{cache_dir}/headers", "$config{cache_dir}/temp") {
+	if (!-d $dir) {
+		print "Doing mkdir($dir, 0755)\n";
+		mkdir($dir, 0755);
+    system (@permcmd, $dir);
+	}
+	if (!-w $dir) {
+		die "Warning, $dir exists but is not is not writeable for apt-cacher!\n";
+	}
+}
+
+# Remove these directories if they exist (obsolete)
+foreach my $rmdir ("$config{cache_dir}/tmp", "$config{cache_dir}/head") {
+	if (-d $rmdir) {
+		print "Doing 'rm -rf $rmdir' (obsolete)\n";
+		system("rm -rf $rmdir");
+	}
+}
+
+# At the moment we need to create empty access and error logs so apt-cacher
+# doesn't barf the first time it's run. Probably should change apt-cacher
+# so it can handle missing logs, and create them itself if required.
+for $file ($config{logfile}, $config{errorfile}) {
+   if(!-e $file) {
+      open(my $tmp, ">$file");
+      close($tmp);
+      system @permcmd, $file;
+   }
+}
+
+# These ownership changes are a cludge: need to make them check httpd.conf for the Apache
+# user and set ownership to that, and do it with Perl instead of shell
+# EB: fsck that, this may simply overwritte changes by the admin
+# `chown -R www-data.www-data $config{cache_dir}`;
+
+# We used to tack a line onto the end of apache.conf. Now we just symlink into conf.d
+if(-d "/etc/apache/conf.d" ){
+	symlink("/etc/apt-cacher/apache.conf","/etc/apache/conf.d/apt-cacher");
+}
+
+if(-d "/etc/apache-ssl/conf.d" ){
+	symlink("/etc/apt-cacher/apache.conf","/etc/apache-ssl/conf.d/apt-cacher");
+}
+
+if(-d "/etc/apache2/conf.d" ){
+	rename("/etc/apache2/conf.d/apt-cacher", "/etc/apache2/conf.d/apt-cacher.conf") || symlink("/etc/apt-cacher/apache.conf","/etc/apache2/conf.d/apt-cacher.conf");
+}
+
+# Apache2 needs the cgi module installed, which it isn't by default.
+if(-d "/etc/apache2/mods-enabled"){
+	symlink("/etc/apache2/mods-available/cgi.load","/etc/apache2/mods-enabled/cgi.load");
+}
+
+
+#vvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvv
+# Just for now we still have to try nuking old entries in httpd.conf,
+# because they may have been left behind previously. After a couple
+# more releases this should be removed from here and remove.pl
+
+# Remove the include lines from Apache's httpd.conf
+my $httpdconf = "/etc/apache/httpd.conf";
+if (-f $httpdconf) {
+	$old = $httpdconf;
+	$new = "$httpdconf.tmp.$$";
+	$bak = "$httpdconf.bak";
+	
+	open(OLD, "< $old")         or die "can't open $old: $!";
+	open(NEW, "> $new")         or die "can't open $new: $!";
+	
+	while (<OLD>) {
+		s/# This line has been appended by the Apt\-cacher install script/ /;
+		s/Include \/etc\/apt\-cacher\/apache.conf/ /;
+		(print NEW $_)          or die "can't write to $new: $!";
+	}
+	
+	close(OLD)                  or die "can't close $old: $!";
+	close(NEW)                  or die "can't close $new: $!";
+	
+	rename($old, $bak)          or die "can't rename $old to $bak: $!";
+	rename($new, $old)          or die "can't rename $new to $old: $!";
+	if (-f "/etc/init.d/apache")
+	{
+		`/etc/init.d/apache restart`;
+	}
+}
+
+# Remove the include lines from Apache-SSL's httpd.conf
+$httpdconf = "/etc/apache-ssl/httpd.conf";
+if (-f $httpdconf) {
+	$old = $httpdconf;
+	$new = "$httpdconf.tmp.$$";
+	$bak = "$httpdconf.bak";
+	
+	open(OLD, "< $old")         or die "can't open $old: $!";
+	open(NEW, "> $new")         or die "can't open $new: $!";
+	
+	while (<OLD>) {
+		s/# This line has been appended by the Apt\-cacher install script/ /;
+		s/Include \/etc\/apt\-cacher\/apache.conf/ /;
+		(print NEW $_)          or die "can't write to $new: $!";
+	}
+	
+	close(OLD)                  or die "can't close $old: $!";
+	close(NEW)                  or die "can't close $new: $!";
+	
+	rename($old, $bak)          or die "can't rename $old to $bak: $!";
+	rename($new, $old)          or die "can't rename $new to $old: $!";
+	if (-f "/etc/init.d/apache-ssl")
+	{
+		`/etc/init.d/apache-ssl restart`;
+	}
+}
+
+# Remove the include lines from Apache2's apache2.conf
+$httpdconf = "/etc/apache2/apache2.conf";
+if (-f $httpdconf) {
+        $old = $httpdconf;
+        $new = "$httpdconf.tmp.$$";
+        $bak = "$httpdconf.bak";
+
+        open(OLD, "< $old")         or die "can't open $old: $!";
+        open(NEW, "> $new")         or die "can't open $new: $!";
+
+        while (<OLD>) {
+                s/# This line has been appended by the Apt\-cacher install script/ /;
+                s/Include \/etc\/apt\-cacher\/apache.conf/ /;
+                (print NEW $_)          or die "can't write to $new: $!";
+        }
+
+        close(OLD)                  or die "can't close $old: $!";
+        close(NEW)                  or die "can't close $new: $!";
+
+        rename($old, $bak)          or die "can't rename $old to $bak: $!";
+        rename($new, $old)          or die "can't rename $new to $old: $!";
+	if (-f "/etc/init.d/apache2")
+	{
+		`/etc/init.d/apache2 restart`;
+	}
+}
+#^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
+
+exit(0);
diff -r cc18a0104636 binary-overlay.xenrt/usr/share/apt-cacher/remove.pl
--- /dev/null	Thu Jan 01 00:00:00 1970 +0000
+++ b/binary-overlay.xenrt/usr/share/apt-cacher/remove.pl	Tue Sep 28 13:04:52 2010 +0100
@@ -0,0 +1,142 @@
+#!/usr/bin/perl -w
+#	@(#) remove.pl -- Remove script for apt-cacher
+#	$ Revision: $
+#	$ Source: $
+#	$ Date: $
+#
+
+my $path = $ENV{PATH_INFO};
+#############################################################################
+### configuration ###########################################################
+# Include the library for the config file parser
+require '/usr/share/apt-cacher/apt-cacher-lib.pl';
+
+# Read in the config file and set the necessary variables
+my $configfile = '/etc/apt-cacher/apt-cacher.conf';
+
+my $configref;
+eval {
+        $configref = read_config($configfile);
+};
+my %config = %$configref;
+
+# not sure what to do if we can't read the config file...
+die "Could not read config file: $@" if $@;
+
+# Now set some things from the config file
+# $logfile used to be set in the config file: now we derive it from $logdir
+$config{logfile} = "$config{logdir}/access.log";
+
+# $errorfile used to be set in the config file: now we derive it from $logdir
+$config{errorfile} = "$config{logdir}/error.log";
+
+my $private_dir = "$config{cache_dir}/private";
+
+################################################
+
+# Now set some things from the config file
+$config{reportfile} = "$config{logdir}/report.html";
+
+
+
+# Remove the include lines from Apache's httpd.conf
+# Thankfully this is a lot easier now we're just symlinking our config file!
+if(-d "/etc/apache/conf.d/" ){
+	unlink("/etc/apache/conf.d/apt-cacher");
+}
+
+if(-d "/etc/apache-ssl/conf.d/" ){
+	unlink("/etc/apache-ssl/conf.d/apt-cacher");
+}
+
+if(-d "/etc/apache2/conf.d/" ){
+	unlink("/etc/apache2/conf.d/apt-cacher");
+	unlink("/etc/apache2/conf.d/apt-cacher.conf");
+}
+
+
+# Delete the cache directory and everything in it, in the purge step
+#system("rm", "-rf", $config{cache_dir});
+
+# Delete the two log files (leaving the directory behind for now)
+unlink($config{logfile});
+unlink($config{errorfile});
+unlink($config{reportfile});
+
+#vvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvv
+# Just for now we still have to try nuking old entries in httpd.conf,
+# because they may have been left behind previously. After a couple
+# more releases this should be removed from here and install.pl
+
+# Remove the include lines from Apache's httpd.conf
+my $httpdconf = "/etc/apache/httpd.conf";
+if (-f $httpdconf) {
+	$old = $httpdconf;
+	$new = "$httpdconf.tmp.$$";
+	$bak = "$httpdconf.bak";
+	
+	open(OLD, "< $old")         or die "can't open $old: $!";
+	open(NEW, "> $new")         or die "can't open $new: $!";
+	
+	while (<OLD>) {
+		s/# This line has been appended by the Apt\-cacher install script/ /;
+		s/Include \/etc\/apt\-cacher\/apache.conf/ /;
+		(print NEW $_)          or die "can't write to $new: $!";
+	}
+	
+	close(OLD)                  or die "can't close $old: $!";
+	close(NEW)                  or die "can't close $new: $!";
+	
+	rename($old, $bak)          or die "can't rename $old to $bak: $!";
+	rename($new, $old)          or die "can't rename $new to $old: $!";
+}
+
+# Remove the include lines from Apache-SSL's httpd.conf
+$httpdconf = "/etc/apache-ssl/httpd.conf";
+if (-f $httpdconf) {
+	$old = $httpdconf;
+	$new = "$httpdconf.tmp.$$";
+	$bak = "$httpdconf.bak";
+	
+	open(OLD, "< $old")         or die "can't open $old: $!";
+	open(NEW, "> $new")         or die "can't open $new: $!";
+	
+	while (<OLD>) {
+		s/# This line has been appended by the Apt\-cacher install script/ /;
+		s/Include \/etc\/apt\-cacher\/apache.conf/ /;
+		(print NEW $_)          or die "can't write to $new: $!";
+	}
+	
+	close(OLD)                  or die "can't close $old: $!";
+	close(NEW)                  or die "can't close $new: $!";
+	
+	rename($old, $bak)          or die "can't rename $old to $bak: $!";
+	rename($new, $old)          or die "can't rename $new to $old: $!";
+}
+
+# Remove the include lines from Apache2's apache2.conf
+$httpdconf = "/etc/apache2/apache2.conf";
+if (-f $httpdconf) {
+        $old = $httpdconf;
+        $new = "$httpdconf.tmp.$$";
+        $bak = "$httpdconf.bak";
+
+        open(OLD, "< $old")         or die "can't open $old: $!";
+        open(NEW, "> $new")         or die "can't open $new: $!";
+
+        while (<OLD>) {
+                s/# This line has been appended by the Apt\-cacher install script/ /;
+                s/Include \/etc\/apt\-cacher\/apache.conf/ /;
+                (print NEW $_)          or die "can't write to $new: $!";
+        }
+
+        close(OLD)                  or die "can't close $old: $!";
+        close(NEW)                  or die "can't close $new: $!";
+
+        rename($old, $bak)          or die "can't rename $old to $bak: $!";
+        rename($new, $old)          or die "can't rename $new to $old: $!";
+}
+#^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
+
+
+exit(0);
diff -r cc18a0104636 binary-overlay.xenrt/usr/share/apt-cacher/upgrade.pl
--- /dev/null	Thu Jan 01 00:00:00 1970 +0000
+++ b/binary-overlay.xenrt/usr/share/apt-cacher/upgrade.pl	Tue Sep 28 13:04:52 2010 +0100
@@ -0,0 +1,124 @@
+#!/usr/bin/perl -w
+#	@(#) remove.pl -- Upgrade script for apt-cacher
+#	$ Revision: $
+#	$ Source: $
+#	$ Date: $
+# This script is actually almost identical to the remove script, except that
+# on upgrade we don't want to nuke the cache contents so that part is commented
+# out. We also don't want to restart Apache twice (it already gets done by the
+# install script that gets run at the end of the upgrade, and even that's not
+# necessary).
+
+my $path = $ENV{PATH_INFO};
+#############################################################################
+### configuration ###########################################################
+# Include the library for the config file parser
+require '/usr/share/apt-cacher/apt-cacher-lib.pl';
+
+# Read in the config file and set the necessary variables
+my $configfile = '/etc/apt-cacher/apt-cacher.conf';
+
+my $configref;
+eval {
+        $configref = read_config($configfile);
+};
+my %config = %$configref;
+
+# not sure what to do if we can't read the config file...
+die "Could not read config file: $@" if $@;
+
+# Now set some things from the config file
+# $logfile used to be set in the config file: now we derive it from $logdir
+$config{logfile} = "$config{logdir}/access.log";
+
+# $errorfile used to be set in the config file: now we derive it from $logdir
+$config{errorfile} = "$config{logdir}/error.log";
+
+my $private_dir = "$config{cache_dir}/private";
+
+################################################
+
+# Now set some things from the config file
+$config{reportfile} = "$config{logdir}/report.html";
+
+
+
+
+# Remove the include lines from Apache's httpd.conf
+# This should really be turned into a function so I don't have to
+# copy the whole lot for Apache-SSL!
+my $httpdconf = "/etc/apache/httpd.conf";
+if (-f $httpdconf) {
+	$old = $httpdconf;
+	$new = "$httpdconf.tmp.$$";
+	$bak = "$httpdconf.bak";
+	
+	open(OLD, "< $old")         or die "can't open $old: $!";
+	open(NEW, "> $new")         or die "can't open $new: $!";
+	
+	while (<OLD>) {
+		s/# This line has been appended by the Apt\-cacher install script/ /;
+		s/Include \/etc\/apt\-cacher\/apache.conf/ /;
+		(print NEW $_)          or die "can't write to $new: $!";
+	}
+	
+	close(OLD)                  or die "can't close $old: $!";
+	close(NEW)                  or die "can't close $new: $!";
+	
+	rename($old, $bak)          or die "can't rename $old to $bak: $!";
+	rename($new, $old)          or die "can't rename $new to $old: $!";
+	
+	## Restart Apache
+	#if ( -f "/etc/init.d/apache" ) {
+	#	print "Restarting Apache (if you have an SSL cert password, enter it now):";
+	#	`/etc/init.d/apache restart`;
+	#	print "... done.\n";
+	#} else {
+	#	print "Apache startup script was not found. Please restart Apache manually.\n";
+	#}
+}
+
+# Remove the include lines from Apache-SSL's httpd.conf
+# This should really be turned into a function so I don't have to
+# copy the whole lot for Apache-SSL!
+$httpdconf = "/etc/apache-ssl/httpd.conf";
+if (-f $httpdconf) {
+	$old = $httpdconf;
+	$new = "$httpdconf.tmp.$$";
+	$bak = "$httpdconf.bak";
+	
+	open(OLD, "< $old")         or die "can't open $old: $!";
+	open(NEW, "> $new")         or die "can't open $new: $!";
+	
+	while (<OLD>) {
+		s/# This line has been appended by the Apt\-cacher install script/ /;
+		s/Include \/etc\/apt\-cacher\/apache.conf/ /;
+		(print NEW $_)          or die "can't write to $new: $!";
+	}
+	
+	close(OLD)                  or die "can't close $old: $!";
+	close(NEW)                  or die "can't close $new: $!";
+	
+	rename($old, $bak)          or die "can't rename $old to $bak: $!";
+	rename($new, $old)          or die "can't rename $new to $old: $!";
+	
+	## Restart Apache-SSL
+	#if ( -f "/etc/init.d/apache-ssl" ) {
+	#	print "Restarting Apache-SSL (if you have an SSL cert password, enter it now):";
+	#	`/etc/init.d/apache-ssl restart`;
+	#	print "... done.\n";
+	#} else {
+	#	print "Apache-SSL startup script was not found. Please restart Apache-SSL manually.\n";
+	#}
+}
+
+
+## Delete the cache directory and everything in it
+#system("rm -rf $config{cache_dir}");
+#
+## Delete the two log files (leaving the directory behind for now)
+#unlink($config{logfile});
+#unlink($config{errorfile});
+#unlink($config{reportfile});
+
+exit(0);
diff -r cc18a0104636 mkfs.swap
--- /dev/null	Thu Jan 01 00:00:00 1970 +0000
+++ b/mkfs.swap	Tue Sep 28 13:04:52 2010 +0100
@@ -0,0 +1,23 @@
+#!/bin/bash
+
+set -e
+
+IMAGE=$1
+SIZE_G=$2
+shift 2
+
+MOUNT=${IMAGE}.mnt
+
+SIZE_B=$((${SIZE_G} * 1000*1000*1000))
+
+if [ -f "${IMAGE}" ] ; then
+    rm -f "${IMAGE}"
+fi
+
+echo "Creating sparse file ${IMAGE} ($SIZE_B bytes)"
+dd if=/dev/zero of=${IMAGE} bs=1 seek=${SIZE_B} count=0 2>/dev/null
+
+echo "Creating swap on ${IMAGE}"
+mkswap ${IMAGE} $@
+
+exit 0
diff -r cc18a0104636 overlay.xenrt/boot/grub/menu.lst
--- /dev/null	Thu Jan 01 00:00:00 1970 +0000
+++ b/overlay.xenrt/boot/grub/menu.lst	Tue Sep 28 13:04:52 2010 +0100
@@ -0,0 +1,3 @@
+title @PRODUCT_BRAND@ XenRT @PRODUCT_VERSION@
+	kernel /boot/vmlinuz-@KERNEL_VERSION@ root=/dev/@OVA_ROOT_DEVICE@1 ro xencons=hvc console=hvc0 
+	initrd /boot/initrd-@KERNEL_VERSION@.img
diff -r cc18a0104636 overlay.xenrt/etc/dnsmasq.conf
--- /dev/null	Thu Jan 01 00:00:00 1970 +0000
+++ b/overlay.xenrt/etc/dnsmasq.conf	Tue Sep 28 13:04:52 2010 +0100
@@ -0,0 +1,446 @@
+# Configuration file for dnsmasq.
+#
+# Format is one option per line, legal options are the same
+# as the long options legal on the command line. See
+# "/usr/sbin/dnsmasq --help" or "man 8 dnsmasq" for details.
+
+# The following two options make you a better netizen, since they
+# tell dnsmasq to filter out queries which the public DNS cannot
+# answer, and which load the servers (especially the root servers)
+# uneccessarily. If you have a dial-on-demand link they also stop
+# these requests from bringing up the link uneccessarily.
+
+# Never forward plain names (without a dot or domain part)
+#domain-needed
+# Never forward addresses in the non-routed address spaces.
+#bogus-priv
+
+
+# Uncomment this to filter useless windows-originated DNS requests
+# which can trigger dial-on-demand links needlessly.
+# Note that (amongst other things) this blocks all SRV requests,
+# so don't use it if you use eg Kerberos.
+# This option only affects forwarding, SRV records originating for
+# dnsmasq (via srv-host= lines) are not suppressed by it.
+#filterwin2k
+
+# Change this line if you want dns to get its upstream servers from
+# somewhere other that /etc/resolv.conf
+#resolv-file=
+
+# By  default,  dnsmasq  will  send queries to any of the upstream
+# servers it knows about and tries to favour servers to are  known
+# to  be  up.  Uncommenting this forces dnsmasq to try each query
+# with  each  server  strictly  in  the  order  they   appear   in
+# /etc/resolv.conf
+#strict-order
+
+# If you don't want dnsmasq to read /etc/resolv.conf or any other
+# file, getting its servers from this file instead (see below), then
+# uncomment this.
+no-resolv
+
+# If you don't want dnsmasq to poll /etc/resolv.conf or other resolv
+# files for changes and re-read them then uncomment this.
+no-poll
+
+# Add other name servers here, with domain specs if they are for
+# non-public domains.
+#server=/localnet/192.168.0.1
+
+# Example of routing PTR queries to nameservers: this will send all 
+# address->name queries for 192.168.3/24 to nameserver 10.1.2.3
+#server=/3.168.192.in-addr.arpa/10.1.2.3
+
+# Add local-only domains here, queries in these domains are answered
+# from /etc/hosts or DHCP only.
+#local=/localnet/
+
+# Add domains which you want to force to an IP address here.
+# The example below send any host in doubleclick.net to a local
+# webserver.
+#address=/doubleclick.net/127.0.0.1
+
+# If you want dnsmasq to change uid and gid to something other
+# than the default, edit the following lines.
+#user=
+#group=
+
+# If you want dnsmasq to listen for DHCP and DNS requests only on
+# specified interfaces (and the loopback) give the name of the
+# interface (eg eth0) here.
+# Repeat the line for more than one interface.
+#interface=
+# Or you can specify which interface _not_ to listen on
+#except-interface=
+# Or which to listen on by address (remember to include 127.0.0.1 if
+# you use this.)
+#listen-address=
+# If you want dnsmasq to provide only DNS service on an interface,
+# configure it as shown above, and then use the following line to
+# disable DHCP on it.
+#no-dhcp-interface=
+
+# On systems which support it, dnsmasq binds the wildcard address,
+# even when it is listening on only some interfaces. It then discards
+# requests that it shouldn't reply to. This has the advantage of
+# working even when interfaces come and go and change address. If you
+# want dnsmasq to really bind only the interfaces it is listening on,
+# uncomment this option. About the only time you may need this is when
+# running another nameserver on the same machine.
+#bind-interfaces
+
+# If you don't want dnsmasq to read /etc/hosts, uncomment the
+# following line.
+#no-hosts
+# or if you want it to read another file, as well as /etc/hosts, use
+# this.
+#addn-hosts=/etc/banner_add_hosts
+
+# Set this (and domain: see below) if you want to have a domain
+# automatically added to simple names in a hosts-file.
+#expand-hosts
+
+# Set the domain for dnsmasq. this is optional, but if it is set, it
+# does the following things.
+# 1) Allows DHCP hosts to have fully qualified domain names, as long
+#     as the domain part matches this setting.
+# 2) Sets the "domain" DHCP option thereby potentially setting the
+#    domain of all systems configured by DHCP
+# 3) Provides the domain part for "expand-hosts"
+#domain=thekelleys.org.uk
+
+# Uncomment this to enable the integrated DHCP server, you need
+# to supply the range of addresses available for lease and optionally
+# a lease time. If you have more than one network, you will need to
+# repeat this for each network on which you want to supply DHCP
+# service.
+#dhcp-range=192.168.0.50,192.168.0.150,12h
+
+# This is an example of a DHCP range where the netmask is given. This
+# is needed for networks we reach the dnsmasq DHCP server via a relay
+# agent. If you don't know what a DHCP relay agent is, you probably
+# don't need to worry about this.
+#dhcp-range=192.168.0.50,192.168.0.150,255.255.255.0,12h
+
+# This is an example of a DHCP range with a network-id, so that
+# some DHCP options may be set only for this network.
+#dhcp-range=red,192.168.0.50,192.168.0.150
+
+# Supply parameters for specified hosts using DHCP. There are lots
+# of valid alternatives, so we will give examples of each. Note that
+# IP addresses DO NOT have to be in the range given above, they just
+# need to be on the same network. The order of the parameters in these
+# do not matter, it's permissble to give name,adddress and MAC in any order
+
+# Always allocate the host with ethernet address 11:22:33:44:55:66
+# The IP address 192.168.0.60
+#dhcp-host=11:22:33:44:55:66,192.168.0.60
+
+# Always set the name of the host with hardware address
+# 11:22:33:44:55:66 to be "fred"
+#dhcp-host=11:22:33:44:55:66,fred
+
+# Always give the host with ethernet address 11:22:33:44:55:66
+# the name fred and IP address 192.168.0.60 and lease time 45 minutes
+#dhcp-host=11:22:33:44:55:66,fred,192.168.0.60,45m
+
+# Give the machine which says it's name is "bert" IP address
+# 192.168.0.70 and an infinite lease
+#dhcp-host=bert,192.168.0.70,infinite
+
+# Always give the host with client identifier 01:02:02:04
+# the IP address 192.168.0.60
+#dhcp-host=id:01:02:02:04,192.168.0.60
+
+# Always give the host with client identifier "marjorie"
+# the IP address 192.168.0.60
+#dhcp-host=id:marjorie,192.168.0.60
+
+# Enable the address given for "judge" in /etc/hosts
+# to be given to a machine presenting the name "judge" when
+# it asks for a DHCP lease.
+#dhcp-host=judge
+
+# Never offer DHCP service to a machine whose ethernet
+# address is 11:22:33:44:55:66
+#dhcp-host=11:22:33:44:55:66,ignore
+
+# Ignore any client-id presented by the machine with ethernet
+# address 11:22:33:44:55:66. This is useful to prevent a machine
+# being treated differently when running under different OS's or
+# between PXE boot and OS boot.
+#dhcp-host=11:22:33:44:55:66,id:*
+
+# Send extra options which are tagged as "red" to
+# the machine with ethernet address 11:22:33:44:55:66
+#dhcp-host=11:22:33:44:55:66,net:red
+
+# Send extra options which are tagged as "red" to
+# any machine with ethernet address starting 11:22:33:
+#dhcp-host=11:22:33:*:*:*,net:red
+
+# Send extra options which are tagged as "red" to any machine whose
+# DHCP vendorclass string includes the substring "Linux"
+#dhcp-vendorclass=red,Linux
+
+# Send extra options which are tagged as "red" to any machine one
+# of whose DHCP userclass strings includes the substring "accounts"
+#dhcp-userclass=red,accounts
+
+# Send extra options which are tagged as "red" to any machine whose
+# MAC address matches the pattern.
+#dhcp-mac=red,00:60:8C:*:*:*
+
+# If this line is uncommented, dnsmasq will read /etc/ethers and act
+# on the ethernet-address/IP pairs found there just as if they had
+# been given as --dhcp-host options. Useful if you keep
+# MAC-address/host mappings there for other purposes.
+#read-ethers
+
+# Send options to hosts which ask for a DHCP lease.
+# See RFC 2132 for details of available options.
+# Common options can be given to dnsmasq by name: 
+# run "dnsmasq --help dhcp" to get a list.
+# Note that all the common settings, such as netmask and
+# broadcast address, DNS server and default route, are given
+# sane defaults by dnsmasq. You very likely will not need any
+# any dhcp-options. If you use Windows clients and Samba, there
+# are some options which are recommended, they are detailed at the
+# end of this section.
+
+# Override the default route supplied by dnsmasq, which assumes the
+# router is the same machine as the one running dnsmasq.
+#dhcp-option=3,1.2.3.4
+
+# Do the same thing, but using the option name
+#dhcp-option=option:router,1.2.3.4
+
+# Override the default route supplied by dnsmasq and send no default
+# route at all. Note that this only works for the options sent by
+# default (1, 3, 6, 12, 28) the same line will send a zero-length option 
+# for all other option numbers.
+#dhcp-option=3
+
+# Set the NTP time server addresses to 192.168.0.4 and 10.10.0.5
+#dhcp-option=option:ntp-server,192.168.0.4,10.10.0.5
+
+# Set the NTP time server address to be the same machine as
+# is running dnsmasq
+#dhcp-option=42,0.0.0.0
+
+# Set the NIS domain name to "welly"
+#dhcp-option=40,welly
+
+# Set the default time-to-live to 50
+#dhcp-option=23,50
+
+# Set the "all subnets are local" flag
+#dhcp-option=27,1
+
+# Send the etherboot magic flag and then etherboot options (a string).
+#dhcp-option=128,e4:45:74:68:00:00
+#dhcp-option=129,NIC=eepro100
+
+# Specify an option which will only be sent to the "red" network
+# (see dhcp-range for the declaration of the "red" network)
+# Note that the net: part must precede the option: part.
+#dhcp-option = net:red, option:ntp-server, 192.168.1.1
+
+# The following DHCP options set up dnsmasq in the same way as is specified
+# for the ISC dhcpcd in
+# http://www.samba.org/samba/ftp/docs/textdocs/DHCP-Server-Configuration.txt
+# adapted for a typical dnsmasq installation where the host running
+# dnsmasq is also the host running samba.
+# you may want to uncomment them if you use Windows clients and Samba.
+#dhcp-option=19,0           # option ip-forwarding off
+#dhcp-option=44,0.0.0.0     # set netbios-over-TCP/IP nameserver(s) aka WINS server(s)
+#dhcp-option=45,0.0.0.0     # netbios datagram distribution server
+#dhcp-option=46,8           # netbios node type
+#dhcp-option=47             # empty netbios scope.
+
+# Send RFC-3397 DNS domain search DHCP option. WARNING: Your DHCP client
+# probably doesn't support this......
+#dhcp-option=option:domain-search,eng.apple.com,marketing.apple.com
+
+# Send RFC-3442 classless static routes (note the netmask encoding)
+#dhcp-option=121,192.168.1.0/24,1.2.3.4,10.0.0.0/8,5.6.7.8
+
+# Send vendor-class specific options encapsulated in DHCP option 43. 
+# The meaning of the options is defined by the vendor-class so
+# options are sent only when the client supplied vendor class
+# matches the class given here. (A substring match is OK, so "MSFT" 
+# matches "MSFT" and "MSFT 5.0"). This example sets the
+# mtftp address to 0.0.0.0 for PXEClients.
+#dhcp-option=vendor:PXEClient,1,0.0.0.0
+
+# Send microsoft-specific option to tell windows to release the DHCP lease
+# when it shuts down. Note the "i" flag, to tell dnsmasq to send the
+# value as a four-byte integer - that's what microsoft wants. See
+# http://technet2.microsoft.com/WindowsServer/en/library/a70f1bb7-d2d4-49f0-96d6-4b7414ecfaae1033.mspx?mfr=true
+#dhcp-option=vendor:MSFT,2,1i
+
+# Send the Encapsulated-vendor-class ID needed by some configurations of
+# Etherboot to allow is to recognise the DHCP server.
+#dhcp-option=vendor:Etherboot,60,"Etherboot"
+
+# Send options to PXELinux. Note that we need to send the options even
+# though they don't appear in the parameter request list, so we need
+# to use dhcp-option-force here. 
+# See http://syslinux.zytor.com/pxe.php#special for details.
+# Magic number - needed before anything else is recognised
+#dhcp-option-force=208,f1:00:74:7e
+# Configuration file name
+#dhcp-option-force=209,configs/common
+# Path prefix
+#dhcp-option-force=210,/tftpboot/pxelinux/files/
+# Reboot time. (Note 'i' to send 32-bit value)
+#dhcp-option-force=211,30i
+
+# Set the boot filename for BOOTP. You will only need 
+# this is you want to boot machines over the network and you will need
+# a TFTP server; either dnsmasq's built in TFTP server or an
+# external one. (See below for how to enable the TFTP server.)
+#dhcp-boot=pxelinux.0
+
+# Enable dnsmasq's built-in TFTP server
+#enable-tftp
+
+# Set the root directory for files availble via FTP.
+#tftp-root=/var/ftpd
+
+# Make the TFTP server more secure: with this set, only files owned by
+# the user dnsmasq is running as will be send over the net.
+#tftp-secure
+
+# Set the boot file name only when the "red" tag is set.
+#dhcp-boot=net:red,pxelinux.red-net
+
+# An example of dhcp-boot with an external server: the name and IP
+# address of the server are given after the filename.
+#dhcp-boot=/var/ftpd/pxelinux.0,boothost,192.168.0.3
+
+# Set the limit on DHCP leases, the default is 150
+#dhcp-lease-max=150
+
+# The DHCP server needs somewhere on disk to keep its lease database.
+# This defaults to a sane location, but if you want to change it, use
+# the line below.
+#dhcp-leasefile=/var/lib/misc/dnsmasq.leases
+
+# Set the DHCP server to authoritative mode. In this mode it will barge in
+# and take over the lease for any client which broadcasts on the network,
+# whether it has a record of the lease or not. This avoids long timeouts
+# when a machine wakes up on a new network. DO NOT enable this if there's
+# the slighest chance that you might end up accidentally configuring a DHCP
+# server for your campus/company accidentally. The ISC server uses the same
+# the same option, and this URL provides more information:
+# http://www.isc.org/index.pl?/sw/dhcp/authoritative.php
+#dhcp-authoritative
+
+# Run an executable when a DHCP lease is created or destroyed.
+# The arguments sent to the script are "add" or "del", 
+# then the MAC address, the IP address and finally the hostname
+# if there is one. 
+#dhcp-script=/bin/echo
+
+# Set the cachesize here.
+#cache-size=150
+
+# If you want to disable negative caching, uncomment this.
+#no-negcache
+
+# Normally responses which come form /etc/hosts and the DHCP lease
+# file have Time-To-Live set as zero, which conventionally means
+# do not cache further. If you are happy to trade lower load on the
+# server for potentially stale date, you can set a time-to-live (in
+# seconds) here.
+#local-ttl=
+
+# If you want dnsmasq to detect attempts by Verisign to send queries
+# to unregistered .com and .net hosts to its sitefinder service and
+# have dnsmasq instead return the correct NXDOMAIN response, uncomment
+# this line. You can add similar lines to do the same for other
+# registries which have implemented wildcard A records.
+#bogus-nxdomain=64.94.110.11
+
+# If you want to fix up DNS results from upstream servers, use the
+# alias option. This only works for IPv4.
+# This alias makes a result of 1.2.3.4 appear as 5.6.7.8
+#alias=1.2.3.4,5.6.7.8
+# and this maps 1.2.3.x to 5.6.7.x
+#alias=1.2.3.0,5.6.7.0,255.255.255.0
+
+
+# Change these lines if you want dnsmasq to serve MX records.
+
+# Return an MX record named "maildomain.com" with target
+# servermachine.com and preference 50
+#mx-host=maildomain.com,servermachine.com,50
+
+# Set the default target for MX records created using the localmx option.
+#mx-target=servermachine.com
+
+# Return an MX record pointing to the mx-target for all local
+# machines.
+#localmx
+
+# Return an MX record pointing to itself for all local machines.
+#selfmx
+
+# Change the following lines if you want dnsmasq to serve SRV
+# records.  These are useful if you want to serve ldap requests for
+# Active Directory and other windows-originated DNS requests.
+# See RFC 2782.
+# You may add multiple srv-host lines.
+# The fields are <name>,<target>,<port>,<priority>,<weight>
+# If the domain part if missing from the name (so that is just has the
+# service and protocol sections) then the domain given by the domain=
+# config option is used. (Note that expand-hosts does not need to be
+# set for this to work.)
+
+# A SRV record sending LDAP for the example.com domain to
+# ldapserver.example.com port 289
+#srv-host=_ldap._tcp.example.com,ldapserver.example.com,389
+
+# A SRV record sending LDAP for the example.com domain to
+# ldapserver.example.com port 289 (using domain=)
+#domain=example.com
+#srv-host=_ldap._tcp,ldapserver.example.com,389
+
+# Two SRV records for LDAP, each with different priorities
+#srv-host=_ldap._tcp.example.com,ldapserver.example.com,389,1
+#srv-host=_ldap._tcp.example.com,ldapserver.example.com,389,2
+
+# A SRV record indicating that there is no LDAP server for the domain
+# example.com
+#srv-host=_ldap._tcp.example.com
+
+# The following line shows how to make dnsmasq serve an arbitrary PTR
+# record. This is useful for DNS-SD. (Note that the
+# domain-name expansion done for SRV records _does_not
+# occur for PTR records.)
+#ptr-record=_http._tcp.dns-sd-services,"New Employee Page._http._tcp.dns-sd-services"
+
+# Change the following lines to enable dnsmasq to serve TXT records.
+# These are used for things like SPF and zeroconf. (Note that the
+# domain-name expansion done for SRV records _does_not
+# occur for TXT records.)
+
+#Example SPF.
+#txt-record=example.com,"v=spf1 a -all"
+
+#Example zeroconf
+#txt-record=_http._tcp.example.com,name=value,paper=A4
+
+
+# For debugging purposes, log each DNS query as it passes through
+# dnsmasq.
+#log-queries
+
+# Log lots of extra information about DHCP transactions.
+#log-dhcp
+
+# Include a another lot of configuration options.
+#conf-file=/etc/dnsmasq.more.conf
+#conf-dir=/etc/dnsmasq.d
diff -r cc18a0104636 overlay.xenrt/etc/exports
--- /dev/null	Thu Jan 01 00:00:00 1970 +0000
+++ b/overlay.xenrt/etc/exports	Tue Sep 28 13:04:52 2010 +0100
@@ -0,0 +1,3 @@
+/usr/share/xenrt/images *(sync,ro,no_root_squash,insecure)
+/local/scratch/nfs *(sync,rw,no_root_squash,insecure)
+/local/inputs/linux *(sync,ro,no_root_squash,insecure)
diff -r cc18a0104636 overlay.xenrt/etc/fstab
--- /dev/null	Thu Jan 01 00:00:00 1970 +0000
+++ b/overlay.xenrt/etc/fstab	Tue Sep 28 13:04:52 2010 +0100
@@ -0,0 +1,6 @@
+/dev/@OVA_ROOT_DEVICE@1	/		ext3	defaults	1  1
+/dev/@XENRT_SWAP_DEVICE@	swap		swap	defaults	1  1
+none		/dev/pts	devpts	defaults	0  0
+none		/dev/shm	tmpfs	defaults	0  0
+none		/proc		proc	defaults	0  0
+none		/sys		sysfs	defaults	0  0
diff -r cc18a0104636 overlay.xenrt/etc/init.d/ipsetup
--- /dev/null	Thu Jan 01 00:00:00 1970 +0000
+++ b/overlay.xenrt/etc/init.d/ipsetup	Tue Sep 28 13:04:52 2010 +0100
@@ -0,0 +1,11 @@
+#!/bin/bash
+
+# chkconfig: 12345 99 01
+# description: configure IP addressing
+
+echo "Press any key within 5 seconds to configure IP addressing..."
+any_key="none"
+read -n1 -t5 any_key
+if [ "${any_key}" != "none" ]; then
+    /etc/ipsetup
+fi
diff -r cc18a0104636 overlay.xenrt/etc/init.d/rootpassword
--- /dev/null	Thu Jan 01 00:00:00 1970 +0000
+++ b/overlay.xenrt/etc/init.d/rootpassword	Tue Sep 28 13:04:52 2010 +0100
@@ -0,0 +1,33 @@
+#!/bin/bash
+
+# chkconfig: 12345 99 01
+# description: configure system at first boot
+
+if [ "$1" != "start" ] ; then
+    exit
+fi
+
+# Rerun ourselves via initlog
+if [ -z '$IN_INITLOG' -a -x /sbin/initlog ]; then
+    exec /sbin/initlog -r "/etc/init.d/rootpassword start"
+fi
+
+. /etc/init.d/functions
+
+echo $"Configuring @PRODUCT_BRAND@ @PRODUCT_VERSION@-@BUILD_NUMBER@ XenRT:"
+echo $"(This will only appear the first time you boot this guest.)"
+
+# root password only if in interactive mode:
+if ! grep -q "noninteractive" /proc/cmdline ; then
+    echo $""
+    echo $"Please specify a root password:"
+    while ! passwd ; do : ; done
+
+#    echo $""
+#    echo $"Please specify a VNC password:"
+#    while ! vncpasswd /etc/vncpass ; do : ; done
+fi
+
+success 
+
+/sbin/chkconfig rootpassword off
diff -r cc18a0104636 overlay.xenrt/etc/ipsetup
--- /dev/null	Thu Jan 01 00:00:00 1970 +0000
+++ b/overlay.xenrt/etc/ipsetup	Tue Sep 28 13:04:52 2010 +0100
@@ -0,0 +1,128 @@
+#!/usr/bin/python
+
+import string, xml.dom.minidom, os, sys
+
+# Functions
+def convertint(ip):
+    # Convert the string ip into an integer
+    ipq = string.split(ip,".",3)
+    shift = 24
+    result = 0
+
+    for q in ipq:
+        # Convert to an int
+        qi = int(q)
+        # Shift the appropriate number of bits
+        qi = qi << shift
+        shift -= 8
+        # Add to the result
+        result += qi
+
+    return result
+
+def convertstring(ip):
+    # Convert the integer ip into a string
+    o3 = str(ip & 0xff)
+    o2 = str((ip & 0xff00) >> 8)
+    o1 = str((ip & 0xff0000) >> 16)
+    o0 = str((ip & 0xff000000) >> 24)
+    return o0 + "." + o1 + "." + o2 + "." + o3
+
+def makeElement(dom, elem, value):
+    # Make an element
+    el = dom.createElement(elem)
+    no = dom.createTextNode(value)
+    el.appendChild(no)
+    return el
+
+print ""
+print "WARNING: This will overwrite the site.xml file, to cancel, press Ctrl-C"
+ip = raw_input("Please specify an IP address for this host: ")
+snet = raw_input("Please specify the subnet mask: ")
+
+# Convert IP and subnet mask into hex
+ip_int = convertint(ip)
+snet_int = convertint(snet)
+
+# Do a bitwise AND to get the network address
+net_int = ip_int & snet_int
+net = convertstring(net_int)
+
+# Now work out the broadcast address
+bcast_int = net_int | (~snet_int)
+bcast = convertstring(bcast_int)
+
+# Now decide what range of addresses to use for the pool
+last_int = bcast_int - 1
+first_int = ip_int + 20
+last = convertstring(last_int)
+first = convertstring(first_int)
+
+print "Network Configuration"
+print "====================="
+print "Network Address: " + net + ", Subnet Mask: " + snet
+print "Controller IP: " + ip
+print "DHCP Pool Start: " + first + ", Finish: " + last
+print ""
+
+# Now write out configs
+ifcfg = """DEVICE=eth0
+BOOTPROTO=static
+ONBOOT=yes
+TYPE=ethernet
+IPADDR=%s
+NETMASK=%s
+NETWORK=%s
+BROADCAST=%s""" % (ip,snet,net,bcast)
+
+f = open('/etc/sysconfig/network-scripts/ifcfg-eth0', 'w')
+f.write(ifcfg)
+f.close()
+
+print "ifcfg-eth0 written"
+
+# Now write out the XenRT config
+
+# Read in sample config
+dom = xml.dom.minidom.parse("/home/xenrtd/xenrt.hg/examples/site.xml.in")
+
+# Add network settings
+net_elem = makeElement(dom,"SUBNET",net)
+snet_elem = makeElement(dom,"SUBNETMASK",snet)
+gw_elem = makeElement(dom,"GATEWAY",ip)
+start_elem = makeElement(dom,"POOLSTART",first)
+end_elem = makeElement(dom,"POOLEND",last)
+ns_elem = makeElement(dom,"NAMESERVERS",ip)
+
+df = dom.createElement("DEFAULT")
+df.appendChild(net_elem)
+df.appendChild(snet_elem)
+df.appendChild(gw_elem)
+df.appendChild(start_elem)
+df.appendChild(end_elem)
+df.appendChild(ns_elem)
+
+nc = dom.createElement("NETWORK_CONFIG")
+nc.appendChild(df)
+
+xenrt = dom.getElementsByTagName("xenrt")[0]
+xenrt.appendChild(nc)
+
+# Write out
+f = file("/etc/xenrt/site.xml", "w")
+dom.writexml(f, addindent="  ", newl="\n")
+f.close()
+os.popen("chown xenrtd:xenrtd /etc/xenrt/site.xml")
+
+print "site.xml written"
+
+# Now launch the network stack
+pipe = os.popen("/etc/init.d/network restart")
+while True:
+    line = pipe.readline()
+    if not line:
+        break
+    print string.strip(line)
+pipe.close()
+
+print "*** Configuration complete - continuing normal boot..."
diff -r cc18a0104636 overlay.xenrt/etc/rc.local
--- /dev/null	Thu Jan 01 00:00:00 1970 +0000
+++ b/overlay.xenrt/etc/rc.local	Tue Sep 28 13:04:52 2010 +0100
@@ -0,0 +1,84 @@
+#!/bin/bash
+
+touch /etc/boottime.stamp
+
+/sbin/update-issue
+clear </dev/tty1 >/dev/tty1
+
+defconsole="$(sed -ne 's/.*\(console=[^ ]*\).*/\1/p' /proc/cmdline)"
+defconsole=${defconsole#console=}
+
+if [ ! -e /etc/xensource/no_move_kernel_tty ]
+then
+    if [ "x${defconsole}" = "x" ] || [[ ${defconsole} = tty[0-9]* ]]
+    then
+        # Put the kernel messages on tty2
+        /usr/bin/openvt -c 2 /bin/echo "System Messages:"
+        /opt/xensource/libexec/set-printk-console 2
+    fi
+fi
+
+#don't show firewall messages on the console
+echo 4 > /proc/sys/kernel/printk
+
+# Start up DNS server
+/usr/local/sbin/dnsmasq
+
+sysctl -q -w vm.dirty_ratio=5 
+
+if [ ! -e /.configdone ]; then
+    mkfs.ext3 -F /dev/@XENRT_DATA_DEVICE@
+    mount /dev/@XENRT_DATA_DEVICE@ /local
+    echo "/dev/@XENRT_DATA_DEVICE@    /local      ext3    defaults    1  1" >> /etc/fstab
+    mkdir -p /local/apt-cache/private
+    mkdir -p /local/apt-cache/tmp
+    mkdir -p /local/apt-cache/import
+    mkdir -p /local/apt-cache/packages
+    mkdir -p /local/apt-cache/headers
+    mkdir -p /local/scratch
+    mkdir -p /local/inputs/windows
+    mkdir -p /local/inputs/linux
+    mkdir -p /local/inputs/linux/distros
+    mkdir -p /local/inputs/linux/iso
+    mkdir -p /local/inputs/linux/kernel
+    mv /home/xenrtd/tests /local/inputs/tests
+    # Populate the apt-cache
+    cp -fR /local/inputs/tests/apt-cache/* /local/apt-cache/
+    chown xenrtd -R /local
+    mkdir -p /var/log/httpd/apt-cache
+    chown xenrtd /var/log/httpd/apt-cache
+    chmod 755 /var/log/httpd
+    /etc/init.d/postgresql initdb 
+    echo "host xenrt xenrtd 127.0.0.1 255.255.255.255 trust" >> /var/lib/pgsql/data/pg_hba.conf
+    /etc/init.d/postgresql start
+    /sbin/chkconfig postgresql on
+
+    if grep -q "noninteractive" /proc/cmdline; then
+        echo "Setting up default config files"
+        cp -f /home/xenrtd/xenrt.hg/examples/ova/ifcfg-eth0 /etc/sysconfig/network-scripts/ifcfg-eth0
+        cp -f /home/xenrtd/xenrt.hg/examples/ova/site.xml /etc/xenrt/site.xml
+        cp -f /home/xenrtd/xenrt.hg/examples/ova/localconfig.mk /home/xenrtd/xenrt.hg/localconfig.mk
+
+        echo "Restarting networking"
+        /etc/init.d/network restart
+
+        echo "Performing initial make install"
+        su - xenrtd -c "make -C /home/xenrtd/xenrt.hg install"
+
+        echo "Generating configs"
+        su - xenrtd -c "cd /home/xenrtd && xrt --make-configs"
+        # Put them in the right places
+        mv -f /home/xenrtd/dhcpd.conf /etc/dhcpd.conf
+        mv -f /home/xenrtd/hosts /etc/hosts        
+
+        echo "Starting dhcpd"
+        /etc/init.d/dhcpd start
+
+        echo "[extensions]" > /home/xenrtd/.hgrc
+        echo "mq =" >> /home/xenrtd/.hgrc
+        
+    fi
+
+    touch /.configdone
+fi
+
diff -r cc18a0104636 overlay.xenrt/etc/redhat-release
--- /dev/null	Thu Jan 01 00:00:00 1970 +0000
+++ b/overlay.xenrt/etc/redhat-release	Tue Sep 28 13:04:52 2010 +0100
@@ -0,0 +1,1 @@
+@COMPANY@ XenRT release @PRODUCT_VERSION@-@BUILD_NUMBER@ (@PRODUCT_NAME@)
diff -r cc18a0104636 overlay.xenrt/etc/resolv.conf
--- /dev/null	Thu Jan 01 00:00:00 1970 +0000
+++ b/overlay.xenrt/etc/resolv.conf	Tue Sep 28 13:04:52 2010 +0100
@@ -0,0 +1,1 @@
+nameserver 127.0.0.1
diff -r cc18a0104636 overlay.xenrt/etc/sysconfig/network
--- /dev/null	Thu Jan 01 00:00:00 1970 +0000
+++ b/overlay.xenrt/etc/sysconfig/network	Tue Sep 28 13:04:52 2010 +0100
@@ -0,0 +1,2 @@
+NETWORKING=yes
+HOSTNAME=localhost.localdomain
diff -r cc18a0104636 overlay.xenrt/etc/sysconfig/network-scripts/ifcfg-eth0
--- /dev/null	Thu Jan 01 00:00:00 1970 +0000
+++ b/overlay.xenrt/etc/sysconfig/network-scripts/ifcfg-eth0	Tue Sep 28 13:04:52 2010 +0100
@@ -0,0 +1,4 @@
+DEVICE=eth0
+BOOTPROTO=dhcp
+ONBOOT=yes
+TYPE=ethernet
diff -r cc18a0104636 overlay.xenrt/etc/tftpremap
--- /dev/null	Thu Jan 01 00:00:00 1970 +0000
+++ b/overlay.xenrt/etc/tftpremap	Tue Sep 28 13:04:52 2010 +0100
@@ -0,0 +1,3 @@
+re bootmgr\.exe xenrt/native/bootmgr.exe
+rg \\Boot\\ xenrt/native/
+rg \\boot\\ xenrt/native/
diff -r cc18a0104636 overlay.xenrt/etc/xenrt_first_boot
--- /dev/null	Thu Jan 01 00:00:00 1970 +0000
+++ b/overlay.xenrt/etc/xenrt_first_boot	Tue Sep 28 13:04:52 2010 +0100
@@ -0,0 +1,1 @@
+This file is to indicate that this is the first boot of this XenRT OVA image
diff -r cc18a0104636 overlay.xenrt/root/README.ExternalModules
--- /dev/null	Thu Jan 01 00:00:00 1970 +0000
+++ b/overlay.xenrt/root/README.ExternalModules	Tue Sep 28 13:04:52 2010 +0100
@@ -0,0 +1,92 @@
+Extra kernel modules should be provided as an SRPM.
+
+The spec file should expect to be passed two variables (via the
+rpmbuild --define command line option).
+
+kernel_version -- the version of the kernel RPM to build against
+	e.g. The kernel-xen-2.6.16.33-xs0.4.0.316.3686.i686.rpm RPM
+	gives kernel_version of "2.6.16.33-xs0.4.0.316.3686".
+
+flavour -- the flavour of kernel to build against. e.g. The
+	kernel-xen-2.6.16.33-xs0.4.0.316.3686.i686.rpm RPM gives
+	flavour of "xen". Other flavours might be "xen0" or "kdump"
+
+It should be possible to take the .src.rpm file and run the command
+	rpmbuild --define "kernel_version 2.6.16.33-xs0.4.0.316.3686" \
+		 --define "flavour xen" \
+		 --rebuild FOO.src.rpm
+
+The uname of the kernel to build against is therefore
+%{kernel_version}%{?flavour}. e.g. The uname of the kernel in the
+kernel-xen-2.6.16.33-xs0.4.0.316.3686.i686.rpm RPM is
+2.6.16.33-xs0.4.0.316.3686xen.
+
+The spec file should expect to find the kernel headers to build
+against in /lib/modules/%{uname}/build (this is the standard upstream
+location). The package should not attempt to build against the currently
+running kernel.
+
+The binary package name should be suffixed with the flavour (if
+flavour is defined) and the kernel_version -- for example
+FOO-modules-%{flavour}-%{kernel_version}. If no flavour is defined it
+should be ommited e.g. FOO-modules-%{kernel_version}.
+
+The binary package should declare that it provides
+FOO-modules-%{flavour} = %{kernel_version} and requires
+kernel-%{flavour} = %{kernel_version}. If no flavour is given this
+becomes provides foo-modules = ${kernel_version} and requires kernel =
+%{kernel_version}.
+
+An example spec file for a module which uses the standard Linux 2.6
+external module Makefile structure is given below.
+
+	%define binsuffix %{?flavour:-%{flavour}}
+	%define uname  %{kernel_version}%{?flavour}
+
+	Summary: Driver for FOO
+	Name: FOO
+	Version: 1.0
+	Revision: 1
+	License: GPL
+	Group: System Environment/Kernel
+	Source: %{name}-%{version}.tar.gz
+	BuildRoot: %{_tmppath}/%{name}-%{version}-%{release}-buildroot
+
+	%description
+	FOO Linux Device Driver source.
+
+	%package modules%{binsuffix}-%{kernel_version}
+	Summary: The foo modules
+	Group: System Environment/Kernel
+	Provides: %{name}-modules%{binsuffix} = %{kernel_version}
+	Requires: kernel%{binsuffix} = %{kernel_version}
+
+	%description modules%{binsuffix}-%{kernel_version}
+	FOO Linux Device Driver modules compiled against kernel
+	version %{uname}.
+
+	%prep
+	%setup -q -n %{name}-%{version}
+
+	%build
+	%{__make} -C /lib/modules/%{uname}/build M=$(pwd) modules
+
+	%install
+	rm -rf $RPM_BUILD_ROOT
+	%{__make} -C /lib/modules/%{uname}/build M=$(pwd) INSTALL_MOD_PATH=$RPM_BUILD_ROOT modules_install
+
+	# mark modules executable so that strip-to-file can strip them
+	find $RPM_BUILD_ROOT/lib/modules/%{uname} -name "*.ko" -type f  | xargs chmod u+x
+
+	%clean
+	rm -rf $RPM_BUILD_ROOT
+
+	%post modules%{binsuffix}-%{kernel_version}
+	depmod %{uname}
+
+	%files modules%{binsuffix}-%{kernel_version}
+	%defattr(-,root,root,-)
+	/lib/modules/%{uname}/extra/*.ko
+	%doc
+
+	%changelog
diff -r cc18a0104636 overlay.xenrt/root/README.RepositoryFormat
--- /dev/null	Thu Jan 01 00:00:00 1970 +0000
+++ b/overlay.xenrt/root/README.RepositoryFormat	Tue Sep 28 13:04:52 2010 +0100
@@ -0,0 +1,157 @@
+XENSOURCE REPOSITORY FORMAT
+===============================
+(for @PRODUCT_BRAND@ @PRODUCT_VERSION@-@BUILD_NUMBER@)
+
+The repository format described here should be used by installation sources
+and driver disks.
+
+Presence of Repositories
+------------------------
+
+Given a path, the presence of a XenSource repository is determined by
+checking for the existence of valid XS-REPOSITORY and XS-PACKAGES files.
+From a given base, that base is checked, along with the packages,
+packages.main, packages.linux, and packages.site subdirectories.  Thus, a
+typical installation point will have the following format:
+
+  xs-installation
+  +-- packages.main
+  |   +-- XS-REPOSITORY
+  |   +-- XS-PACKAGES
+  |   +-- ...
+  +-- packages.linux
+  |   +-- XS-REPOSITORY
+  |   +-- XS-PACKAGES
+  |   +-- ...
+  +-- packages.site
+  |   +-- XS-REPOSITORY
+  |   +-- XS-PACKAGES
+  |   +-- ...
+
+A typical driver disk will have the following layout:
+
+  xs-driver-disk
+  +-- XS-REPOSITORY
+  +-- XS-PACKAGES
+
+In the first example, given a path to xs-installation, the installer will
+detect the presence of three repositories.  In the second example, a single
+repository will be detected.
+
+
+Repository Meta-data
+--------------------
+
+The XS-REPOSITORY file is used to describe a XenSource-format repository.
+It has four fields, separated by newlines:
+
+   <repository id>
+   <repository name>
+   <intended target product>
+   <intended target version>
+
+Repository IDs should be alphanumeric strings that provide a machine
+identifier for the repository.  They should be unique within a target
+product and version.  Best practise is to use the form 'vendor:repository':
+XenSource repositories start with 'xs', e.g. 'xs:main' -- custom
+repositories should be 'custom:my-repo', and third-party add-ons should be
+identified as such by using an appropriate vendor string.  This will help
+avoid name clashes.
+
+Repository names are presented to the user, so should be a string that
+identifies the repository in a sensible manner so the user can confirm that
+they wish to install from it.
+
+The intended target product will be XenServer; version 3.2.0-<build>.
+
+
+Package meta-data
+-----------------
+
+The XS-PACKAGES file describes the packages in a repository, one line per
+package.  Fields are space separated.
+
+There are three types of package: tbz2 packages are bzipped tarballs that
+get extracted onto the root filesystem, driver packages are kernel modules
+that get loaded by the installer at runtime as well as being installed into
+the filesystem, and firmware packages are made available during the
+installation so that they may be loaded by udev as welle being installed
+into the target filesystem.. Firmware loading support is currently limited
+but this will be addressed in the next release. 
+
+The first three fields are mandatory: package name, package size, and
+package checksum (md5).  The fourth field is one of 'tbz2', 'driver', or
+'firmware', and this dictates the contents of the subsequent fields.
+
+tbz2 fields:
+  required/optional
+  source filename
+  destination (usually '/')i
+
+  example:
+   docs 37750 2ba1783d84d10c71f07469252c555427 tbz2 required docs.tar.bz2 /
+
+
+driver fields:
+  source filename
+  destination (${KERNEL_VERSION} will be substituted with the Xen-kernel
+        version.)
+
+  example:
+    firmware_example 77001 3452c04dfcc237cde11c63d43e97a303 driver \
+      firmware_example.ko \
+      /lib/modules/${KERNEL_VERSION}/extra/firmware_example.ko
+
+firmware fields:
+  destination filename (no path necessary - automatically prefixed with
+        /lib/firmware).
+
+  example:
+    firmware 12 6f5902ac237024bdd0c176cb93063dc4 firmware sample_firware.bin
+
+
+('\' indicates an unintended line break).
+
+
+Example files:
+--------------
+
+XS-REPOSITORY:
+- - - - - - - 
+
+    xs:main
+    Base Pack and extra driver
+    XenServer
+    3.2.0-1934
+
+XS-PACKAGES:
+- - - - - - 
+
+    storage-manager 59831 b66672f0aa681bd2b498e3d902f17c04 tbz2 required \
+             storage-manager.tar.bz2 /
+    xenagentd 2073470 9d34f795e814160a01c262be3b68f9c9 tbz2 required \
+             xenagentd.tar.bz2 /
+    docs 37750 2ba1783d84d10c71f07469252c555427 tbz2 required docs.tar.bz2 /
+    xgts-main 1133 59dda9c318f4205167350b7ed993b5cd tbz2 required \
+            xgts-main.tar.bz2 /
+    pvdrivers-win 524477 37ea0c145f5b0d7a2740ecb69d21ed52 tbz2 required \
+            pvdrivers-win.tar.bz2 /
+    dom0fs 169875708 c1a86d705915eda16cca84cccffaca9f tbz2 required \
+            dom0fs.tar.bz2 /
+
+('\' indicates an unintended line-break.)
+
+
+Notes on best practise
+----------------------
+
+If a driver disk is used, any tbz2 packages on it will also be installed to
+the target.  However, a copy of the repository will be taken so that the
+drivers can be loaded at runtime; this copy is placed into memory.
+
+Therefore, if you are constructing a driver disk that also includes
+user-space tools, if these result in a large repository it is better to
+split it up into two repositories and require that people use the
+packages.site mechanism to install your add-ons, or provide a post-install
+script to install them after-the-fact.
+
diff -r cc18a0104636 overlay.xenrt/sbin/update-issue
--- /dev/null	Thu Jan 01 00:00:00 1970 +0000
+++ b/overlay.xenrt/sbin/update-issue	Tue Sep 28 13:04:52 2010 +0100
@@ -0,0 +1,13 @@
+#!/bin/bash
+
+[ -e /etc/boottime.stamp ] || touch /etc/boottime.stamp
+
+cat > $mnt/etc/issue <<EOF
+@COMPANY@ XenRT @PRODUCT_VERSION@-@BUILD_NUMBER@
+
+System Booted: `date -r /etc/boottime.stamp +"%F %R"`
+
+EOF
+
+exit 0
+
diff -r cc18a0104636 overlay.xenrt/tftpboot/banner
--- /dev/null	Thu Jan 01 00:00:00 1970 +0000
+++ b/overlay.xenrt/tftpboot/banner	Tue Sep 28 13:04:52 2010 +0100
@@ -0,0 +1,11 @@
+
+                   #     #  #######  #     #  ######   #######
+                    #   #   #        ##    #  #     #     #
+                     # #    #        # #   #  #     #     #
+                      #     #####    #  #  #  ######      #
+                     # #    #        #   # #  #   #       #
+                    #   #   #        #    ##  #    #      #
+                   #     #  #######  #     #  #     #     #
+
+   ========================= Citrix XenRT PXE boot =========================
+
diff -r cc18a0104636 overlay.xenrt/tftpboot/pxelinux.cfg/default
--- /dev/null	Thu Jan 01 00:00:00 1970 +0000
+++ b/overlay.xenrt/tftpboot/pxelinux.cfg/default	Tue Sep 28 13:04:52 2010 +0100
@@ -0,0 +1,8 @@
+SERIAL 0 115200
+PROMPT 1
+TIMEOUT 20
+DEFAULT local
+DISPLAY banner
+
+LABEL local
+    LOCALBOOT 0
diff -r cc18a0104636 packages.xenrt
--- /dev/null	Thu Jan 01 00:00:00 1970 +0000
+++ b/packages.xenrt	Tue Sep 28 13:04:52 2010 +0100
@@ -0,0 +1,50 @@
+postgresql-python
+postgresql-server
+postgresql
+stunnel
+net-snmp
+net-snmp-utils
+nmap
+nfs-utils
+httpd
+rcs
+mkisofs
+tftp-server
+make
+gcc
+gcc-c++
+glibc-devel
+kernel-xen-devel
+kernel-kdump-devel
+xen-devel
+valgrind
+redhat-rpm-config
+xe-guest-utilities
+libxml2-devel
+python-devel
+curl-devel
+rsync
+rpm-build
+rpm-devel
+ghostscript
+mercurial
+lynx
+telnet
+strace
+tcpdump
+authd
+libjpeg-devel
+perl-IO-Socket-SSL
+perl-Net-SSLeay
+vconfig
+perl-libwww-perl
+gnuplot
+vim-common
+vim-enhanced
+openssl-devel
+libxml2-devel
+yp-tools
+ypbind
+hesiod
+autofs
+libxml2-python
diff -r cc18a0104636 patches.xenrt/patch-etc_crontab
--- /dev/null	Thu Jan 01 00:00:00 1970 +0000
+++ b/patches.xenrt/patch-etc_crontab	Tue Sep 28 13:04:52 2010 +0100
@@ -0,0 +1,12 @@
+--- dom0-pure/etc/crontab	2007-08-16 14:34:47.000000000 +0000
++++ dom0-staging/etc/crontab	2007-08-16 14:36:33.000000000 +0000
+@@ -8,3 +8,9 @@
+ 02 4 * * * root run-parts /etc/cron.daily
+ 22 4 * * 0 root run-parts /etc/cron.weekly
+ 42 4 1 * * root run-parts /etc/cron.monthly
++
++*/2 * * * * xenrtd if [ -e /etc/xenrt/siteid ]; then /usr/share/xenrt/control/site-controller -d -s `cat /etc/xenrt/siteid` >> /tmp/xenrt-site-controller.log 2>&1; fi
++30 * * * * xenrtd /usr/bin/xrt -V --replay-db >> /tmp/xenrt-replay-db.log 2>&1
++0 0 * * * xenrtd /usr/bin/xrt -V --cleanup-filecache >> /tmp/xenrt-cleanup-filecache.log 2>&1
++5 * * * * xenrtd /usr/bin/xrt -V --cleanup-locks >> /tmp/xenrt-cleanup-locks.log 2>&1
++40 6 * * * xenrtd if [ -e /usr/share/xenrt/control/backupdb.sh ]; then /usr/share/xenrt/control/backupdb.sh; fi
diff -r cc18a0104636 patches.xenrt/patch-etc_httpd_conf_httpd.conf
--- /dev/null	Thu Jan 01 00:00:00 1970 +0000
+++ b/patches.xenrt/patch-etc_httpd_conf_httpd.conf	Tue Sep 28 13:04:52 2010 +0100
@@ -0,0 +1,40 @@
+--- dom0-pure/etc/httpd/conf/httpd.conf	2007-06-27 15:26:07.000000000 +0000
++++ dom0-staging/etc/httpd/conf/httpd.conf	2007-06-27 15:26:48.000000000 +0000
+@@ -227,8 +227,8 @@
+ #  when the value of (unsigned)Group is above 60000; 
+ #  don't use Group #-1 on these systems!
+ #
+-User apache
+-Group apache
++User xenrtd
++Group xenrtd
+ 
+ ### Section 2: 'Main' server configuration
+ #
+@@ -316,14 +316,14 @@
+ # http://httpd.apache.org/docs/2.2/mod/core.html#options
+ # for more information.
+ #
+-    Options Indexes FollowSymLinks
++    Options Indexes FollowSymLinks ExecCGI
+ 
+ #
+ # AllowOverride controls what directives may be placed in .htaccess files.
+ # It can be "All", "None", or any combination of the keywords:
+ #   Options FileInfo AuthConfig Limit
+ #
+-    AllowOverride None
++    AllowOverride All
+ 
+ #
+ # Controls who can get stuff from this server.
+@@ -580,6 +580,9 @@
+ # Example:
+ # Redirect permanent /foo http://www.example.com/bar
+ 
++RewriteEngine on
++RewriteRule ^/$ /share/control/ [R]
++
+ #
+ # Directives controlling the display of server-generated directory listings.
+ #
diff -r cc18a0104636 patches.xenrt/patch-etc_inittab
--- /dev/null	Thu Jan 01 00:00:00 1970 +0000
+++ b/patches.xenrt/patch-etc_inittab	Tue Sep 28 13:04:52 2010 +0100
@@ -0,0 +1,8 @@
+--- dom0-pure/etc/inittab	2008-05-08 11:36:34.000000000 +0100
++++ dom0-staging/etc/inittab	2008-05-08 11:38:49.000000000 +0100
+@@ -51,3 +45,3 @@
+ 
+-# Run xdm in runlevel 5
+-x:5:respawn:/etc/X11/prefdm -nodaemon
++s0:2345:respawn:/sbin/agetty hvc0 115200,9600 linux
++
diff -r cc18a0104636 patches.xenrt/patch-etc_modprobe.d_modprobe.conf.dist
--- /dev/null	Thu Jan 01 00:00:00 1970 +0000
+++ b/patches.xenrt/patch-etc_modprobe.d_modprobe.conf.dist	Tue Sep 28 13:04:52 2010 +0100
@@ -0,0 +1,11 @@
+--- /etc/modprobe.d/modprobe.conf.dist.orig	2007-06-21 05:52:23.000000000 -0400
++++ /etc/modprobe.d/modprobe.conf.dist	2007-06-21 05:51:07.000000000 -0400
+@@ -42,7 +42,7 @@
+ alias char-major-9-* st
+ alias char-major-10-2 msbusmouse
+ alias char-major-10-3 atixlmouse
+-alias char-major-10-135 rtc
++alias char-major-10-135 off
+ alias char-major-10-139 openprom
+ alias char-major-10-157 applicom
+ alias char-major-10-175 agpgart
diff -r cc18a0104636 patches.xenrt/patch-etc_sudoers
--- /dev/null	Thu Jan 01 00:00:00 1970 +0000
+++ b/patches.xenrt/patch-etc_sudoers	Tue Sep 28 13:04:52 2010 +0100
@@ -0,0 +1,16 @@
+--- dom0-pure/etc/sudoers	2007-10-01 10:04:00.000000000 +0000
++++ dom0-staging/etc/sudoers	2007-10-01 10:04:49.000000000 +0000
+@@ -53,7 +53,6 @@
+ # Disable "ssh hostname sudo <cmd>", because it will show the password in clear. 
+ #         You have to run "ssh -t hostname sudo <cmd>".
+ #
+-Defaults    requiretty
+ 
+ Defaults    env_reset
+ Defaults    env_keep = "COLORS DISPLAY HOSTNAME HISTSIZE INPUTRC KDEDIR \
+@@ -92,3 +91,5 @@
+ ## Allows members of the users group to shutdown this system
+ # %users  localhost=/sbin/shutdown -h now
+ 
++xenrtd ALL=(ALL)	NOPASSWD: ALL
++
diff -r cc18a0104636 patches.xenrt/patch-etc_vimrc
--- /dev/null	Thu Jan 01 00:00:00 1970 +0000
+++ b/patches.xenrt/patch-etc_vimrc	Tue Sep 28 13:04:52 2010 +0100
@@ -0,0 +1,10 @@
+diff -ur dom0-pure/etc/vimrc dom0-staging/etc/vimrc
+--- dom0-pure/etc/vimrc	2008-04-21 10:19:38.000000000 +0000
++++ dom0-staging/etc/vimrc	2008-04-21 10:20:47.000000000 +0000
+@@ -49,3 +49,6 @@
+      set t_Sb=[4%dm
+      set t_Sf=[3%dm
+ endif
++
++set tabstop=4
++set expandtab
diff -r cc18a0104636 patches.xenrt/patch-etc_xinetd.d_auth
--- /dev/null	Thu Jan 01 00:00:00 1970 +0000
+++ b/patches.xenrt/patch-etc_xinetd.d_auth	Tue Sep 28 13:04:52 2010 +0100
@@ -0,0 +1,17 @@
+--- dom0-pure/etc/xinetd.d/auth	2007-08-07 15:15:09.000000000 +0000
++++ dom0-staging/etc/xinetd.d/auth	2007-08-07 15:15:29.000000000 +0000
+@@ -8,12 +8,12 @@
+ # SPAM HARVESTERS) BEFORE RUNNING THIS DAEMON WITH NO ARGUMENTS.
+ service auth
+ {
+-        disable         = yes
++        disable         = no
+         socket_type     = stream
+         wait            = no
+         user            = ident
+         cps             = 4096 10
+         instances       = UNLIMITED
+         server          = /usr/sbin/in.authd
+-        server_args     = -t60 --xerror --os -E
++        server_args     = -t60 --xerror --os
+ }
diff -r cc18a0104636 patches.xenrt/patch-etc_xinetd.d_tftp
--- /dev/null	Thu Jan 01 00:00:00 1970 +0000
+++ b/patches.xenrt/patch-etc_xinetd.d_tftp	Tue Sep 28 13:04:52 2010 +0100
@@ -0,0 +1,13 @@
+--- dom0-pure/etc/xinetd.d/tftp	2007-07-23 08:50:35.000000000 +0000
++++ dom0-staging/etc/xinetd.d/tftp	2008-02-15 10:30:00.000000000 +0000
+@@ -10,8 +10,8 @@
+ 	wait			= yes
+ 	user			= root
+ 	server			= /usr/sbin/in.tftpd
+-	server_args		= -s /tftpboot
+-	disable			= yes
++	server_args		= -s /tftpboot -v -m /etc/tftpremap
++	disable			= no
+ 	per_source		= 11
+ 	cps			= 100 2
+ 	flags			= IPv4
diff -r cc18a0104636 xenrt.ova.xml.in
--- /dev/null	Thu Jan 01 00:00:00 1970 +0000
+++ b/xenrt.ova.xml.in	Tue Sep 28 13:04:52 2010 +0100
@@ -0,0 +1,17 @@
+<?xml version="1.0" ?>
+<appliance version="0.1">
+        <vm name="vm">
+                <label>
+                        @COMPANY@ XenRT @PRODUCT_VERSION@-@BUILD_NUMBER@
+                </label>
+                <shortdesc>
+			
+                </shortdesc>
+                <config mem_set="@OVA_MEM@" vcpus="1"/>
+        <hacks is_hvm="false"/>
+                <vbd device="@OVA_ROOT_DEVICE@" function="root" mode="w" vdi="vdi_@OVA_ROOT_DEVICE@"/>
+                <vbd device="@XENRT_SWAP_DEVICE@" function="swap" mode="w" vdi="vdi_@XENRT_SWAP_DEVICE@"/>
+        </vm>
+        <vdi name="vdi_@OVA_ROOT_DEVICE@" size="@OVA_DISK@" source="file://@OVA_ROOT_DEVICE@" type="dir-gzipped-chunks" variety="system"/>
+        <vdi name="vdi_@XENRT_SWAP_DEVICE@" size="@XENRT_DISK_SWAP@" source="file://@XENRT_SWAP_DEVICE@" type="dir-gzipped-chunks" variety="system"/>
+</appliance>
